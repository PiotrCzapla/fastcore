[
  {
    "objectID": "external.html",
    "href": "external.html",
    "title": "External modules",
    "section": "",
    "text": "fastcore includes functionality from some modules from other projects that have been copied here, in cases where the original is no longer maintained, or where the original includes dependencies that we’d rather avoid.",
    "crumbs": [
      "External modules"
    ]
  },
  {
    "objectID": "external.html#imghdr",
    "href": "external.html#imghdr",
    "title": "External modules",
    "section": "imghdr",
    "text": "imghdr\nfastcore includes a copy of the Python standard library’s imghdr module, which was deprecated in Python 3.11, and removed in 3.13. However since it’s still widely used (including within fastcore), we are providing it here. We have also added some fixes to the automatic detection.\n\nfrom fastcore.imghdr import what,tests\n\n\nwhat('images/puppy.jpg')\n\n'jpeg'\n\n\nThese are the tests provided:\n\nprint(', '.join(t.__name__ for t in tests))\n\ntest_jpeg, test_png, test_gif, test_tiff, test_rgb, test_pbm, test_pgm, test_ppm, test_rast, test_xbm, test_bmp, test_webp, test_exr",
    "crumbs": [
      "External modules"
    ]
  },
  {
    "objectID": "external.html#ansi",
    "href": "external.html#ansi",
    "title": "External modules",
    "section": "ansi",
    "text": "ansi\nnbconvert provides handy functionality to convert ansi terminal codes to HTML, which we’ve copied to fastcore so they can be used without nbconvert’s prequisites. Also nbconvert doesn’t document them, so we’re showing some examples here.\n\nfrom fastcore.ansi import ansi2html,strip_ansi\n\n\nansi_test = \"\"\"\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m\n\\x1b[0;31mZeroDivisionError\\x1b[0m                         Traceback (most recent call last)\nFile \\x1b[0;32m&lt;input-1&gt;:1\\x1b[0m\n\\x1b[0;32m----&gt; 1\\x1b[0m \\x1b[38;5;241m1\\x1b[39m\\x1b[38;5;241m/\\x1b[39m\\x1b[38;5;241m0\\x1b[39m\n\n\\x1b[0;31mZeroDivisionError\\x1b[0m: division by zero\"\"\"\n\n\nout = ansi2html(ansi_test)\nprint(out)\n\n&lt;span class=\"ansi-red-fg\"&gt;---------------------------------------------------------------------------&lt;/span&gt;\n&lt;span class=\"ansi-red-fg\"&gt;ZeroDivisionError&lt;/span&gt;                         Traceback (most recent call last)\nFile &lt;span class=\"ansi-green-fg\"&gt;&lt;input-1&gt;:1&lt;/span&gt;\n&lt;span class=\"ansi-green-fg\"&gt;----&gt; 1&lt;/span&gt; &lt;span style=\"color: rgb(98,98,98)\"&gt;1&lt;/span&gt;&lt;span style=\"color: rgb(98,98,98)\"&gt;/&lt;/span&gt;&lt;span style=\"color: rgb(98,98,98)\"&gt;0&lt;/span&gt;\n\n&lt;span class=\"ansi-red-fg\"&gt;ZeroDivisionError&lt;/span&gt;: division by zero\n\n\n\ntest_err = ''.join([f\"&lt;div&gt;{o}&lt;/div&gt;\" for o in out.splitlines()])\nHTML(f'&lt;pre&gt;{test_err}&lt;pre&gt;')\n\n---------------------------------------------------------------------------ZeroDivisionError                         Traceback (most recent call last)File &lt;input-1&gt;:1----&gt; 1 1/0ZeroDivisionError: division by zero\n\n\nprint(strip_ansi(ansi_test))\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nFile &lt;ipython-input-1-9e1622b385b6&gt;:1\n----&gt; 1 1/0\n\nZeroDivisionError: division by zero",
    "crumbs": [
      "External modules"
    ]
  },
  {
    "objectID": "parallel.html",
    "href": "parallel.html",
    "title": "Parallel",
    "section": "",
    "text": "from fastcore.test import *\nfrom nbdev.showdoc import *\nfrom fastcore.nb_imports import *\n\n\nsource\n\nthreaded\n\ndef threaded(\n    process:bool=False\n):\n\nRun f in a Thread (or Process if process=True), and returns it\n\n@threaded\ndef _1():\n    time.sleep(0.05)\n    print(\"second\")\n    return 5\n\n@threaded\ndef _2():\n    time.sleep(0.01)\n    print(\"first\")\n\na = _1()\n_2()\ntime.sleep(0.1)\n\nfirst\nsecond\n\n\nAfter the thread is complete, the return value is stored in the result attr.\n\na.result\n\n5\n\n\n\nsource\n\n\nstartthread\n\ndef startthread(\n    f\n):\n\nLike threaded, but start thread immediately\n\n@startthread\ndef _():\n    time.sleep(0.05)\n    print(\"second\")\n\n@startthread\ndef _():\n    time.sleep(0.01)\n    print(\"first\")\n\ntime.sleep(0.1)\n\nfirst\nsecond\n\n\n\nsource\n\n\nstartproc\n\ndef startproc(\n    f\n):\n\nLike threaded(True), but start Process immediately\n\n@startproc\ndef _():\n    time.sleep(0.05)\n    print(\"second\")\n\n@startproc\ndef _():\n    time.sleep(0.01)\n    print(\"first\")\n\ntime.sleep(0.1)\n\nfirst\nsecond\n\n\n\nsource\n\n\nparallelable\n\ndef parallelable(\n    param_name, num_workers, f:NoneType=None\n):\n\n\nsource\n\nThreadPoolExecutor\n\ndef ThreadPoolExecutor(\n    max_workers:int=4, on_exc:builtin_function_or_method=&lt;built-in function print&gt;, pause:int=0, kwargs:VAR_KEYWORD\n):\n\nSame as Python’s ThreadPoolExecutor, except can pass max_workers==0 for serial execution\n\nsource\n\n\nProcessPoolExecutor\n\ndef ProcessPoolExecutor(\n    max_workers:int=4, on_exc:builtin_function_or_method=&lt;built-in function print&gt;, pause:int=0,\n    mp_context:NoneType=None, initializer:NoneType=None, initargs:tuple=(), max_tasks_per_child:NoneType=None\n):\n\nSame as Python’s ProcessPoolExecutor, except can pass max_workers==0 for serial execution\n\nsource\n\n\n\nparallel\n\ndef parallel(\n    f, items, args:VAR_POSITIONAL, n_workers:int=4, total:NoneType=None, progress:NoneType=None, pause:int=0,\n    method:NoneType=None, threadpool:bool=False, timeout:NoneType=None, chunksize:int=1, kwargs:VAR_KEYWORD\n):\n\nApplies func in parallel to items, using n_workers\n\ninp,exp = range(50),range(1,51)\n\ntest_eq(parallel(_add_one, inp, n_workers=2), exp)\ntest_eq(parallel(_add_one, inp, threadpool=True, n_workers=2), exp)\ntest_eq(parallel(_add_one, inp, n_workers=1, a=2), range(2,52))\ntest_eq(parallel(_add_one, inp, n_workers=0), exp)\ntest_eq(parallel(_add_one, inp, n_workers=0, a=2), range(2,52))\n\nUse the pause parameter to ensure a pause of pause seconds between processes starting. This is in case there are race conditions in starting some process, or to stagger the time each process starts, for example when making many requests to a webserver. Set threadpool=True to use ThreadPoolExecutor instead of ProcessPoolExecutor.\n\nfrom datetime import datetime\n\n\ndef print_time(i): \n    time.sleep(random.random()/1000)\n    print(i, datetime.now())\n\nparallel(print_time, range(5), n_workers=2, pause=0.25);\n\n0 2024-10-11 23:06:05.920741\n1 2024-10-11 23:06:06.171470\n2 2024-10-11 23:06:06.431925\n3 2024-10-11 23:06:06.689940\n4 2024-10-11 23:06:06.937109\n\n\n\nsource\n\n\nparallel_async\n\ndef parallel_async(\n    f, items, args:VAR_POSITIONAL, n_workers:int=16, timeout:NoneType=None, chunksize:int=1,\n    on_exc:builtin_function_or_method=&lt;built-in function print&gt;, kwargs:VAR_KEYWORD\n):\n\nApplies f to items in parallel using asyncio and a semaphore to limit concurrency.\n\nimport asyncio\n\n\nasync def print_time_async(i): \n    wait = random.random()\n    await asyncio.sleep(wait)\n    print(i, datetime.now(), wait)\n\nawait parallel_async(print_time_async, range(6), n_workers=3);\n\n0 2024-10-11 23:06:39.545583 0.10292732609738675\n3 2024-10-11 23:06:39.900393 0.3516179734831676\n4 2024-10-11 23:06:39.941094 0.03699593757956876\n2 2024-10-11 23:06:39.957677 0.5148658606540902\n1 2024-10-11 23:06:40.099716 0.6574035385815227\n5 2024-10-11 23:06:40.654097 0.7116319667399102\n\n\n\nsource\n\n\nrun_procs\n\ndef run_procs(\n    f, f_done, args\n):\n\nCall f for each item in args in parallel, yielding f_done\n\nsource\n\n\nparallel_gen\n\ndef parallel_gen(\n    cls, items, n_workers:int=4, kwargs:VAR_KEYWORD\n):\n\nInstantiate cls in n_workers procs & call each on a subset of items in parallel.\n\n# class _C:\n#     def __call__(self, o): return ((i+1) for i in o)\n\n# items = range(5)\n\n# res = L(parallel_gen(_C, items, n_workers=0))\n# idxs,dat1 = zip(*res.sorted(itemgetter(0)))\n# test_eq(dat1, range(1,6))\n\n# res = L(parallel_gen(_C, items, n_workers=3))\n# idxs,dat2 = zip(*res.sorted(itemgetter(0)))\n# test_eq(dat2, dat1)\n\ncls is any class with __call__. It will be passed args and kwargs when initialized. Note that n_workers instances of cls are created, one in each process. items are then split in n_workers batches and one is sent to each cls. The function then returns a generator of tuples of item indices and results.\n\nclass TestSleepyBatchFunc:\n    \"For testing parallel processes that run at different speeds\"\n    def __init__(self): self.a=1\n    def __call__(self, batch):\n        for k in batch:\n            time.sleep(random.random()/4)\n            yield k+self.a\n\nx = np.linspace(0,0.99,20)\n\nres = L(parallel_gen(TestSleepyBatchFunc, x, n_workers=2))\ntest_eq(res.sorted().itemgot(1), x+1)\n\n\n\n\n\n\n\n\n\n# #|hide\n# from subprocess import Popen, PIPE\n# # test num_workers &gt; 0 in scripts works when python process start method is spawn\n# process = Popen([\"python\", \"parallel_test.py\"], stdout=PIPE)\n# _, err = process.communicate(timeout=10)\n# exit_code = process.wait()\n# test_eq(exit_code, 0)",
    "crumbs": [
      "Parallel"
    ]
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Test",
    "section": "",
    "text": "We can check that code raises an exception when that’s expected (test_fail).\nTo test for equality or inequality (with different types of things) we define a simple function test that compares two objects with a given cmp operator.\n\nsource\n\n\n\ndef test_fail(\n    f, msg:str='', contains:str='', exc:type=&lt;class 'Exception'&gt;, args:NoneType=None, kwargs:NoneType=None\n):\n\nFails with msg unless f() raises an exception of type exc and (optionally) has contains in e.args\n\ndef _fail(): raise Exception(\"foobar\")\ntest_fail(_fail, contains=\"foo\")\n\ndef _fail(): raise Exception()\ntest_fail(_fail)\n\ndef _fail(): raise ValueError()\ntest_fail(_fail, exc=ValueError)\ntest_fail(lambda: test_fail(_fail, exc=IndexError), exc=AssertionError)\n\nWe can also pass args and kwargs to function to check if it fails with special inputs.\n\ndef _fail_args(a):\n    if a == 5:\n        raise ValueError\ntest_fail(_fail_args, args=(5,))\ntest_fail(_fail_args, kwargs=dict(a=5))\n\n\nsource\n\n\n\n\ndef test(\n    a, b, cmp, cname:NoneType=None\n):\n\nassert that cmp(a,b); display inputs and cname or cmp.__name__ if it fails\n\ntest([1,2],[1,2], operator.eq)\ntest_fail(lambda: test([1,2],[1], operator.eq))\ntest([1,2],[1],   operator.ne)\ntest_fail(lambda: test([1,2],[1,2], operator.ne))\n\n\n\n\n\n\ndef all_equal(\n    a, b\n):\n\nCompares whether a and b are the same length and have the same contents\n\ntest(['abc'], ['abc'], all_equal)\ntest_fail(lambda: test(['abc'],['cab'], all_equal))\n\n\n\n\n\n\ndef equals(\n    a, b\n):\n\nCompares a and b for equality; supports sublists, tensors and arrays too\n\ntest([['abc'],['a']], [['abc'],['a']],  equals)\ntest([['abc'],['a'],'b', [['x']]], [['abc'],['a'],'b', [['x']]],  equals) # supports any depth and nested structure\n\n\nsource\n\n\n\n\ndef nequals(\n    a, b\n):\n\nCompares a and b for not equals\n\ntest(['abc'], ['ab' ], nequals)",
    "crumbs": [
      "Test"
    ]
  },
  {
    "objectID": "test.html#simple-test-functions",
    "href": "test.html#simple-test-functions",
    "title": "Test",
    "section": "",
    "text": "We can check that code raises an exception when that’s expected (test_fail).\nTo test for equality or inequality (with different types of things) we define a simple function test that compares two objects with a given cmp operator.\n\nsource\n\n\n\ndef test_fail(\n    f, msg:str='', contains:str='', exc:type=&lt;class 'Exception'&gt;, args:NoneType=None, kwargs:NoneType=None\n):\n\nFails with msg unless f() raises an exception of type exc and (optionally) has contains in e.args\n\ndef _fail(): raise Exception(\"foobar\")\ntest_fail(_fail, contains=\"foo\")\n\ndef _fail(): raise Exception()\ntest_fail(_fail)\n\ndef _fail(): raise ValueError()\ntest_fail(_fail, exc=ValueError)\ntest_fail(lambda: test_fail(_fail, exc=IndexError), exc=AssertionError)\n\nWe can also pass args and kwargs to function to check if it fails with special inputs.\n\ndef _fail_args(a):\n    if a == 5:\n        raise ValueError\ntest_fail(_fail_args, args=(5,))\ntest_fail(_fail_args, kwargs=dict(a=5))\n\n\nsource\n\n\n\n\ndef test(\n    a, b, cmp, cname:NoneType=None\n):\n\nassert that cmp(a,b); display inputs and cname or cmp.__name__ if it fails\n\ntest([1,2],[1,2], operator.eq)\ntest_fail(lambda: test([1,2],[1], operator.eq))\ntest([1,2],[1],   operator.ne)\ntest_fail(lambda: test([1,2],[1,2], operator.ne))\n\n\n\n\n\n\ndef all_equal(\n    a, b\n):\n\nCompares whether a and b are the same length and have the same contents\n\ntest(['abc'], ['abc'], all_equal)\ntest_fail(lambda: test(['abc'],['cab'], all_equal))\n\n\n\n\n\n\ndef equals(\n    a, b\n):\n\nCompares a and b for equality; supports sublists, tensors and arrays too\n\ntest([['abc'],['a']], [['abc'],['a']],  equals)\ntest([['abc'],['a'],'b', [['x']]], [['abc'],['a'],'b', [['x']]],  equals) # supports any depth and nested structure\n\n\nsource\n\n\n\n\ndef nequals(\n    a, b\n):\n\nCompares a and b for not equals\n\ntest(['abc'], ['ab' ], nequals)",
    "crumbs": [
      "Test"
    ]
  },
  {
    "objectID": "test.html#test_eq-test_ne-etc",
    "href": "test.html#test_eq-test_ne-etc",
    "title": "Test",
    "section": "test_eq test_ne, etc…",
    "text": "test_eq test_ne, etc…\nJust use test_eq/test_ne to test for ==/!=. test_eq_type checks things are equal and of the same type. We define them using test:\n\nsource\n\ntest_eq\n\ndef test_eq(\n    a, b\n):\n\ntest that a==b\n\ntest_eq([1,2],[1,2])\ntest_eq([1,2],map(int,[1,2]))\ntest_eq(array([1,2]),array([1,2]))\ntest_eq(array([1,2]),array([1,2]))\ntest_eq([array([1,2]),3],[array([1,2]),3])\ntest_eq(dict(a=1,b=2), dict(b=2,a=1))\ntest_fail(lambda: test_eq([1,2], 1), contains=\"==\")\ntest_fail(lambda: test_eq(None, np.array([1,2])), contains=\"==\")\ntest_eq({'a', 'b', 'c'}, {'c', 'a', 'b'})\n\n\ndf1 = pd.DataFrame(dict(a=[1,2],b=['a','b']))\ndf2 = pd.DataFrame(dict(a=[1,2],b=['a','b']))\ndf3 = pd.DataFrame(dict(a=[1,2],b=['a','c']))\n\ntest_eq(df1,df2)\ntest_eq(df1.a,df2.a)\ntest_fail(lambda: test_eq(df1,df3), contains='==')\nclass T(pd.Series): pass\ntest_eq(df1.iloc[0], T(df2.iloc[0])) # works with subclasses\n\n\ntest_eq(torch.zeros(10), torch.zeros(10, dtype=torch.float64))\ntest_eq(torch.zeros(10), torch.ones(10)-1)\ntest_fail(lambda:test_eq(torch.zeros(10), torch.ones(1, 10)), contains='==')\ntest_eq(torch.zeros(3), [0,0,0])\n\n\nsource\n\n\ntest_eq_type\n\ndef test_eq_type(\n    a, b\n):\n\ntest that a==b and are same type\n\ntest_eq_type(1,1)\ntest_fail(lambda: test_eq_type(1,1.))\ntest_eq_type([1,1],[1,1])\ntest_fail(lambda: test_eq_type([1,1],(1,1)))\ntest_fail(lambda: test_eq_type([1,1],[1,1.]))\n\n\nsource\n\n\ntest_ne\n\ndef test_ne(\n    a, b\n):\n\ntest that a!=b\n\ntest_ne([1,2],[1])\ntest_ne([1,2],[1,3])\ntest_ne(array([1,2]),array([1,1]))\ntest_ne(array([1,2]),array([1,1]))\ntest_ne([array([1,2]),3],[array([1,2])])\ntest_ne([3,4],array([3]))\ntest_ne([3,4],array([3,5]))\ntest_ne(dict(a=1,b=2), ['a', 'b'])\ntest_ne(['a', 'b'], dict(a=1,b=2))\n\n\nsource\n\n\nis_close\n\ndef is_close(\n    a, b, eps:float=1e-05\n):\n\nIs a within eps of b\n\nsource\n\n\ntest_close\n\ndef test_close(\n    a, b, eps:float=1e-05\n):\n\ntest that a is within eps of b\n\ntest_close(1,1.001,eps=1e-2)\ntest_fail(lambda: test_close(1,1.001))\ntest_close([-0.001,1.001], [0.,1.], eps=1e-2)\ntest_close(np.array([-0.001,1.001]), np.array([0.,1.]), eps=1e-2)\ntest_close(array([-0.001,1.001]), array([0.,1.]), eps=1e-2)\n\n\nsource\n\n\ntest_is\n\ndef test_is(\n    a, b\n):\n\ntest that a is b\n\ntest_fail(lambda: test_is([1], [1]))\na = [1]\ntest_is(a, a)\nb = [2]; test_fail(lambda: test_is(a, b))\n\n\nsource\n\n\ntest_shuffled\n\ndef test_shuffled(\n    a, b\n):\n\ntest that a and b are shuffled versions of the same sequence of items\n\na = list(range(50))\nb = copy(a)\nrandom.shuffle(b)\ntest_shuffled(a,b)\ntest_fail(lambda:test_shuffled(a,a))\n\n\na = 'abc'\nb = 'abcabc'\ntest_fail(lambda:test_shuffled(a,b))\n\n\na = ['a', 42, True] \nb = [42, True, 'a']\ntest_shuffled(a,b)\n\n\nsource\n\n\ntest_stdout\n\ndef test_stdout(\n    f, exp, regex:bool=False\n):\n\nTest that f prints exp to stdout, optionally checking as regex\n\ntest_stdout(lambda: print('hi'), 'hi')\ntest_fail(lambda: test_stdout(lambda: print('hi'), 'ho'))\ntest_stdout(lambda: 1+1, '')\ntest_stdout(lambda: print('hi there!'), r'^hi.*!$', regex=True)\n\n\nsource\n\n\ntest_warns\n\ndef test_warns(\n    f, show:bool=False\n):\n\n\ntest_warns(lambda: warnings.warn(\"Oh no!\"))\ntest_fail(lambda: test_warns(lambda: 2+2), contains='No warnings raised')\n\n\ntest_warns(lambda: warnings.warn(\"Oh no!\"), show=True)\n\n&lt;class 'UserWarning'&gt;: Oh no!\n\n\n\nim = Image.open(TEST_IMAGE).resize((128,128)); im\n\n\n\n\n\n\n\n\n\nim = Image.open(TEST_IMAGE_BW).resize((128,128)); im\n\n\n\n\n\n\n\n\n\nsource\n\n\ntest_fig_exists\n\ndef test_fig_exists(\n    ax\n):\n\nTest there is a figure displayed in ax\n\nfig,ax = plt.subplots()\nax.imshow(array(im));\n\n\n\n\n\n\n\n\n\ntest_fig_exists(ax)\n\n\nsource\n\n\nExceptionExpected\n\ndef ExceptionExpected(\n    ex:type=&lt;class 'Exception'&gt;, regex:str=''\n):\n\nContext manager that tests if an exception is raised\n\ndef _tst_1(): assert False, \"This is a test\"\ndef _tst_2(): raise SyntaxError\n\nwith ExceptionExpected(): _tst_1()\nwith ExceptionExpected(ex=AssertionError, regex=\"This is a test\"): _tst_1()\nwith ExceptionExpected(ex=SyntaxError): _tst_2()\n\nexception is an abbreviation for ExceptionExpected().\n\nwith exception: _tst_1()",
    "crumbs": [
      "Test"
    ]
  },
  {
    "objectID": "style.html",
    "href": "style.html",
    "title": "Style",
    "section": "",
    "text": "Note\n\n\n\nStyled outputs don’t show in Quarto documentation. Please use a notebook editor to correctly view this page.\n\n\n\nsource\n\nStyleCode\n\ndef StyleCode(\n    name, code, typ\n):\n\nAn escape sequence for styling terminal text.\nThe primary building block of the S API.\n\nprint(str(StyleCode('blue', 34, 'fg')) + 'hello' + str(StyleCode('default', 39, 'fg')) + ' world')\n\nhello world\n\n\n\nsource\n\n\nStyle\n\ndef Style(\n    codes:NoneType=None\n):\n\nA minimal terminal text styler.\nThe main way to use it is via the exported S object.\n\n\nExported source\nS = Style()\n\n\nWe start with an empty style:\n\nS\n\n&lt;Style: none&gt;\n\n\nDefine a new style by chaining attributes:\n\ns = S.blue.bold.underline\ns\n\n&lt;Style: blue bold underline&gt;\n\n\nYou can see a full list of available styles with auto-complete by typing S . Tab.\nApply a style by calling it with a string:\n\ns('hello world')\n\n'\\x1b[34m\\x1b[1m\\x1b[4mhello world\\x1b[22m\\x1b[24m\\x1b[39m'\n\n\nThat’s a raw string with the underlying escape sequences that tell the terminal how to format text. To see the styled version we have to print it:\n\nprint(s('hello world'))\n\nhello world\n\n\nYou can also nest styles:\n\nprint(S.bold(S.blue('key') + ' = value ') + S.light_gray(' ' + S.underline('# With a comment')) + ' and unstyled text')\n\nkey = value  # With a comment and unstyled text\n\n\n\nprint(S.blue('this '+S.bold('is')+' a test'))\n\nthis is a test\n\n\n\nsource\n\n\ndemo\n\ndef demo(\n    \n):\n\nDemonstrate all available styles and their codes.\n\ndemo()\n\n 30    black           \n 31    red             \n 32    green           \n 33    yellow          \n 34    blue            \n 35    magenta         \n 36    cyan            \n 37    light_gray      \n 39    default         \n 90    dark_gray       \n 91    light_red       \n 92    light_green     \n 93    light_yellow    \n 94    light_blue      \n 95    light_magenta   \n 96    light_cyan      \n 97    white           \n 40    black_bg        \n 41    red_bg          \n 42    green_bg        \n 43    yellow_bg       \n 44    blue_bg         \n 45    magenta_bg      \n 46    cyan_bg         \n 47    light_gray_bg   \n 49    default_bg      \n100    dark_gray_bg    \n101    light_red_bg    \n102    light_green_bg  \n103    light_yellow_bg \n104    light_blue_bg   \n105    light_magenta_bg\n106    light_cyan_bg   \n107    white_bg        \n  1    bold            \n  2    dim             \n  3    italic          \n  4    underline       \n  5    blink           \n  7    invert          \n  8    hidden          \n  9    strikethrough   \n 22    reset_bold      \n 22    reset_dim       \n 23    reset_italic    \n 24    reset_underline \n 25    reset_blink     \n 27    reset_invert    \n 28    reset_hidden    \n 29    reset_strikethrough\n  0    reset",
    "crumbs": [
      "Style"
    ]
  },
  {
    "objectID": "foundation.html",
    "href": "foundation.html",
    "title": "Foundation",
    "section": "",
    "text": "source\n\n\n\ndef working_directory(\n    path\n):\n\nChange working directory to path and return to previous on exit.\n\nsource\n\n\n\n\ndef add_docs(\n    cls, cls_doc:NoneType=None, docs:VAR_KEYWORD\n):\n\nCopy values from docs to cls docstrings, and confirm all public methods are documented\nadd_docs allows you to add docstrings to a class and its associated methods. This function allows you to group docstrings together seperate from your code, which enables you to define one-line functions as well as organize your code more succintly. We believe this confers a number of benefits which we discuss in our style guide.\nSuppose you have the following undocumented class:\n\nclass T:\n    def foo(self): pass\n    def bar(self): pass\n\nYou can add documentation to this class like so:\n\nadd_docs(T, cls_doc=\"A docstring for the class.\",\n            foo=\"The foo method.\",\n            bar=\"The bar method.\")\n\nNow, docstrings will appear as expected:\n\ntest_eq(T.__doc__, \"A docstring for the class.\")\ntest_eq(T.foo.__doc__, \"The foo method.\")\ntest_eq(T.bar.__doc__, \"The bar method.\")\n\nadd_docs also validates that all of your public methods contain a docstring. If one of your methods is not documented, it will raise an error:\n\nclass T:\n    def foo(self): pass\n    def bar(self): pass\n\nf=lambda: add_docs(T, \"A docstring for the class.\", foo=\"The foo method.\")\ntest_fail(f, contains=\"Missing docs\")\n\n\nsource\n\n\n\n\ndef docs(\n    cls\n):\n\nDecorator version of add_docs, using _docs dict\nInstead of using add_docs, you can use the decorator docs as shown below. Note that the docstring for the class can be set with the argument cls_doc:\n\n@docs\nclass _T:\n    def f(self): pass\n    def g(cls): pass\n    \n    _docs = dict(cls_doc=\"The class docstring\", \n                 f=\"The docstring for method f.\",\n                 g=\"A different docstring for method g.\")\n\n    \ntest_eq(_T.__doc__, \"The class docstring\")\ntest_eq(_T.f.__doc__, \"The docstring for method f.\")\ntest_eq(_T.g.__doc__, \"A different docstring for method g.\")\n\nFor either the docs decorator or the add_docs function, you can still define your docstrings in the normal way. Below we set the docstring for the class as usual, but define the method docstrings through the _docs attribute:\n\n@docs\nclass _T:\n    \"The class docstring\"\n    def f(self): pass\n    _docs = dict(f=\"The docstring for method f.\")\n\n    \ntest_eq(_T.__doc__, \"The class docstring\")\ntest_eq(_T.f.__doc__, \"The docstring for method f.\")\n\n\n\n\n\n\ndef is_iter(\n    o\n):\n\nTest whether o can be used in a for loop\n\nassert is_iter([1])\nassert not is_iter(array(1))\nassert is_iter(array([1,2]))\nassert (o for o in range(3))\n\n\nsource\n\n\n\n\ndef coll_repr(\n    c, max_n:int=250\n):\n\nString repr of up to max_n items of (possibly lazy) collection c\ncoll_repr is used to provide a more informative __repr__ about list-like objects. coll_repr and is used by L to build a __repr__ that displays the length of a list in addition to a preview of a list.\n\ntest_eq(coll_repr(range(1000),10), '(#1000) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9...]')\ntest_eq(coll_repr(range(1000), 5), '(#1000) [0, 1, 2, 3, 4...]')\ntest_eq(coll_repr(range(10),   5), '(#10) [0, 1, 2, 3, 4...]')\ntest_eq(coll_repr(range(5),    5), '[0, 1, 2, 3, 4]')\n\n\nsource\n\n\n\n\ndef is_bool(\n    x\n):\n\nCheck whether x is a bool or None\n\nsource\n\n\n\n\ndef mask2idxs(\n    mask\n):\n\nConvert bool mask or index list to index L\n\ntest_eq(mask2idxs([False,True,False,True]), [1,3])\ntest_eq(mask2idxs(array([False,True,False,True])), [1,3])\ntest_eq(mask2idxs(array([1,2,3])), [1,2,3])\n\n\nsource\n\n\n\n\ndef cycle(\n    o\n):\n\nLike itertools.cycle except creates list of Nones if o is empty\n\ntest_eq(itertools.islice(cycle([1,2,3]),5), [1,2,3,1,2])\ntest_eq(itertools.islice(cycle([]),3), [None]*3)\ntest_eq(itertools.islice(cycle(None),3), [None]*3)\ntest_eq(itertools.islice(cycle(1),3), [1,1,1])\n\n\nsource\n\n\n\n\ndef zip_cycle(\n    x, args:VAR_POSITIONAL\n):\n\nLike itertools.zip_longest but cycles through elements of all but first argument\n\ntest_eq(zip_cycle([1,2,3,4],list('abc')), [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'a')])\n\n\nsource\n\n\n\n\ndef is_indexer(\n    idx\n):\n\nTest whether idx will index a single item in a list\nYou can, for example index a single item in a list with an integer or a 0-dimensional numpy array:\n\nassert is_indexer(1)\nassert is_indexer(np.array(1))\n\nHowever, you cannot index into single item in a list with another list or a numpy array with ndim &gt; 0.\n\nassert not is_indexer([1, 2])\nassert not is_indexer(np.array([[1, 2], [3, 4]]))\n\n\nsource\n\n\n\n\ndef product(\n    xs\n):\n\nThe product of elements of xs, with Nones removed\n\nproduct([None, 3, 4, 5])\n\n60\n\n\n\nproduct([])\n\n1\n\n\n\nsum([])\n\n0\n\n\n\n\n\n\nsource\n\n\n\n\ndef flatmap(\n    f, xs\n):\n\nApply f to each element and flatten the results into a single list.\nflatmap is a fundamental operation in functional programming that combines mapping and flattening into a single step. Where map applies a function to each element and returns a list of results, flatmap goes further: it expects the function to return a sequence for each element, then concatenates all those sequences into one flat list, which is useful for operations where each input naturally produces zero, one, or many outputs.\nflatmap(f, xs) is just a named abstraction for the list comprehension [y for x in xs for y in f(x)]. Giving it a name makes the intent clearer and the code more readable.\n\nflatmap(range, range(4))\n\n[0, 0, 1, 0, 1, 2]\n\n\nCompare map (which nests results) with flatmap (which flattens them):\n\nlist(map(str.split, [\"hello world\", \"foo bar\"]))  # nested\n\n[['hello', 'world'], ['foo', 'bar']]\n\n\n\nflatmap(str.split, [\"hello world\", \"flatmap rocks\"])\n\n['hello', 'world', 'flatmap', 'rocks']\n\n\nCommon use cases include: parsing structured text (splitting lines into words), expanding nested data (extracting all emails from a list of contacts), filtering with transformation (keeping and transforming only valid items), and traversing hierarchies (listing files across multiple directories). The pattern elegantly handles “optional” results too—return an empty list to skip an item, or a single-element list to include it. This avoids the nested lists you’d get from map followed by a separate flatten, and expresses the intent more directly. Below we show a few examples.\nParse CSV-like lines into all values:\n\nflatmap(Self.split(','), [\"a,b,c\", \"d,e\"])\n\n['a', 'b', 'c', 'd', 'e']\n\n\nReturn [] to skip an item, [x] to keep it, or [x, y, ...] to expand it:\n\nflatmap(lambda x: [x*10] if x else [], [1, 0, 2])  # skips zeros\n\n[10, 20]\n\n\n\ndat = [{'emails': ['a@x.com','b@x.com']}, {'emails': []}, {'emails': ['c@x.com']}]\nflatmap(Self['emails'], dat)\n\n['a@x.com', 'b@x.com', 'c@x.com']\n\n\nAll files in multiple directories:\n\nflatmap(Self.iterdir(), [Path('files'), Path('images')])\n\n[Path('files/test.txt.bz2'),\n Path('images/mnist3.png'),\n Path('images/att_00000.png'),\n Path('images/att_00005.png'),\n Path('images/att_00007.png'),\n Path('images/att_00006.png'),\n Path('images/puppy.jpg')]\n\n\nPair each item with its factors:\n\ndef factpairs(n): return [(n,i) for i in range(1,n+1) if n%i==0]\nflatmap(factpairs, [6,10])\n\n[(6, 1), (6, 2), (6, 3), (6, 6), (10, 1), (10, 2), (10, 5), (10, 10)]",
    "crumbs": [
      "Foundation"
    ]
  },
  {
    "objectID": "foundation.html#foundational-functions",
    "href": "foundation.html#foundational-functions",
    "title": "Foundation",
    "section": "",
    "text": "source\n\n\n\ndef working_directory(\n    path\n):\n\nChange working directory to path and return to previous on exit.\n\nsource\n\n\n\n\ndef add_docs(\n    cls, cls_doc:NoneType=None, docs:VAR_KEYWORD\n):\n\nCopy values from docs to cls docstrings, and confirm all public methods are documented\nadd_docs allows you to add docstrings to a class and its associated methods. This function allows you to group docstrings together seperate from your code, which enables you to define one-line functions as well as organize your code more succintly. We believe this confers a number of benefits which we discuss in our style guide.\nSuppose you have the following undocumented class:\n\nclass T:\n    def foo(self): pass\n    def bar(self): pass\n\nYou can add documentation to this class like so:\n\nadd_docs(T, cls_doc=\"A docstring for the class.\",\n            foo=\"The foo method.\",\n            bar=\"The bar method.\")\n\nNow, docstrings will appear as expected:\n\ntest_eq(T.__doc__, \"A docstring for the class.\")\ntest_eq(T.foo.__doc__, \"The foo method.\")\ntest_eq(T.bar.__doc__, \"The bar method.\")\n\nadd_docs also validates that all of your public methods contain a docstring. If one of your methods is not documented, it will raise an error:\n\nclass T:\n    def foo(self): pass\n    def bar(self): pass\n\nf=lambda: add_docs(T, \"A docstring for the class.\", foo=\"The foo method.\")\ntest_fail(f, contains=\"Missing docs\")\n\n\nsource\n\n\n\n\ndef docs(\n    cls\n):\n\nDecorator version of add_docs, using _docs dict\nInstead of using add_docs, you can use the decorator docs as shown below. Note that the docstring for the class can be set with the argument cls_doc:\n\n@docs\nclass _T:\n    def f(self): pass\n    def g(cls): pass\n    \n    _docs = dict(cls_doc=\"The class docstring\", \n                 f=\"The docstring for method f.\",\n                 g=\"A different docstring for method g.\")\n\n    \ntest_eq(_T.__doc__, \"The class docstring\")\ntest_eq(_T.f.__doc__, \"The docstring for method f.\")\ntest_eq(_T.g.__doc__, \"A different docstring for method g.\")\n\nFor either the docs decorator or the add_docs function, you can still define your docstrings in the normal way. Below we set the docstring for the class as usual, but define the method docstrings through the _docs attribute:\n\n@docs\nclass _T:\n    \"The class docstring\"\n    def f(self): pass\n    _docs = dict(f=\"The docstring for method f.\")\n\n    \ntest_eq(_T.__doc__, \"The class docstring\")\ntest_eq(_T.f.__doc__, \"The docstring for method f.\")\n\n\n\n\n\n\ndef is_iter(\n    o\n):\n\nTest whether o can be used in a for loop\n\nassert is_iter([1])\nassert not is_iter(array(1))\nassert is_iter(array([1,2]))\nassert (o for o in range(3))\n\n\nsource\n\n\n\n\ndef coll_repr(\n    c, max_n:int=250\n):\n\nString repr of up to max_n items of (possibly lazy) collection c\ncoll_repr is used to provide a more informative __repr__ about list-like objects. coll_repr and is used by L to build a __repr__ that displays the length of a list in addition to a preview of a list.\n\ntest_eq(coll_repr(range(1000),10), '(#1000) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9...]')\ntest_eq(coll_repr(range(1000), 5), '(#1000) [0, 1, 2, 3, 4...]')\ntest_eq(coll_repr(range(10),   5), '(#10) [0, 1, 2, 3, 4...]')\ntest_eq(coll_repr(range(5),    5), '[0, 1, 2, 3, 4]')\n\n\nsource\n\n\n\n\ndef is_bool(\n    x\n):\n\nCheck whether x is a bool or None\n\nsource\n\n\n\n\ndef mask2idxs(\n    mask\n):\n\nConvert bool mask or index list to index L\n\ntest_eq(mask2idxs([False,True,False,True]), [1,3])\ntest_eq(mask2idxs(array([False,True,False,True])), [1,3])\ntest_eq(mask2idxs(array([1,2,3])), [1,2,3])\n\n\nsource\n\n\n\n\ndef cycle(\n    o\n):\n\nLike itertools.cycle except creates list of Nones if o is empty\n\ntest_eq(itertools.islice(cycle([1,2,3]),5), [1,2,3,1,2])\ntest_eq(itertools.islice(cycle([]),3), [None]*3)\ntest_eq(itertools.islice(cycle(None),3), [None]*3)\ntest_eq(itertools.islice(cycle(1),3), [1,1,1])\n\n\nsource\n\n\n\n\ndef zip_cycle(\n    x, args:VAR_POSITIONAL\n):\n\nLike itertools.zip_longest but cycles through elements of all but first argument\n\ntest_eq(zip_cycle([1,2,3,4],list('abc')), [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'a')])\n\n\nsource\n\n\n\n\ndef is_indexer(\n    idx\n):\n\nTest whether idx will index a single item in a list\nYou can, for example index a single item in a list with an integer or a 0-dimensional numpy array:\n\nassert is_indexer(1)\nassert is_indexer(np.array(1))\n\nHowever, you cannot index into single item in a list with another list or a numpy array with ndim &gt; 0.\n\nassert not is_indexer([1, 2])\nassert not is_indexer(np.array([[1, 2], [3, 4]]))\n\n\nsource\n\n\n\n\ndef product(\n    xs\n):\n\nThe product of elements of xs, with Nones removed\n\nproduct([None, 3, 4, 5])\n\n60\n\n\n\nproduct([])\n\n1\n\n\n\nsum([])\n\n0\n\n\n\n\n\n\nsource\n\n\n\n\ndef flatmap(\n    f, xs\n):\n\nApply f to each element and flatten the results into a single list.\nflatmap is a fundamental operation in functional programming that combines mapping and flattening into a single step. Where map applies a function to each element and returns a list of results, flatmap goes further: it expects the function to return a sequence for each element, then concatenates all those sequences into one flat list, which is useful for operations where each input naturally produces zero, one, or many outputs.\nflatmap(f, xs) is just a named abstraction for the list comprehension [y for x in xs for y in f(x)]. Giving it a name makes the intent clearer and the code more readable.\n\nflatmap(range, range(4))\n\n[0, 0, 1, 0, 1, 2]\n\n\nCompare map (which nests results) with flatmap (which flattens them):\n\nlist(map(str.split, [\"hello world\", \"foo bar\"]))  # nested\n\n[['hello', 'world'], ['foo', 'bar']]\n\n\n\nflatmap(str.split, [\"hello world\", \"flatmap rocks\"])\n\n['hello', 'world', 'flatmap', 'rocks']\n\n\nCommon use cases include: parsing structured text (splitting lines into words), expanding nested data (extracting all emails from a list of contacts), filtering with transformation (keeping and transforming only valid items), and traversing hierarchies (listing files across multiple directories). The pattern elegantly handles “optional” results too—return an empty list to skip an item, or a single-element list to include it. This avoids the nested lists you’d get from map followed by a separate flatten, and expresses the intent more directly. Below we show a few examples.\nParse CSV-like lines into all values:\n\nflatmap(Self.split(','), [\"a,b,c\", \"d,e\"])\n\n['a', 'b', 'c', 'd', 'e']\n\n\nReturn [] to skip an item, [x] to keep it, or [x, y, ...] to expand it:\n\nflatmap(lambda x: [x*10] if x else [], [1, 0, 2])  # skips zeros\n\n[10, 20]\n\n\n\ndat = [{'emails': ['a@x.com','b@x.com']}, {'emails': []}, {'emails': ['c@x.com']}]\nflatmap(Self['emails'], dat)\n\n['a@x.com', 'b@x.com', 'c@x.com']\n\n\nAll files in multiple directories:\n\nflatmap(Self.iterdir(), [Path('files'), Path('images')])\n\n[Path('files/test.txt.bz2'),\n Path('images/mnist3.png'),\n Path('images/att_00000.png'),\n Path('images/att_00005.png'),\n Path('images/att_00007.png'),\n Path('images/att_00006.png'),\n Path('images/puppy.jpg')]\n\n\nPair each item with its factors:\n\ndef factpairs(n): return [(n,i) for i in range(1,n+1) if n%i==0]\nflatmap(factpairs, [6,10])\n\n[(6, 1), (6, 2), (6, 3), (6, 6), (10, 1), (10, 2), (10, 5), (10, 10)]",
    "crumbs": [
      "Foundation"
    ]
  },
  {
    "objectID": "foundation.html#l-helpers",
    "href": "foundation.html#l-helpers",
    "title": "Foundation",
    "section": "L helpers",
    "text": "L helpers\n\nsource\n\nCollBase\n\ndef CollBase(\n    items\n):\n\nBase class for composing a list of items\nColBase is a base class that emulates the functionality of a python list:\n\nclass _T(CollBase): pass\nl = _T([1,2,3,4,5])\n\ntest_eq(len(l), 5) # __len__\ntest_eq(l[-1], 5); test_eq(l[0], 1) #__getitem__\nl[2] = 100; test_eq(l[2], 100)      # __set_item__\ndel l[0]; test_eq(len(l), 4)        # __delitem__\ntest_eq(str(l), '[2, 100, 4, 5]')   # __repr__\n\n\nsource\n\n\nL\n\ndef L(\n    items:NoneType=None, rest:VAR_POSITIONAL, use_list:bool=False, match:NoneType=None\n):\n\nBehaves like a list of items but can also index with list of indices or masks\nL is a drop in replacement for a python list. Inspired by NumPy, L, supports advanced indexing and has additional methods (outlined below) that provide additional functionality and encourage simple expressive code.\n\n\nExamples and overview\n\nfrom fastcore.utils import gt\n\nRead this overview section for a quick tutorial of L, as well as background on the name.\nYou can create an L from an existing iterable (e.g. a list, range, etc) and access or modify it with an int list/tuple index, mask, int, or slice. All list methods can also be used with L.\n\nt = L(range(12))\ntest_eq(t, list(range(12)))\ntest_ne(t, list(range(11)))\nt[3] = \"h\"\ntest_eq(t[3], \"h\")\nt[3,5] = (\"j\",\"k\")\ntest_eq(t[3,5], [\"j\",\"k\"])\ntest_eq(t, L(t))\ntest_eq(L(L(1,2),[3,4]), ([1,2],[3,4]))\nt[0:3] = [1, 2, 3]\ntest_eq(t[0:3], [1, 2, 3])\nt\n\n[1, 2, 3, 'j', 4, 'k', 6, 7, 8, 9, 10, 11]\n\n\nAny L is a Sequence so you can use it with methods like random.sample:\n\nassert isinstance(t, Sequence)\n\n\nimport random\n\n\nrandom.seed(0)\nrandom.sample(t, 3)\n\n[6, 11, 1]\n\n\nThere are optimized indexers for arrays, tensors, and DataFrames.\n\nimport pandas as pd\n\n\narr = np.arange(9).reshape(3,3)\nt = L(arr, use_list=None)\ntest_eq(t[1,2], arr[[1,2]])\n\ndf = pd.DataFrame({'a':[1,2,3]})\nt = L(df, use_list=None)\ntest_eq(t[1,2], L(pd.DataFrame({'a':[2,3]}, index=[1,2]), use_list=None))\n\nYou can also modify an L with append, +, and *.\n\nt = L()\ntest_eq(t, [])\nt.append(1)\ntest_eq(t, [1])\nt += [3,2]\ntest_eq(t, [1,3,2])\nt = t + [4]\ntest_eq(t, [1,3,2,4])\nt = 5 + t\ntest_eq(t, [5,1,3,2,4])\ntest_eq(L(1,2,3), [1,2,3])\ntest_eq(L(1,2,3), L(1,2,3))\nt = L(1)*5\ntest_eq(~L([True,False,False]), L([False,True,True]))\n\nAn L can be constructed from anything iterable, although tensors and arrays will not be iterated over on construction, unless you pass use_list to the constructor.\n\ntest_eq(L([1,2,3]),[1,2,3])\ntest_eq(L(L([1,2,3])),[1,2,3])\ntest_ne(L([1,2,3]),[1,2,])\ntest_eq(L('abc'),['abc'])\ntest_eq(L(range(0,3)),[0,1,2])\ntest_eq(L(o for o in range(0,3)),[0,1,2])\ntest_eq(L(array(0)),[array(0)])\ntest_eq(L([array(0),array(1)]),[array(0),array(1)])\ntest_eq(L(array([0.,1.1]))[0],array([0.,1.1]))\ntest_eq(L(array([0.,1.1]), use_list=True), [array(0.),array(1.1)])  # `use_list=True` to unwrap arrays/arrays\n\nIf match is not None then the created list is same len as match, either by:\n\nIf len(items)==1 then items is replicated,\nOtherwise an error is raised if match and items are not already the same size.\n\n\ntest_eq(L(1,match=[1,2,3]),[1,1,1])\ntest_eq(L([1,2],match=[2,3]),[1,2])\ntest_fail(lambda: L([1,2],match=[1,2,3]))\n\nIf you create an L from an existing L then you’ll get back the original object (since L uses the NewChkMeta metaclass).\n\ntest_is(L(t), t)\n\nAn L is considred equal to a list if they have the same elements. It’s never considered equal to a str a set or a dict even if they have the same elements/keys.\n\ntest_eq(L(['a', 'b']), ['a', 'b'])\ntest_ne(L(['a', 'b']), 'ab')\ntest_ne(L(['a', 'b']), {'a':1, 'b':2})\n\n\n\nL Methods\n\nsource\n\n\nL.__getitem__\n\ndef __getitem__(\n    idx\n):\n\nRetrieve idx (can be list of indices, or mask, or int) items\n\nt = L(range(12))\ntest_eq(t[1,2], [1,2])                # implicit tuple\ntest_eq(t[[1,2]], [1,2])              # list\ntest_eq(t[:3], [0,1,2])               # slice\ntest_eq(t[[False]*11 + [True]], [11]) # mask\ntest_eq(t[array(3)], 3)\n\n\nsource\n\n\nL.__setitem__\n\ndef __setitem__(\n    idx, o\n):\n\nSet idx (can be list of indices, or mask, or int) items to o (which is broadcast if not iterable)\n\nt[4,6] = 0\ntest_eq(t[4,6], [0,0])\nt[4,6] = [1,2]\ntest_eq(t[4,6], [1,2])\n\n\nsource\n\n\nL.unique\n\ndef unique(\n    sort:bool=False, bidir:bool=False, start:NoneType=None\n):\n\nUnique items, in stable order\n\ntest_eq(L(4,1,2,3,4,4).unique(), [4,1,2,3])\n\n\nsource\n\n\nL.val2idx\n\ndef val2idx(\n    \n):\n\nDict from value to index\n\ntest_eq(L(1,2,3).val2idx(), {3:2,1:0,2:1})\n\n\nsource\n\n\nL.range\n\ndef range(\n    a, b:NoneType=None, step:NoneType=None\n):\n\nClass Method: Same as range, but returns L. Can pass collection for a, to use len(a)\n\ntest_eq_type(L.range([1,1,1]), L(range(3)))\ntest_eq_type(L.range(5,2,2), L(range(5,2,2)))\n\n\nsource\n\n\nL.enumerate\n\ndef enumerate(\n    \n):\n\nSame as enumerate\n\ntest_eq(L('a','b','c').enumerate(), [(0,'a'),(1,'b'),(2,'c')])\n\n\nsource\n\n\nL.renumerate\n\ndef renumerate(\n    \n):\n\nSame as renumerate\n\ntest_eq(L('a','b','c').renumerate(), [('a', 0), ('b', 1), ('c', 2)])\n\n\nsource\n\n\nL.split\n\ndef split(\n    s, sep:NoneType=None, maxsplit:int=-1\n):\n\nClass Method: Same as str.split, but returns an L\nL.split is a class method that works like str.split, but returns an L instead of a list:\n\ntest_eq(L.split('a b c'), ['a','b','c'])\ntest_eq(L.split('a-b-c', '-'), ['a','b','c'])\ntest_eq(L.split('a-b-c', '-', maxsplit=1), ['a','b-c'])\n\n\nsource\n\n\nL.splitlines\n\ndef splitlines(\n    s, keepends:bool=False\n):\n\nClass Method: Same as str.splitlines, but returns an L\nL.splitlines is a class method that works like str.splitlines, but returns an L instead of a list:\n\ntest_eq(L.splitlines('a\\nb\\nc'), ['a','b','c'])\ntest_eq(L.splitlines('a\\nb\\nc', keepends=True), ['a\\n','b\\n','c'])\n\n\nsource\n\n\ncurryable\n\ndef curryable(\n    f\n):\n\nThe curryable decorator enables a powerful pattern: methods decorated with it can be called either as instance methods (the normal way) or as class methods that return a partial function.\nFor instance, consider processing nested data structures. Without curryable, you’d write:\nL(lines).map(lambda x: L(x).map(int))\nWith curryable, you can write:\nL(lines).map(L.map(int))\nWhen you call L.map(int) on the class (not an instance), the decorator returns a functools.partial that waits for an iterable to be passed in later.\nThis pattern is especially valuable for data parsing pipelines where you’re frequently mapping transformations over nested structures. The curried form reads more naturally and composes well with other curried functions like splitter() and linesplitter().\n\n\n\nmap\n\ndef map(\n    f, args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nCreate new L with f applied to all items, passing args and kwargs to f\n\ntest_eq(L.range(4).map(operator.neg), [0,-1,-2,-3])\n\nIf f is a string then it is treated as a format string to create the mapping:\n\ntest_eq(L.range(4).map('#{}#'), ['#0#','#1#','#2#','#3#'])\n\nIf f is a dictionary (or anything supporting __getitem__) then it is indexed to create the mapping:\n\ntest_eq(L.range(4).map(list('abcd')), list('abcd'))\n\nYou can also pass the same arg params that bind accepts:\n\ndef f(a=None,b=None): return b\ntest_eq(L.range(4).map(f, b=arg0), range(4))\n\n\nsource\n\n\nsplitter\n\ndef splitter(\n    sep:NoneType=None, maxsplit:int=-1\n):\n\nCreate a partial function that splits strings into L\nA curried version of L.split, useful for mapping over collections of strings. For instance to split some lines with the same separator:\n\ndata = '''1,2,3\n4,5,6\n7,8,9'''\n\ngrid = L.splitlines(data).map(splitter(','))\ngrid\n\n[['1', '2', '3'], ['4', '5', '6'], ['7', '8', '9']]\n\n\nAs mentioned in the curryable discussion, map can be curried. This can work well together with L.splitlines output:\n\nintgrid = grid.map(L.map(int))\nintgrid\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n\nAlthough in this particular example numpy has a useful shortcut:\n\nnp.genfromtxt(data.splitlines(), delimiter=',', dtype=int)\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\n\nsource\n\n\nlinesplitter\n\ndef linesplitter(\n    keepends:bool=False\n):\n\nCreate a partial function that splits strings by lines into L\nA curried version of L.splitlines, useful for splitting multi-line strings into Ls when mapping over a collection.\n\nL(['a\\nb\\nc', 'd\\ne']).map(linesplitter())\n\n[['a', 'b', 'c'], ['d', 'e']]\n\n\n\nsource\n\n\ngroupby\n\ndef groupby(\n    key, val:function=&lt;function noop at 0x7f158aa50d60&gt;\n):\n\nSame as fastcore.basics.groupby\n\nwords = L.split('aaa abc bba')\ntest_eq(words.groupby(0, (1,2)), {'a':[('a','a'),('b','c')], 'b':[('b','a')]})\n\nL.groupby can also be used in curried form, which is useful when you need to apply the same grouping operation across multiple collections.\n\nL([['a1','b2','a3'], ['x1','y2','x3']]).map(L.groupby(0))\n\n[{'a': ['a1', 'a3'], 'b': ['b2']}, {'x': ['x1', 'x3'], 'y': ['y2']}]\n\n\n\n\n\nstarmap\n\ndef starmap(\n    f, args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nLike map, but use itertools.starmap\nL.starmap applies a function to each element, unpacking tuples as arguments:\n\ntest_eq(L([(1,2),(3,4)]).starmap(operator.add), [3,7])\ntest_eq(L([(1,2,3),(4,5,6)]).starmap(lambda a,b,c: a+b*c), [7,34])\n\nThe curried form of L.starmap is useful when you need to apply the same starmap operation across nested structures. For example, when you have a list of lists of tuples and want to apply a function that unpacks each tuple:\n\nnested = L([[(1,2),(3,4)], [(5,6),(7,8)]])\nnested.map(L.starmap(operator.mul))\n\n[[2, 12], [30, 56]]\n\n\n\n\n\nrstarmap\n\ndef rstarmap(\n    f, args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nLike starmap, but reverse the order of args\nL.rstarmap is like starmap, but reverses the order of unpacked arguments:\n\ntest_eq(L((1,2),(3,4)).rstarmap(operator.sub), [1,1])  # 2-1, 4-3\ntest_eq(L(('a','b'),('c','d')).rstarmap('{}{}'.format), ['ba','dc'])\n\nThe curried form of L.rstarmap is useful when mapping over nested structures where you need reversed argument order. This commonly occurs when processing pairs where the second element should be the first argument to a function:\n\nnested = L([[('x',1),('y',2)], [('z',3)]])\nnested.map(L.rstarmap('{}{}'.format))\n\n[['1x', '2y'], ['3z']]\n\n\n\nsource\n\n\nL.map_dict\n\ndef map_dict(\n    f:function=&lt;function noop at 0x7f158aa50d60&gt;, args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nLike map, but creates a dict from items to function results\n\ntest_eq(L(range(1,5)).map_dict(), {1:1, 2:2, 3:3, 4:4})\ntest_eq(L(range(1,5)).map_dict(operator.neg), {1:-1, 2:-2, 3:-3, 4:-4})\n\n\nsource\n\n\nL.zip\n\ndef zip(\n    cycled:bool=False\n):\n\nCreate new L with zip(*items)\n\nt = L([[1,2,3],'abc'])\ntest_eq(t.zip(), [(1, 'a'),(2, 'b'),(3, 'c')])\n\n\nt = L([[1,2,3,4],['a','b','c']])\ntest_eq(t.zip(cycled=True ), [(1, 'a'),(2, 'b'),(3, 'c'),(4, 'a')])\ntest_eq(t.zip(cycled=False), [(1, 'a'),(2, 'b'),(3, 'c')])\n\n\nsource\n\n\nL.map_zip\n\ndef map_zip(\n    f, args:VAR_POSITIONAL, cycled:bool=False, kwargs:VAR_KEYWORD\n):\n\nCombine zip and starmap\n\nt = L([1,2,3],[2,3,4])\ntest_eq(t.map_zip(operator.mul), [2,6,12])\n\n\nsource\n\n\nL.zipwith\n\ndef zipwith(\n    rest:VAR_POSITIONAL, cycled:bool=False\n):\n\nCreate new L with self zip with each of *rest\n\nb = [[0],[1],[2,2]]\nt = L([1,2,3]).zipwith(b)\ntest_eq(t, [(1,[0]), (2,[1]), (3,[2,2])])\n\n\nsource\n\n\nL.map_zipwith\n\ndef map_zipwith(\n    f, rest:VAR_POSITIONAL, cycled:bool=False, kwargs:VAR_KEYWORD\n):\n\nCombine zipwith and starmap\n\ntest_eq(L(1,2,3).map_zipwith(operator.mul, [2,3,4]), [2,6,12])\n\n\n\n\nfilter\n\ndef filter(\n    f:function=&lt;function noop at 0x7f158aa50d60&gt;, negate:bool=False, kwargs:VAR_KEYWORD\n):\n\nCreate new L filtered by predicate f, passing args and kwargs to f\n\nt = L(range(12))\ntest_eq(t.filter(lambda o:o&lt;5), [0,1,2,3,4])\ntest_eq(t.filter(lambda o:o&lt;5, negate=True), [5,6,7,8,9,10,11])\n\nL.filter can be used as a curried class method, returning a partial that filters any iterable and wraps the result in an L. This is useful when mapping a filter operation over nested collections.\n\nintgrid\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n\n\nintgrid.map(L.filter(ge(5)))\n\n[[], [5, 6], [7, 8, 9]]\n\n\n\n\n\nstarfilter\n\ndef starfilter(\n    f, negate:bool=False, kwargs:VAR_KEYWORD\n):\n\nLike filter, but unpacks elements as args to f\nL.starfilter is like filter, but unpacks tuple elements as arguments to the predicate:\n\ntest_eq(L((1,2),(3,1),(2,3)).starfilter(lt), [(1,2),(2,3)])\ntest_eq(L((1,2),(3,1),(2,3)).starfilter(lt, negate=True), [(3,1)])\n\nCurried L.starfilter is useful when mapping a starfilter operation over nested collections—each inner collection gets filtered by unpacking its tuples as arguments to the predicate, eg to filter pairs where first &lt; second, across multiple lists of pairs:\n\nnested = L([[(1,5),(3,2)], [(4,6),(9,1)]])\nnested.map(L.starfilter(lt))\n\n[[(1, 5)], [(4, 6)]]\n\n\n\n\n\nrstarfilter\n\ndef rstarfilter(\n    f, negate:bool=False, kwargs:VAR_KEYWORD\n):\n\nLike starfilter, but reverse the order of args\nL.rstarfilter is like starfilter, but reverses the order of unpacked arguments (and can also be curried):\n\ntest_eq(L((2,1),(1,3),(3,2)).rstarfilter(lt), [(2,1),(3,2)])  # 1&lt;2, 3&lt;1 fails, 2&lt;3\ntest_eq(L((2,1),(1,3),(3,2)).rstarfilter(lt, negate=True), [(1,3)])\n\n\nsource\n\n\nargwhere\n\ndef argwhere(\n    f, negate:bool=False, kwargs:VAR_KEYWORD\n):\n\nLike filter, but return indices for matching items\n\nt = L([0,1,2,3,4,99,0])\ntest_eq(t.argwhere(lambda o:o&lt;5), [0,1,2,3,4,6])\n\n\n\n\nstarargwhere\n\ndef starargwhere(\n    f, negate:bool=False\n):\n\nLike argwhere, but unpacks elements as args to f\nL.starargwhere is like argwhere, but unpacks tuple elements as arguments to the predicate (it is also curryable):\n\ntest_eq(L((1,2),(3,1),(2,3)).starargwhere(lt), [0,2])\ntest_eq(L((1,2),(3,1),(2,3)).starargwhere(lt, negate=True), [1])\n\n\n\n\nrstarargwhere\n\ndef rstarargwhere(\n    f, negate:bool=False\n):\n\nLike starargwhere, but reverse the order of args\nL.rstarargwhere is like starargwhere, but reverses the order of unpacked arguments (it is also curryable):\n\ntest_eq(L((2,1),(1,3),(3,2)).rstarargwhere(lt), [0,2])  # 1&lt;2, 3&lt;1 fails, 2&lt;3\ntest_eq(L((2,1),(1,3),(3,2)).rstarargwhere(lt, negate=True), [1])\n\n\n\n\nargfirst\n\ndef argfirst(\n    f, negate:bool=False\n):\n\nReturn index of first matching item\n\ntest_eq(t.argfirst(lambda o:o&gt;4), 5)\ntest_eq(t.argfirst(lambda o:o&gt;4,negate=True),0)\n\nCurried L.argfirst returns a partial function that finds the index of the first matching item in any iterable. This is useful when mapping over nested collections to find the first match in each.\n\nnested = L([[1,2,8,4], [5,9,7], [1,1,1]])\nnested.map(L.argfirst(gt(5)))\n\n[2, 1, None]\n\n\n\n\n\nstarargfirst\n\ndef starargfirst(\n    f, negate:bool=False\n):\n\nLike argfirst, but unpacks elements as args to f\nL.starargfirst is like argfirst, but unpacks tuple elements as arguments to the predicate (and is curryable):\n\ntest_eq(L((3,1),(1,2),(2,3)).starargfirst(lt), 1)\ntest_eq(L((1,2),(3,1),(2,3)).starargfirst(lt, negate=True), 1)\n\n\n\n\nrstarargfirst\n\ndef rstarargfirst(\n    f, negate:bool=False\n):\n\nLike starargfirst, but reverse the order of args\nL.rstarargfirst is like starargfirst, but reverses the order of unpacked arguments (and is curryable):\n\ntest_eq(L((1,3),(2,1),(3,2)).rstarargfirst(lt), 1)  # 3&lt;1 fails, 1&lt;2\ntest_eq(L((2,1),(1,3),(3,2)).rstarargfirst(lt, negate=True), 1)\n\n\nsource\n\n\nL.itemgot\n\ndef itemgot(\n    idxs:VAR_POSITIONAL\n):\n\nCreate new L with item idx of all items\n\nt = L([['x', [0]], ['y', [1]], ['z', [2,2]]])\ntest_eq(t.itemgot(1), b)\n\n\nsource\n\n\nL.attrgot\n\ndef attrgot(\n    k, default:NoneType=None\n):\n\nCreate new L with attr k (or value k for dicts) of all items.\n\n# Example when items are not a dict\na = [SimpleNamespace(a=3,b=4),SimpleNamespace(a=1,b=2)]\ntest_eq(L(a).attrgot('b'), [4,2])\n\n#Example of when items are a dict\nb =[{'id': 15, 'name': 'nbdev'}, {'id': 17, 'name': 'fastcore'}]\ntest_eq(L(b).attrgot('id'), [15, 17])\n\n\n\n\nsorted\n\ndef sorted(\n    key:NoneType=None, reverse:bool=False, cmp:NoneType=None, kwargs:VAR_KEYWORD\n):\n\nNew L sorted by key, using sort_ex. If key is str use attrgetter; if int use itemgetter\n\ntest_eq(L(a).sorted('a').attrgot('b'), [2,4])\n\nCurried L.sorted returns a partial function that sorts any iterable by the given key. This is useful when mapping a sort operation over nested collections—each inner collection gets sorted independently using the same key.\n\nnested = L([[(3,'c'),(1,'a'),(2,'b')], [(6,'f'),(4,'d')]])\nnested.map(L.sorted(0))\n\n[[(1, 'a'), (2, 'b'), (3, 'c')], [(4, 'd'), (6, 'f')]]\n\n\n\n\n\nstarsorted\n\ndef starsorted(\n    key, reverse:bool=False\n):\n\nLike sorted, but unpacks elements as args to key\nL.starsorted is like sorted, but unpacks tuple elements as arguments to the key function:\n\ntest_eq(L((3,1),(1,2),(2,0)).starsorted(operator.sub), [(1,2),(3,1),(2,0)])  # sorted by a-b: 2, 2, -1\ntest_eq(L((1,2),(3,1),(2,3)).starsorted(operator.add), [(1,2),(3,1),(2,3)])  # sorted by a+b: 3, 4, 5\n\n\n\n\nrstarsorted\n\ndef rstarsorted(\n    key, reverse:bool=False\n):\n\nLike starsorted, but reverse the order of args\nL.rstarsorted is like starsorted, but reverses the order of unpacked arguments:\n\ntest_eq(L((1,3),(2,1),(0,2)).rstarsorted(operator.sub), [(2,1),(1,3),(0,2)])  # sorted by b-a: 0, 2, 2\ntest_eq(L((2,1),(1,3),(3,2)).rstarsorted(operator.sub), [(2,1),(3,2),(1,3)])  # sorted by b-a: -1, -1, 2\n\n\nsource\n\n\nL.concat\n\ndef concat(\n    \n):\n\nConcatenate all elements of list\n\ntest_eq(L([0,1,2,3],4,L(5,6)).concat(), range(7))\n\n\nsource\n\n\nL.copy\n\ndef copy(\n    \n):\n\nSame as list.copy, but returns an L\n\nt = L([0,1,2,3],4,L(5,6)).copy()\ntest_eq(t.concat(), range(7))\n\n\nsource\n\n\nL.shuffle\n\ndef shuffle(\n    \n):\n\nSame as random.shuffle, but not inplace\nL.shuffle returns a new shuffled L, leaving the original unchanged:\n\nt = L(1,2,3,4,5)\ns = t.shuffle()\ntest_eq(set(s), set(t))  # same elements\ntest_eq(t, [1,2,3,4,5])  # original unchanged\n\n\n\n\nreduce\n\ndef reduce(\n    f, initial:NoneType=None\n):\n\nWrapper for functools.reduce\n\ntest_eq(L(1,2,3,4).reduce(operator.add), 10)\ntest_eq(L(1,2,3,4).reduce(operator.mul, 10), 240)\n\nCurried L.reduce returns a partial function that reduces any iterable using the given function. This is useful when mapping a reduction over nested collections—each inner collection gets reduced independently using the same operation.\n\nnested = L([[1,2,3], [4,5], [6,7,8,9]])\nnested.map(L.reduce(operator.add))\n\n[6, 9, 30]\n\n\n\n\n\nstarreduce\n\ndef starreduce(\n    f, initial:NoneType=None\n):\n\nLike reduce, but unpacks elements as args to f\nL.starreduce is like reduce, but unpacks tuple elements as additional arguments to f (after accumulator):\n\ntest_eq(L((1,2),(3,4),(5,6)).starreduce(lambda acc,a,b: acc+a*b, 0), 44)  # 0+1*2+3*4+5*6\ntest_eq(L(('a',1),('b',2)).starreduce(lambda acc,k,v: {**acc, k:v}, {}), {'a':1,'b':2})\n\nE.g implement a dot product:\n\ndef dot(a,b): return a.zipwith(b).starreduce(lambda acc,a,b: acc+a*b, 0)\ndot(L(1,3,5), L(2,4,6))\n\n44\n\n\n\n\n\nrstarreduce\n\ndef rstarreduce(\n    f, initial:NoneType=None\n):\n\nLike starreduce, but reverse the order of unpacked args\nL.rstarreduce is like starreduce, but reverses the order of unpacked arguments:\n\nsource\n\n\nL.sum\n\ndef sum(\n    \n):\n\nSum of the items\n\ntest_eq(L(1,2,3,4).sum(), 10)\ntest_eq(L().sum(), 0)\n\n\nsource\n\n\nL.product\n\ndef product(\n    \n):\n\nProduct of the items\n\ntest_eq(L(1,2,3,4).product(), 24)\ntest_eq(L().product(), 1)\n\n\nsource\n\n\nL.map_first\n\ndef map_first(\n    f:function=&lt;function noop at 0x7f158aa50d60&gt;, g:function=&lt;function noop at 0x7f158aa50d60&gt;, args:VAR_POSITIONAL,\n    kwargs:VAR_KEYWORD\n):\n\nFirst element of map_filter\n\nt = L(0,1,2,3)\ntest_eq(t.map_first(lambda o:o*2 if o&gt;2 else None), 6)\n\n\nsource\n\n\nL.setattrs\n\ndef setattrs(\n    attr, val\n):\n\nCall setattr on all items\n\nt = L(SimpleNamespace(),SimpleNamespace())\nt.setattrs('foo', 'bar')\ntest_eq(t.attrgot('foo'), ['bar','bar'])\n\n\nsource\n\n\nL.flatmap\n\ndef flatmap(\n    f\n):\n\nApply f to each element and flatten the results into a single L.\nL.flatmap is the method version of the flatmap function, allowing you to call it directly on an L instance. It applies a function to each element and flattens the results into a single L. This is useful for operations where each input naturally produces zero, one, or many outputs.\n\ntest_eq(L(\"a,b,c\", \"d,e\").flatmap(Self.split(',')), ['a', 'b', 'c', 'd', 'e'])\n\nAs an alternative, you can just chain map and concat:\n\nL(\"a,b,c\", \"d,e\").map(Self.split(',')).concat()\n\n['a', 'b', 'c', 'd', 'e']\n\n\n\n\nitertools wrappers\n\nsource\n\n\nL.cycle\n\ndef cycle(\n    \n):\n\nSame as itertools.cycle\nL.cycle returns an infinite iterator that cycles through the elements:\n\ntest_eq(list(itertools.islice(L(1,2,3).cycle(), 7)), [1,2,3,1,2,3,1])\n\n\n\n\ntakewhile\n\ndef takewhile(\n    f\n):\n\nSame as itertools.takewhile\nL.takewhile returns elements from the beginning of the list while the predicate is true:\n\ntest_eq(L(1,2,3,4,5,1,2).takewhile(lambda x: x&lt;4), [1,2,3])\ntest_eq(L(1,2,3,11).takewhile(lt(10)), [1,2,3])\n\nCurried L.takewhile returns a partial function that takes elements from the beginning of any iterable while the predicate holds. This is useful when mapping over nested collections—each inner collection gets truncated at the first failing element using the same predicate.\n\nnested = L([[1,2,5,3], [2,3,8,1], [9,1,2]])\nnested.map(L.takewhile(lt(5)))\n\n[[1, 2], [2, 3], []]\n\n\n\n\n\ndropwhile\n\ndef dropwhile(\n    f\n):\n\nSame as itertools.dropwhile\nL.dropwhile skips elements from the beginning while the predicate is true, then returns the rest:\n\ntest_eq(L(1,2,3,4,5,1,2).dropwhile(lt(4)), [4,5,1,2])\ntest_eq(L(1,2,3).dropwhile(lt(10)), [])\n\n\n\n\nstartakewhile\n\ndef startakewhile(\n    f\n):\n\nLike takewhile, but unpacks elements as args to f\nL.startakewhile is like takewhile, but unpacks tuple elements as arguments to the predicate:\n\ntest_eq(L((1,2),(2,3),(4,1),(5,6)).startakewhile(lambda a,b: a&lt;b), [(1,2),(2,3)])\ntest_eq(L((1,10),(2,20),(5,3)).startakewhile(lt), [(1,10),(2,20)])\n\n\nnested = L([[(1,5),(2,6),(7,3)], [(0,1),(2,1),(3,9)]])\nnested.map(L.startakewhile(lt))\n\n[[(1, 5), (2, 6)], [(0, 1)]]\n\n\n\n\n\nrstartakewhile\n\ndef rstartakewhile(\n    f\n):\n\nLike startakewhile, but reverse the order of args\nL.rstartakewhile is like startakewhile, but reverses the order of unpacked arguments:\n\ntest_eq(L((2,1),(3,2),(1,4),(6,5)).rstartakewhile(lt), [(2,1),(3,2)])  # 1&lt;2, 2&lt;3, 4&lt;1 fails\ntest_eq(L((10,1),(20,2),(3,5)).rstartakewhile(lt), [(10,1),(20,2)])  # 1&lt;10, 2&lt;20, 5&lt;3 fails\n\n\n\n\nstardropwhile\n\ndef stardropwhile(\n    f\n):\n\nLike dropwhile, but unpacks elements as args to f\nL.stardropwhile is like dropwhile, but unpacks tuple elements as arguments to the predicate:\n\ntest_eq(L((1,2),(2,3),(4,1),(5,6)).stardropwhile(lambda a,b: a&lt;b), [(4,1),(5,6)])\ntest_eq(L((1,10),(2,20),(5,3)).stardropwhile(lt), [(5,3)])\n\n\n\n\nrstardropwhile\n\ndef rstardropwhile(\n    f\n):\n\nLike stardropwhile, but reverse the order of args\nL.rstardropwhile is like stardropwhile, but reverses the order of unpacked arguments:\n\ntest_eq(L((2,1),(3,2),(1,4),(6,5)).rstardropwhile(lt), [(1,4),(6,5)])  # 1&lt;2, 2&lt;3 pass, 4&lt;1 fails\ntest_eq(L((10,1),(20,2),(3,5)).rstardropwhile(lt), [(3,5)])\n\n\n\n\naccumulate\n\ndef accumulate(\n    f:builtin_function_or_method=&lt;built-in function add&gt;, initial:NoneType=None\n):\n\nSame as itertools.accumulate\nL.accumulate returns running totals (or running results of any binary function):\n\ntest_eq(L(1,2,3,4).accumulate(), [1,3,6,10])\ntest_eq(L(1,2,3,4).accumulate(operator.mul), [1,2,6,24])\ntest_eq(L(1,2,3).accumulate(initial=10), [10,11,13,16])\n\nCurried L.accumulate returns a partial function that computes running totals (or running results of any binary function) on any iterable. This is useful when mapping over nested collections—each inner collection gets its own running accumulation using the same function.\n\nnested = L([[1,2,3], [4,5,6], [10,20]])\nnested.map(L.accumulate(operator.mul))\n\n[[1, 2, 6], [4, 20, 120], [10, 200]]\n\n\n\nsource\n\n\nL.pairwise\n\ndef pairwise(\n    \n):\n\nSame as itertools.pairwise\nL.pairwise returns consecutive overlapping pairs:\n\ntest_eq(L(1,2,3,4).pairwise(), [(1,2),(2,3),(3,4)])\ntest_eq(L(list('abcd')).pairwise(), [('a','b'),('b','c'),('c','d')])\n\n\nsource\n\n\nL.batched\n\ndef batched(\n    n\n):\n\nSame as itertools.batched (but also works on older Python versions\nL.batched splits into chunks of size n:\n\ntest_eq(L(1,2,3,4,5).batched(2), [(1,2),(3,4),(5,)])\ntest_eq(L(list('abcdefg')).batched(3), [('a','b','c'),('d','e','f'),('g',)])\n\n\nsource\n\n\nL.compress\n\ndef compress(\n    selectors\n):\n\nSame as itertools.compress\nL.compress filters elements using a boolean selector:\n\ntest_eq(L(list('abcd')).compress([1,0,1,0]), ['a','c'])\ntest_eq(L(1,2,3,4,5).compress([True,False,True,False,True]), [1,3,5])\n\n\nsource\n\n\nL.permutations\n\ndef permutations(\n    r:NoneType=None\n):\n\nSame as itertools.permutations\nL.permutations returns all permutations of length r (defaults to full length):\n\ntest_eq(L(1,2,3).permutations(), [(1,2,3),(1,3,2),(2,1,3),(2,3,1),(3,1,2),(3,2,1)])\ntest_eq(L(list('abc')).permutations(2), [('a','b'),('a','c'),('b','a'),('b','c'),('c','a'),('c','b')])\n\n\nsource\n\n\nL.combinations\n\ndef combinations(\n    r\n):\n\nSame as itertools.combinations\nL.combinations returns all combinations of length r:\n\ntest_eq(L(1,2,3,4).combinations(2), [(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)])\ntest_eq(L(list('abcd')).combinations(3), [('a','b','c'),('a','b','d'),('a','c','d'),('b','c','d')])\n\n\nsource\n\n\npartition\n\ndef partition(\n    f:function=&lt;function noop at 0x7f158aa50d60&gt;, kwargs:VAR_KEYWORD\n):\n\nSplit into two Ls based on predicate f: (true_items, false_items)\nL.partition splits a list into two Ls based on a predicate—items where f returns true, and items where it returns false:\n\nt,f = L(1,2,3,4,5,6).partition(lambda x: x%2==0)\ntest_eq(t, [2,4,6])\ntest_eq(f, [1,3,5])\n\nevens,odds = L.range(10).partition(lambda x: x%2==0)\ntest_eq(evens, [0,2,4,6,8])\ntest_eq(odds, [1,3,5,7,9])\n\nCurried L.partition returns a partial function that splits any iterable into two Ls based on a predicate. This is useful when mapping over nested collections—each inner collection gets partitioned independently using the same predicate, returning a tuple of (true_items, false_items) for each.\n\nnested = L([[1,2,3,4,5], [10,15,20,25], [3,6,9]])\nnested.map(L.partition(gt(5)))\n\n[([], [1, 2, 3, 4, 5]), ([10, 15, 20, 25], []), ([6, 9], [3])]\n\n\n\n\n\nstarpartition\n\ndef starpartition(\n    f, kwargs:VAR_KEYWORD\n):\n\nLike partition, but unpacks elements as args to f\nL.starpartition is like partition, but unpacks tuple elements as arguments to the predicate:\n\nasc,desc = L((1,2),(3,1),(2,4),(5,3)).starpartition(lt)\ntest_eq(asc, [(1,2),(2,4)])   # a &lt; b\ntest_eq(desc, [(3,1),(5,3)])  # a &gt;= b\n\n\n\n\nrstarpartition\n\ndef rstarpartition(\n    f, kwargs:VAR_KEYWORD\n):\n\nLike starpartition, but reverse the order of args\nL.rstarpartition is like starpartition, but reverses the order of unpacked arguments:\n\nasc,desc = L((2,1),(1,3),(4,2),(3,5)).rstarpartition(lt)\ntest_eq(asc, [(2,1),(4,2)])   # b &lt; a (i.e., 1&lt;2, 2&lt;4)\ntest_eq(desc, [(1,3),(3,5)])  # b &gt;= a\n\n\nsource\n\n\nL.flatten\n\ndef flatten(\n    \n):\n\nRecursively flatten nested iterables (except strings)\nL.flatten recursively flattens nested iterables into a single L. Strings are treated as atomic (not iterated over):\n\ntest_eq(L([[1,2],[3,[4,5]]]).flatten(), [1,2,3,4,5])\ntest_eq(L([1,[2,[3,[4]]]]).flatten(), [1,2,3,4])\ntest_eq(L(['a',['b','c'],'d']).flatten(), ['a','b','c','d'])  # strings not flattened\ntest_eq(L([1,2,3]).flatten(), [1,2,3])  # already flat",
    "crumbs": [
      "Foundation"
    ]
  },
  {
    "objectID": "foundation.html#config",
    "href": "foundation.html#config",
    "title": "Foundation",
    "section": "Config",
    "text": "Config\n\nsource\n\nsave_config_file\n\ndef save_config_file(\n    file, d, kwargs:VAR_KEYWORD\n):\n\nWrite settings dict to a new config file, or overwrite the existing one.\n\nsource\n\n\nread_config_file\n\ndef read_config_file(\n    file, kwargs:VAR_KEYWORD\n):\n\nConfig files are saved and read using Python’s configparser.ConfigParser, inside the DEFAULT section.\n\n_d = dict(user='fastai', lib_name='fastcore', some_path='test', some_bool=True, some_num=3)\ntry:\n    save_config_file('tmp.ini', _d)\n    res = read_config_file('tmp.ini')\nfinally: os.unlink('tmp.ini')\ndict(res)\n\n{'user': 'fastai',\n 'lib_name': 'fastcore',\n 'some_path': 'test',\n 'some_bool': 'True',\n 'some_num': '3'}\n\n\n\nsource\n\n\nConfig\n\ndef Config(\n    cfg_path, cfg_name, create:NoneType=None, save:bool=True, extra_files:NoneType=None, types:NoneType=None,\n    cfg_kwargs:VAR_KEYWORD\n):\n\nReading and writing ConfigParser ini files\nConfig is a convenient wrapper around ConfigParser ini files with a single section (DEFAULT).\nInstantiate a Config from an ini file at cfg_path/cfg_name:\n\nsave_config_file('../tmp.ini', _d)\ntry: cfg = Config('..', 'tmp.ini')\nfinally: os.unlink('../tmp.ini')\ncfg\n\n{'user': 'fastai', 'lib_name': 'fastcore', 'some_path': 'test', 'some_bool': 'True', 'some_num': '3'}\n\n\nYou can create a new file if one doesn’t exist by providing a create dict:\n\ntry: cfg = Config('..', 'tmp.ini', create=_d)\nfinally: os.unlink('../tmp.ini')\ncfg\n\n{'user': 'fastai', 'lib_name': 'fastcore', 'some_path': 'test', 'some_bool': 'True', 'some_num': '3'}\n\n\nIf you additionally pass save=False, the Config will contain the items from create without writing a new file:\n\ncfg = Config('..', 'tmp.ini', create=_d, save=False)\ntest_eq(cfg.user,'fastai')\nassert not Path('../tmp.ini').exists()\n\nYou can also pass in ConfigParser kwargs to change the behavior of how your configuration file will be parsed. For example, by default, inline comments are not handled by Config. However, if you pass in the inline_comment_prefixes with whatever your comment symbol is, you’ll overwrite this behavior.\n\n# Create a complete example config file with comments\ncfg_str = \"\"\"\\\n[DEFAULT]\nuser = fastai # inline comment\n\n# Library configuration\nlib_name = fastcore\n\n# Paths\nsome_path = test \n\n# Feature flags\nsome_bool = True\n\n# Numeric settings\nsome_num = # missing value\n\"\"\"\n\nwith open('../tmp.ini', 'w') as f:\n    f.write(cfg_str)\n\n\n# Now read it back to verify\ntry: cfg = Config('..', 'tmp.ini', inline_comment_prefixes=('#'))\nfinally: os.unlink('../tmp.ini')\ntest_eq(cfg.user,'fastai')\ntest_eq(cfg.some_num,'')\n\n\nsource\n\n\nConfig.get\n\ndef get(\n    k, default:NoneType=None\n):\n\nKeys can be accessed as attributes, items, or with get and an optional default:\n\ntest_eq(cfg.user,'fastai')\ntest_eq(cfg['some_path'], 'test')\ntest_eq(cfg.get('foo','bar'),'bar')\n\nExtra files can be read before cfg_path/cfg_name using extra_files, in the order they appear:\n\nwith tempfile.TemporaryDirectory() as d:\n    a = Config(d, 'a.ini', {'a':0,'b':0})\n    b = Config(d, 'b.ini', {'a':1,'c':0})\n    c = Config(d, 'c.ini', {'a':2,'d':0}, extra_files=[a.config_file,b.config_file])\n    test_eq(c.d, {'a':'2','b':'0','c':'0','d':'0'})\n\nIf you pass a dict types, then the values of that dict will be used as types to instantiate all values returned. Path is a special case – in that case, the path returned will be relative to the path containing the config file (assuming the value is relative). bool types use str2bool to convert to boolean.\n\n_types = dict(some_path=Path, some_bool=bool, some_num=int)\ncfg = Config('..', 'tmp.ini', create=_d, save=False, types=_types)\n\ntest_eq(cfg.user,'fastai')\ntest_eq(cfg['some_path'].resolve(), (Path('..')/'test').resolve())\ntest_eq(cfg.get('some_num'), 3)\n\n\nsource\n\n\nConfig.find\n\ndef find(\n    cfg_name, cfg_path:NoneType=None, kwargs:VAR_KEYWORD\n):\n\nSearch cfg_path and its parents to find cfg_name\nYou can use Config.find to search subdirectories for a config file, starting in the current path if no path is specified:\n\nConfig.find('settings.ini').repo\n\n'fastcore'",
    "crumbs": [
      "Foundation"
    ]
  },
  {
    "objectID": "tour.html",
    "href": "tour.html",
    "title": "A tour of fastcore",
    "section": "",
    "text": "Here’s a (somewhat) quick tour of a few higlights from fastcore.\n\nDocumentation\nAll fast.ai projects, including this one, are built with nbdev, which is a full literate programming environment built on Jupyter Notebooks. That means that every piece of documentation, including the page you’re reading now, can be accessed as interactive Jupyter notebooks. In fact, you can even grab a link directly to a notebook running interactively on Google Colab - if you want to follow along with this tour, click the link below:\n\ncolab_link('000_tour')\n\nOpen 000_tour in Colab\n\n\nThe full docs are available at fastcore.fast.ai. The code in the examples and in all fast.ai libraries follow the fast.ai style guide. In order to support interactive programming, all fast.ai libraries are designed to allow for import * to be used safely, particular by ensuring that __all__ is defined in all packages. In order to see where a function is from, just type it:\n\ncoll_repr\n\n&lt;function fastcore.foundation.coll_repr(c, max_n=250)&gt;\n\n\nFor more details, including a link to the full documentation and source code, use doc, which pops up a window with this information:\ndoc(coll_repr)\n\nThe documentation also contains links to any related functions or classes, which appear like this: coll_repr (in the notebook itself you will just see a word with back-ticks around it; the links are auto-generated in the documentation site). The documentation will generally show one or more examples of use, along with any background context necessary to understand them. As you’ll see, the examples for each function and method are shown as tests, rather than example outputs, so let’s start by explaining that.\n\n\nTesting\nfastcore’s testing module is designed to work well with nbdev, which is a full literate programming environment built on Jupyter Notebooks. That means that your tests, docs, and code all live together in the same notebook. fastcore and nbdev’s approach to testing starts with the premise that all your tests should pass. If one fails, no more tests in a notebook are run.\nTests look like this:\n\ntest_eq(coll_repr(range(1000), 5), '(#1000) [0, 1, 2, 3, 4...]')\n\nThat’s an example from the docs for coll_repr. As you see, it’s not showing you the output directly. Here’s what that would look like:\n\ncoll_repr(range(1000), 5)\n\n'(#1000) [0, 1, 2, 3, 4...]'\n\n\nSo, the test is actually showing you what the output looks like, because if the function call didn’t return '(#1000) [0,1,2,3,4...]', then the test would have failed.\nSo every test shown in the docs is also showing you the behavior of the library — and vice versa!\nTest functions always start with test_, and then follow with the operation being tested. So test_eq tests for equality (as you saw in the example above). This includes tests for equality of arrays and tensors, lists and generators, and many more:\n\ntest_eq([0,1,2,3], np.arange(4))\n\nWhen a test fails, it prints out information about what was expected:\ntest_eq([0,1,2,3], np.arange(3))\n----\n  AssertionError: ==:\n  [0, 1, 2, 3]\n  [0 1 2]\nIf you want to check that objects are the same type, rather than the just contain the same collection, use test_eq_type.\nYou can test with any comparison function using test, e.g test whether an object is less than:\n\ntest(2, 3, operator.lt)\n\nYou can even test that exceptions are raised:\n\ndef divide_zero(): return 1/0\ntest_fail(divide_zero)\n\n…and test that things are printed to stdout:\n\ntest_stdout(lambda: print('hi'), 'hi')\n\n\n\nFoundations\nfast.ai is unusual in that we often use mixins in our code. Mixins are widely used in many programming languages, such as Ruby, but not so much in Python. We use mixins to attach new behavior to existing libraries, or to allow modules to add new behavior to our own classes, such as in extension modules. One useful example of a mixin we define is Path.ls, which lists a directory and returns an L (an extended list class which we’ll discuss shortly):\n\np = Path('images')\np.ls()\n\n[Path('images/mnist3.png'), Path('images/att_00000.png'), Path('images/att_00005.png'), Path('images/att_00007.png'), Path('images/att_00006.png'), Path('images/puppy.jpg')]\n\n\nYou can easily add you own mixins with the patch decorator, which takes advantage of Python 3 function annotations to say what class to patch:\n\n@patch\ndef num_items(self:Path): return len(self.ls())\n\np.num_items()\n\n6\n\n\nWe also use **kwargs frequently. In python **kwargs in a parameter like means “put any additional keyword arguments into a dict called kwargs”. Normally, using kwargs makes an API quite difficult to work with, because it breaks things like tab-completion and popup lists of signatures. utils provides use_kwargs and delegates to avoid this problem. See our detailed article on delegation on this topic.\nGetAttr solves a similar problem (and is also discussed in the article linked above): it’s allows you to use Python’s exceptionally useful __getattr__ magic method, but avoids the problem that normally in Python tab-completion and docs break when using this. For instance, you can see here that Python’s dir function, which is used to find the attributes of a python object, finds everything inside the self.default attribute here:\n\nclass Author:\n    def __init__(self, name): self.name = name\n\nclass ProductPage(GetAttr):\n    _default = 'author'\n    def __init__(self,author,price,cost): self.author,self.price,self.cost = author,price,cost\n\np = ProductPage(Author(\"Jeremy\"), 1.50, 0.50)\n[o for o in dir(p) if not o.startswith('_')]\n\n['author', 'cost', 'name', 'price']\n\n\nLooking at that ProductPage example, it’s rather verbose and duplicates a lot of attribute names, which can lead to bugs later if you change them only in one place. fastcore provides store_attr to simplify this common pattern. It also provides basic_repr to give simple objects a useful repr:\n\nclass ProductPage:\n    def __init__(self,author,price,cost): store_attr()\n    __repr__ = basic_repr('author,price,cost')\n\nProductPage(\"Jeremy\", 1.50, 0.50)\n\nProductPage(author='Jeremy', price=1.5, cost=0.5)\n\n\nOne of the most interesting fastcore functions is the funcs_kwargs decorator. This allows class behavior to be modified without sub-classing. This can allow folks that aren’t familiar with object-oriented programming to customize your class more easily. Here’s an example of a class that uses funcs_kwargs:\n\n@funcs_kwargs\nclass T:\n    _methods=['some_method']\n    def __init__(self, **kwargs): assert not kwargs, f'Passed unknown args: {kwargs}'\n\np = T(some_method = print)\np.some_method(\"hello\")\n\nhello\n\n\nThe assert not kwargs above is used to ensure that the user doesn’t pass an unknown parameter (i.e one that’s not in _methods). fastai uses funcs_kwargs in many places, for instance, you can customize any part of a DataLoader by passing your own methods.\nfastcore also provides many utility functions that make a Python programmer’s life easier, in fastcore.utils. We won’t look at many here, since you can easily look at the docs yourself. To get you started, have a look at the docs for chunked (remember, if you’re in a notebook, type doc(chunked)), which is a handy function for creating lazily generated batches from a collection.\nPython’s ProcessPoolExecutor is extended to allow max_workers to be set to 0, to easily turn off parallel processing. This makes it easy to debug your code in serial, then run it in parallel. It also allows you to pass arguments to your parallel function, and to ensure there’s a pause between calls, in case the process you are running has race conditions. parallel makes parallel processing even easier to use, and even adds an optional progress bar.\n\n\nL\nLike most languages, Python allows for very concise syntax for some very common types, such as list, which can be constructed with [1,2,3]. Perl’s designer Larry Wall explained the reasoning for this kind of syntax:\n\nIn metaphorical honor of Huffman’s compression code that assigns smaller numbers of bits to more common bytes. In terms of syntax, it simply means that commonly used things should be shorter, but you shouldn’t waste short sequences on less common constructs.\n\nOn this basis, fastcore has just one type that has a single letter name: L. The reason for this is that it is designed to be a replacement for list, so we want it to be just as easy to use as [1,2,3]. Here’s how to create that as an L:\n\nL(1,2,3)\n\n[1, 2, 3]\n\n\nThe first thing to notice is that an L object includes in its representation its number of elements; that’s the (#3) in the output above. If there’s more than 10 elements, it will automatically truncate the list:\n\np = L.range(20).shuffle()\np\n\n[14, 19, 13, 11, 8, 9, 0, 6, 4, 15, 1, 17, 16, 5, 3, 10, 2, 7, 12, 18]\n\n\nL contains many of the same indexing ideas that NumPy’s array does, including indexing with a list of indexes, or a boolean mask list:\n\np[2,4,6]\n\n[13, 8, 0]\n\n\nIt also contains other methods used in array, such as L.argwhere:\n\np.argwhere(ge(15))\n\n[1, 9, 11, 12, 19]\n\n\nAs you can see from this example, fastcore also includes a number of features that make a functional style of programming easier, such as a full range of boolean functions (e.g ge, gt, etc) which give the same answer as the functions from Python’s operator module if given two parameters, but return a curried function if given one parameter.\nThere’s too much functionality to show it all here, so be sure to check the docs. Many little things are added that we thought should have been in list in the first place, such as making this do what you’d expect (which is an error with list, but works fine with L):\n\n1 + L(2,3,4)\n\n[1, 2, 3, 4]",
    "crumbs": [
      "A tour of fastcore"
    ]
  },
  {
    "objectID": "meta.html",
    "href": "meta.html",
    "title": "Meta",
    "section": "",
    "text": "from fastcore.foundation import *\nfrom nbdev.showdoc import *\nfrom fastcore.nb_imports import *\nfrom fastcore.test import *\nSee this blog post for more information about metaclasses.\nsource",
    "crumbs": [
      "Meta"
    ]
  },
  {
    "objectID": "meta.html#metaprogramming",
    "href": "meta.html#metaprogramming",
    "title": "Meta",
    "section": "Metaprogramming",
    "text": "Metaprogramming\n\nsource\n\nempty2none\n\ndef empty2none(\n    p\n):\n\nReplace Parameter.empty with None\n\nsource\n\n\nanno_dict\n\ndef anno_dict(\n    f\n):\n\n__annotation__ dictionary withemptycast toNone`, returning empty if doesn’t exist\n\ndef _f(a:int, b:L)-&gt;str: ...\ntest_eq(anno_dict(_f), {'a': int, 'b': L, 'return': str})\n\n\nsource\n\n\nuse_kwargs_dict\n\ndef use_kwargs_dict(\n    keep:bool=False, kwargs:VAR_KEYWORD\n):\n\nDecorator: replace **kwargs in signature with names params\nReplace all **kwargs with named arguments like so:\n\n@use_kwargs_dict(y=1,z=None)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None)')\n\nAdd named arguments, but optionally keep **kwargs by setting keep=True:\n\n@use_kwargs_dict(y=1,z=None, keep=True)\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=1, z=None, **kwargs)')\n\n\nsource\n\n\nuse_kwargs\n\ndef use_kwargs(\n    names, keep:bool=False\n):\n\nDecorator: replace **kwargs in signature with names params\nuse_kwargs is different than use_kwargs_dict as it only replaces **kwargs with named parameters without any default values:\n\n@use_kwargs(['y', 'z'])\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, y=None, z=None)')\n\nYou may optionally keep the **kwargs argument in your signature by setting keep=True:\n\n@use_kwargs(['y', 'z'], keep=True)\ndef foo(a, *args, b=1, **kwargs): pass\ntest_sig(foo, '(a, *args, b=1, y=None, z=None, **kwargs)')\n\n\nfrom fastcore.basics import *\n\n\nlistify('a')\n\n['a']\n\n\n\nsource\n\n\ndelegates\n\ndef delegates(\n    to:function=None, # Delegatee\n    keep:bool=False, # Keep `kwargs` in decorated function?\n    but:list=None, # Exclude these parameters from signature\n    sort_args:bool=False, # Sort arguments alphabetically, doesn't work with call_parse\n):\n\nDecorator: replace **kwargs in signature with params from to\n\ndef baz(a, b:int=2, c:int=3): return a + b + c\n\ndef foo(c, a, **kwargs):\n    return c + baz(a, **kwargs)\n\nassert foo(c=1, a=1) == 7\n\nThe problem with this approach is the api for foo is obfuscated. Users cannot introspect what the valid arguments for **kwargs are without reading the source code. When a user tries tries to introspect the signature of foo, they are presented with this:\n\ninspect.signature(foo)\n\n&lt;Signature (c, a, **kwargs)&gt;\n\n\nWe can address this issue by using the decorator delegates to include parameters from other functions. For example, if we apply the delegates decorator to foo to include parameters from baz:\n\n@delegates(baz)\ndef foo(c, a, **kwargs):\n    return c + baz(a, **kwargs)\n\ntest_sig(foo, '(c, a, *, b: int = 2)')\ninspect.signature(foo)\n\n&lt;Signature (c, a, *, b: int = 2)&gt;\n\n\nWe can optionally decide to keep **kwargs by setting keep=True:\n\n@delegates(baz, keep=True)\ndef foo(c, a, **kwargs):\n    return c + baz(a, **kwargs)\n\ninspect.signature(foo)\n\n&lt;Signature (c, a, *, b: int = 2, **kwargs)&gt;\n\n\nIt is important to note that only parameters with default parameters are included. For example, in the below scenario only c, but NOT e and d are included in the signature of foo after applying delegates:\n\ndef basefoo(e, d, c=2): pass\n\n@delegates(basefoo)\ndef foo(a, b=1, **kwargs): pass\ninspect.signature(foo) # e and d are not included b/c they don't have default parameters.\n\n&lt;Signature (a, b=1, *, c=2)&gt;\n\n\nThe reason that required arguments (i.e. those without default parameters) are automatically excluded is that you should be explicitly implementing required arguments into your function’s signature rather than relying on delegates.\nAdditionally, you can exclude specific parameters from being included in the signature with the but parameter. In the example below, we exclude the parameter d:\n\ndef basefoo(e, c=2, d=3): pass\n\n@delegates(basefoo, but= ['d'])\ndef foo(a, b=1, **kwargs): pass\n\ntest_sig(foo, '(a, b=1, *, c=2)')\ninspect.signature(foo)\n\n&lt;Signature (a, b=1, *, c=2)&gt;\n\n\nYou can also use delegates between methods in a class. Here is an example of delegates with class methods:\n\n# example 1: class methods\nclass _T():\n    @classmethod\n    def foo(cls, a=1, b=2):\n        pass\n    \n    @classmethod\n    @delegates(foo)\n    def bar(cls, c=3, **kwargs):\n        pass\n\ntest_sig(_T.bar, '(c=3, *, a=1, b=2)')\n\nHere is the same example with instance methods:\n\n# example 2: instance methods\nclass _T():\n    def foo(self, a=1, b=2):\n        pass\n    \n    @delegates(foo)\n    def bar(self, c=3, **kwargs):\n        pass\n\nt = _T()\ntest_sig(t.bar, '(c=3, *, a=1, b=2)')\n\nYou can also delegate between classes. By default, the delegates decorator will delegate to the superclass:\n\nclass BaseFoo:\n    def __init__(self, e, c=2): pass\n\n@delegates()# since no argument was passsed here we delegate to the superclass\nclass Foo(BaseFoo):\n    def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs)\n\ntest_sig(Foo, '(a, b=1, *, c=2)')\n\n\nsource\n\n\nmethod\n\ndef method(\n    f\n):\n\nMark f as a method\nThe method function is used to change a function’s type to a method. In the below example we change the type of a from a function to a method:\n\ndef a(x=2): return x + 1\nassert type(a).__name__ == 'function'\n\na = method(a)\nassert type(a).__name__ == 'method'\n\nYou can also sort the arguments by setting the sort_args parameter to True. Here’s a function with arguments not in alphabetical order.\n\ndef unsortedfunc(c=3,a=1,b=2): pass\nunsortedfunc\n\n&lt;function __main__.unsortedfunc(c=3, a=1, b=2)&gt;\n\n\nWe can sort them using the sort_args parameter:\n\n@delegates(unsortedfunc, sort_args=True)\ndef sortedfunc(**kwargs): pass\ntest_sig(sortedfunc, '(*, a=1, b=2, c=3)')\nsortedfunc\n\n&lt;function __main__.sortedfunc(*, a=1, b=2, c=3)&gt;\n\n\n\nsource\n\n\nfuncs_kwargs\n\ndef funcs_kwargs(\n    as_method:bool=False\n):\n\nReplace methods in cls._methods with those from kwargs\nThe func_kwargs decorator allows you to add a list of functions or methods to an existing class. You must set this list as a class attribute named _methods when defining your class. Additionally, you must incldue the **kwargs argument in the ___init__ method of your class.\nAfter defining your class this way, you can add functions to your class upon instantation as illusrated below.\nFor example, we define class T to allow adding the function b to class T as follows (note that this function is stored as an attribute of T and doesn’t have access to cls or self):\n\n@funcs_kwargs\nclass T:\n    _methods=['b'] # allows you to add method b upon instantiation\n    def __init__(self, f=1, **kwargs): pass # don't forget to include **kwargs in __init__\n    def a(self): return 1\n    def b(self): return 2\n    \nt = T()\ntest_eq(t.a(), 1)\ntest_eq(t.b(), 2)\n\nBecause we defined the class T this way, the signature of T indicates the option to add the function or method(s) specified in _methods. In this example, b is added to the signature:\n\ntest_sig(T, '(f=1, *, b=None)')\ninspect.signature(T)\n\n&lt;Signature (f=1, *, b=None)&gt;\n\n\nYou can now add the function b to class T upon instantiation:\n\ndef _new_func(): return 5\n\nt = T(b = _new_func)\ntest_eq(t.b(), 5)\n\nIf you try to add a function with a name not listed in _methods it will be ignored. In the below example, the attempt to add a function named a is ignored:\n\nt = T(a = lambda:3)\ntest_eq(t.a(), 1) # the attempt to add a is ignored and uses the original method instead.\n\nNote that you can also add methods not defined in the original class as long it is specified in the _methods attribute:\n\n@funcs_kwargs\nclass T:\n    _methods=['c']\n    def __init__(self, f=1, **kwargs): pass\n\nt = T(c = lambda: 4)\ntest_eq(t.c(), 4)\n\nUntil now, these examples showed how to add functions stored as an instance attribute without access to self. However, if you need access to self you can set as_method=True in the func_kwargs decorator to add a method instead:\n\ndef _f(self,a=1): return self.num + a # access the num attribute from the instance\n\n@funcs_kwargs(as_method=True)\nclass T: \n    _methods=['b']\n    num = 5\n    \nt = T(b = _f) # adds method b\ntest_eq(t.b(5), 10) # self.num + 5 = 10\n\nHere is an example of how you might use this functionality with inheritence:\n\ndef _f(self,a=1): return self.num * a #multiply instead of add \n\nclass T2(T):\n    def __init__(self,num):\n        super().__init__(b = _f) # add method b from the super class\n        self.num=num\n        \nt = T2(num=3)\ntest_eq(t.b(a=5), 15) # 3 * 5 = 15\ntest_sig(T2, '(num)')",
    "crumbs": [
      "Meta"
    ]
  },
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "LLM tools",
    "section": "",
    "text": "source\n\n\n\ndef run_cmd(\n    cmd:str, # The command name to run\n    argstr:str='', # All args to the command, will be split with shlex\n    disallow_re:str=None, # optional regex which, if matched on argstr, will disallow the command\n    allow_re:str=None, # optional regex which, if not matched on argstr, will disallow the command\n):\n\nRun cmd passing split argstr, optionally checking for allowed argstr\nWith this little function, we can now run any cli command:\n\nprint(run_cmd('ls')[:128])\n\n__pycache__\n_parallel_win.ipynb\n_quarto.yml\n00_test.ipynb\n000_tour.ipynb\n01_basics.ipynb\n02_foundation.ipynb\n03_xtras\n\n\nNote that, for tool safety, this is not passed through the shell, so wildcards, env vars, etc will not work:\n\nprint(run_cmd('ls', 'f*')[:128])\n\nls: f*: No such file or directory\n\n\n\nLet’s create some useful functions from this that will allow for searching, reading and modifing content on the file system.\n\nsource\n\n\n\n\ndef rg(\n    argstr:str, # All args to the command, will be split with shlex\n    disallow_re:str=None, # optional regex which, if matched on argstr, will disallow the command\n    allow_re:str=None, # optional regex which, if not matched on argstr, will disallow the command\n):\n\nRun the rg command with the args in argstr (no need to backslash escape)\n\nrg('fast.ai CNAME')\n\n'1:fastcore.fast.ai\\n'\n\n\nFunctions implemented with run_cmd like this one can be passed regexps to allow or disallow arg strs, i.e to block parent or root directories:\n\ndisallowed = r' /|\\.\\.'\nrg('info@fast.ai ..', disallow_re=disallowed)\n\n'Error: args disallowed'\n\n\n\nrg('info@fast.ai /', disallow_re=disallowed)\n\n'Error: args disallowed'\n\n\n\nprint(rg('fast.ai CNAME', disallow_re=disallowed))\n\n1:fastcore.fast.ai\n\n\n\nNB: These tools have special behavior around errors. Since these have been speficially designed for work with LLMs, any exceptions created from there use is returned as a string to help them debug their work.\n\nrun_cmd('asdfe')\n\n\"Error running cmd: [Errno 2] No such file or directory: 'asdfe'\"\n\n\n\nsource\n\n\n\n\ndef sed(\n    argstr:str, # All args to the command, will be split with shlex\n    disallow_re:str=None, # optional regex which, if matched on argstr, will disallow the command\n    allow_re:str=None, # optional regex which, if not matched on argstr, will disallow the command\n):\n\nRun the sed command with the args in argstr (e.g for reading a section of a file)\n\nprint(sed('-n \"1,5 p\" _quarto.yml'))\n\nproject:\n  type: website\n  pre-render: \n    - pysym2md --output_file apilist.txt fastcore\n  post-render: \n\n\n\n\n# Print line numbers too\nprint(sed('-n \"1,5 {=;p;}\" _quarto.yml'))\n\n1\nproject:\n2\n  type: website\n3\n  pre-render: \n4\n    - pysym2md --output_file apilist.txt fastcore\n5\n  post-render:",
    "crumbs": [
      "LLM tools"
    ]
  },
  {
    "objectID": "tools.html#bash-tools",
    "href": "tools.html#bash-tools",
    "title": "LLM tools",
    "section": "",
    "text": "source\n\n\n\ndef run_cmd(\n    cmd:str, # The command name to run\n    argstr:str='', # All args to the command, will be split with shlex\n    disallow_re:str=None, # optional regex which, if matched on argstr, will disallow the command\n    allow_re:str=None, # optional regex which, if not matched on argstr, will disallow the command\n):\n\nRun cmd passing split argstr, optionally checking for allowed argstr\nWith this little function, we can now run any cli command:\n\nprint(run_cmd('ls')[:128])\n\n__pycache__\n_parallel_win.ipynb\n_quarto.yml\n00_test.ipynb\n000_tour.ipynb\n01_basics.ipynb\n02_foundation.ipynb\n03_xtras\n\n\nNote that, for tool safety, this is not passed through the shell, so wildcards, env vars, etc will not work:\n\nprint(run_cmd('ls', 'f*')[:128])\n\nls: f*: No such file or directory\n\n\n\nLet’s create some useful functions from this that will allow for searching, reading and modifing content on the file system.\n\nsource\n\n\n\n\ndef rg(\n    argstr:str, # All args to the command, will be split with shlex\n    disallow_re:str=None, # optional regex which, if matched on argstr, will disallow the command\n    allow_re:str=None, # optional regex which, if not matched on argstr, will disallow the command\n):\n\nRun the rg command with the args in argstr (no need to backslash escape)\n\nrg('fast.ai CNAME')\n\n'1:fastcore.fast.ai\\n'\n\n\nFunctions implemented with run_cmd like this one can be passed regexps to allow or disallow arg strs, i.e to block parent or root directories:\n\ndisallowed = r' /|\\.\\.'\nrg('info@fast.ai ..', disallow_re=disallowed)\n\n'Error: args disallowed'\n\n\n\nrg('info@fast.ai /', disallow_re=disallowed)\n\n'Error: args disallowed'\n\n\n\nprint(rg('fast.ai CNAME', disallow_re=disallowed))\n\n1:fastcore.fast.ai\n\n\n\nNB: These tools have special behavior around errors. Since these have been speficially designed for work with LLMs, any exceptions created from there use is returned as a string to help them debug their work.\n\nrun_cmd('asdfe')\n\n\"Error running cmd: [Errno 2] No such file or directory: 'asdfe'\"\n\n\n\nsource\n\n\n\n\ndef sed(\n    argstr:str, # All args to the command, will be split with shlex\n    disallow_re:str=None, # optional regex which, if matched on argstr, will disallow the command\n    allow_re:str=None, # optional regex which, if not matched on argstr, will disallow the command\n):\n\nRun the sed command with the args in argstr (e.g for reading a section of a file)\n\nprint(sed('-n \"1,5 p\" _quarto.yml'))\n\nproject:\n  type: website\n  pre-render: \n    - pysym2md --output_file apilist.txt fastcore\n  post-render: \n\n\n\n\n# Print line numbers too\nprint(sed('-n \"1,5 {=;p;}\" _quarto.yml'))\n\n1\nproject:\n2\n  type: website\n3\n  pre-render: \n4\n    - pysym2md --output_file apilist.txt fastcore\n5\n  post-render:",
    "crumbs": [
      "LLM tools"
    ]
  },
  {
    "objectID": "tools.html#text-edit-tools",
    "href": "tools.html#text-edit-tools",
    "title": "LLM tools",
    "section": "Text Edit Tools",
    "text": "Text Edit Tools\nPython implementations of the text editor tools from Anthropic, plus more. These tools are especially useful in an AI’s tool loop. See claudette for examples.\n\nsource\n\nview\n\ndef view(\n    path:str, # Path to directory or file to view\n    view_range:tuple=None, # Optional 1-indexed (start, end) line range for files, end=-1 for EOF\n    nums:bool=False, # Whether to show line numbers\n):\n\nView directory or file contents with optional line range and numbers\nYou can specify line ranges and whether to have the output contain line numbers:\n\nprint(view('_quarto.yml', (1,10), nums=True))\n\n     1 │ project:\n     2 │   type: website\n     3 │   pre-render: \n     4 │     - pysym2md --output_file apilist.txt fastcore\n     5 │   post-render: \n     6 │     - llms_txt2ctx llms.txt --optional true --save_nbdev_fname llms-ctx-full.txt\n     7 │     - llms_txt2ctx llms.txt --save_nbdev_fname llms-ctx.txt\n     8 │   resources: \n     9 │     - \"*.txt\"\n    10 │   preview:\n\n\nHere’s what the output looks like when viewing a directory:\n\nprint(view('.', (1,5)))\n\nDirectory contents of /Users/jhoward/aai-ws/fastcore/nbs:\n/Users/jhoward/aai-ws/fastcore/nbs/llms.txt\n/Users/jhoward/aai-ws/fastcore/nbs/000_tour.ipynb\n/Users/jhoward/aai-ws/fastcore/nbs/parallel_test.py\n/Users/jhoward/aai-ws/fastcore/nbs/_quarto.yml\n/Users/jhoward/aai-ws/fastcore/nbs/08_style.ipynb\n\n\n\nsource\n\n\ncreate\n\ndef create(\n    path:str, # Path where the new file should be created\n    file_text:str, # Content to write to the file\n    overwrite:bool=False, # Whether to overwrite existing files\n)-&gt;str:\n\nCreates a new file with the given content at the specified path\n\nprint(create('test.txt', 'Hello, world!'))\nf = Path('test.txt')\ntest_eq(f.exists(), True)\nprint('Contents:\\n', view(f, nums=True))\n\nCreated file test.txt.\nContents:\n      1 │ Hello, world!\n\n\n\nsource\n\n\ninsert\n\ndef insert(\n    path:str, # Path to the file to modify\n    insert_line:int, # Line number where to insert (0-based indexing)\n    new_str:str, # Text to insert at the specified line\n)-&gt;str:\n\nInsert new_str at specified line number\n\ninsert(f, 0, 'Let\\'s add a new line')\nprint(view(f, nums=True))\n\n     1 │ Let's add a new line\n     2 │ Hello, world!\n\n\n\nsource\n\n\nstr_replace\n\ndef str_replace(\n    path:str, # Path to the file to modify\n    old_str:str, # Text to find and replace\n    new_str:str, # Text to replace with\n)-&gt;str:\n\nReplace first occurrence of old_str with new_str in file\n\nstr_replace(f, 'new line', '')\nprint(view(f, nums=True))\n\n     1 │ Let's add a \n     2 │ Hello, world!\n\n\n\nsource\n\n\nstrs_replace\n\ndef strs_replace(\n    path:str, # Path to the file to modify\n    old_strs:list, # List of strings to find and replace\n    new_strs:list, # List of replacement strings (must match length of old_strs)\n):\n\nReplace for each str pair in old_strs,new_strs\n\nstrs_replace(f, [\"add a new line\", \"world!\"], [\"just say\", \"friends!\\nNice to see you.\"])\nprint(view(f, nums=True))\n\n     1 │ Let's add a \n     2 │ Hello, friends!\n     3 │ Nice to see you.\n\n\n\nsource\n\n\nreplace_lines\n\ndef replace_lines(\n    path:str, # Path to the file to modify\n    start_line:int, # Starting line number to replace (1-based indexing)\n    end_line:int, # Ending line number to replace (1-based indexing, inclusive)\n    new_content:str, # New content to replace the specified lines\n):\n\nReplace lines in file using start and end line-numbers (index starting at 1)\n\nreplace_lines('test.txt', 1, 2, 'Replaced first two lines')\nprint(view('test.txt', nums=True))\n\n     1 │ Replaced first two lines\n     2 │ Nice to see you.\n\n\n\nsource\n\n\nmove_lines\n\ndef move_lines(\n    path:str, # Path to the file to modify\n    start_line:int, # Starting line number to move (1-based)\n    end_line:int, # Ending line number to move (1-based, inclusive)\n    dest_line:int, # Destination line number (1-based, where lines will be inserted before)\n)-&gt;str:\n\nMove lines from start_line:end_line to before dest_line\nThe move_lines function relocates a range of lines within a file to a new position. It handles the tricky index adjustment when the destination is after the removed chunk.\nLet’s test it by creating a simple 5-line file:\n\ncreate('move_test.txt', 'Line 1\\nLine 2\\nLine 3\\nLine 4\\nLine 5', overwrite=True)\nprint(view('move_test.txt', nums=True))\n\n     1 │ Line 1\n     2 │ Line 2\n     3 │ Line 3\n     4 │ Line 4\n     5 │ Line 5\n\n\nMove lines 4-5 up to before line 2:\n\nprint(move_lines('move_test.txt', 4, 5, 2))\nprint(view('move_test.txt', nums=True))\n\nMoved lines 4-5 to line 2\n     1 │ Line 1\n     2 │ Line 4\n     3 │ Line 5\n     4 │ Line 2\n     5 │ Line 3\n\n\nMove lines down — moving lines 1-2 to the end (line 6) correctly adjusts the destination index after removal:\n\nprint(move_lines('move_test.txt', 1, 2, 6))\nprint(view('move_test.txt', nums=True))\n\nMoved lines 1-2 to line 4\n     1 │ Line 5\n     2 │ Line 2\n     3 │ Line 3\n     4 │ Line 1\n     5 │ Line 4\n\n\nError handling — destination within source range, invalid line ranges, and invalid destinations are all caught:\n\nprint(move_lines('move_test.txt', 2, 3, 3))  # dest within source range\nprint(move_lines('move_test.txt', 10, 12, 1))  # invalid range\nprint(move_lines('move_test.txt', 1, 2, 99))  # invalid destination\n\nError: Destination within source range\nError: Invalid range 10-12\nError: Invalid destination 99\n\n\n\nPath('move_test.txt').unlink()\n\n\nf.unlink()\n\n\nsource\n\n\nget_callable\n\ndef get_callable(\n    \n):\n\nReturn callable objects defined in caller’s module\n\n'; '.join(get_callable())\n\n'run_cmd; rg; sed; view; create; insert; str_replace; strs_replace; replace_lines; move_lines; get_callable'\n\n\n\n# Verify that all public functions defined in this module have valid schemas\n# (i.e., they have proper type annotations and docstrings required by get_schema)\nfor f,_o in get_callable().items(): test_eq(f, get_schema(globals()[f])['name'])",
    "crumbs": [
      "LLM tools"
    ]
  },
  {
    "objectID": "xtras.html",
    "href": "xtras.html",
    "title": "Utility functions",
    "section": "",
    "text": "Utilities (other than extensions to Pathlib.Path) for dealing with IO.\n\nsource\n\n\n\ndef walk(\n    path:Path \\| str, # path to start searching\n    symlinks:bool=True, # follow symlinks?\n    keep_file:callable=&lt;function ret_true at 0x7f717bfc96c0&gt;, # function that returns True for wanted files\n    keep_folder:callable=&lt;function ret_true at 0x7f717bfc96c0&gt;, # function that returns True for folders to enter\n    skip_folder:callable=&lt;function ret_false at 0x7f717bfc9760&gt;, # function that returns True for folders to skip\n    func:callable=&lt;function join at 0x7f717c718cc0&gt;, # function to apply to each matched file\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n):\n\nGenerator version of os.walk, using functions to filter files and folders\n\nsource\n\n\n\n\ndef exttypes(\n    types\n):\n\nGet exts for comma-separated or list typ; if not found in list, return list with just types. Supported: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n\nprint(exttypes('py,doc'))\nprint(exttypes('zig,txt'))\n\n['ipynb', 'py', 'md', 'rst']\n['zig', 'txt']\n\n\n\nsource\n\n\n\n\ndef globtastic(\n    path:Path \\| str='.', # path to start searching\n    recursive:bool=True, # search subfolders\n    symlinks:bool=True, # follow symlinks?\n    file_glob:str=None, # Only include files matching glob\n    file_re:str=None, # Only include files matching regex\n    folder_re:str=None, # Only enter folders matching regex\n    skip_file_glob:str=None, # Skip files matching glob\n    skip_file_re:str=None, # Skip files matching regex\n    skip_folder_re:str=None, # Skip folders matching regex,\n    func:callable=&lt;function join at 0x7f717c718cc0&gt;, # function to apply to each matched file\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n    types:str \\| list=None, # list or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n    exts:str \\| list=None, # list or comma-separated str of exts to include\n)-&gt;L: # Paths to matched files\n\nA more powerful glob, including regex matches, symlink handling, and skip parameters\n\nglobtastic('.', skip_folder_re='^[_.]', folder_re='core', file_glob='*.*py*', file_re='c')\n\n['./fastcore/basics.py', './fastcore/dispatch.py', './fastcore/docments.py', './fastcore/docscrape.py', './fastcore/script.py']\n\n\n\nglobtastic(skip_folder_re='^[_.]', folder_re='core', types='py', file_re='c', skip_file_re='^_', sort=True)\n\n['./fastcore/all.py', './fastcore/ansi.py', './fastcore/basics.py', './fastcore/dispatch.py', './fastcore/docments.py', './fastcore/docscrape.py', './fastcore/foundation.py', './fastcore/imghdr.py', './fastcore/imports.py', './fastcore/meta.py', './fastcore/nb_imports.py', './fastcore/net.py', './fastcore/parallel.py', './fastcore/py2pyi.py', './fastcore/script.py', './fastcore/shutil.py', './fastcore/style.py', './fastcore/test.py', './fastcore/tools.py', './fastcore/transform.py', './fastcore/utils.py', './fastcore/xdg.py', './fastcore/xml.py', './fastcore/xtras.py']\n\n\n\nsource\n\n\n\n\ndef pglob(\n    path:Path \\| str='.', # path to start searching\n    func:callable=&lt;class 'pathlib.Path'&gt;, # function to apply to each matched file\n    recursive:bool=True, symlinks:bool=True, file_glob:str=None, file_re:str=None, folder_re:str=None,\n    skip_file_glob:str=None, skip_file_re:str=None, skip_folder_re:str=None, ret_folders:bool=False, sort:bool=True,\n    types:str \\| list=None, exts:str \\| list=None\n)-&gt;L: # Paths to matched files\n\nShortcut for globtastic(..., call=Path)\n\npglob('..', skip_folder_re='^[_.]', types='doc', skip_file_re='^_')[:6]\n\n[Path('../CHANGELOG.md'), Path('../CODE_OF_CONDUCT.md'), Path('../CONTRIBUTING.md'), Path('../README.md')]\n\n\n\nsource\n\n\n\n\ndef maybe_open(\n    f, mode:str='r', kwargs:VAR_KEYWORD\n):\n\nContext manager: open f if it is a path (and close on exit)\nThis is useful for functions where you want to accept a path or file. maybe_open will not close your file handle if you pass one in.\n\ndef _f(fn):\n    with maybe_open(fn) as f: return f.encoding\n\nfname = '00_test.ipynb'\nsys_encoding = 'cp1252' if sys.platform == 'win32' else 'utf-8'\ntest_eq(_f(fname).lower(), sys_encoding)\nwith open(fname) as fh: test_eq(_f(fh).lower(), sys_encoding)\n\nFor example, we can use this to reimplement imghdr.what from the Python standard library, which is written in Python 3.9 as:\n\nfrom fastcore import imghdr\n\n\ndef what(file, h=None):\n    f = None\n    try:\n        if h is None:\n            if isinstance(file, (str,os.PathLike)):\n                f = open(file, 'rb')\n                h = f.read(32)\n            else:\n                location = file.tell()\n                h = file.read(32)\n                file.seek(location)\n        for tf in imghdr.tests:\n            res = tf(h, f)\n            if res: return res\n    finally:\n        if f: f.close()\n    return None\n\nHere’s an example of the use of this function:\n\nfname = 'images/puppy.jpg'\nwhat(fname)\n\n'jpeg'\n\n\nWith maybe_open, Self, and L.map_first, we can rewrite this in a much more concise and (in our opinion) clear way:\n\ndef what(file, h=None):\n    if h is None:\n        with maybe_open(file, 'rb') as f: h = f.peek(32)\n    return L(imghdr.tests).map_first(Self(h,file))\n\n…and we can check that it still works:\n\ntest_eq(what(fname), 'jpeg')\n\n…along with the version passing a file handle:\n\nwith open(fname,'rb') as f: test_eq(what(f), 'jpeg')\n\n…along with the h parameter version:\n\nwith open(fname,'rb') as f: test_eq(what(None, h=f.read(32)), 'jpeg')\n\n\nsource\n\n\n\n\ndef mkdir(\n    path, exist_ok:bool=False, parents:bool=False, overwrite:bool=False, kwargs:VAR_KEYWORD\n):\n\nCreates and returns a directory defined by path, optionally removing previous existing directory if overwrite is True\n\nwith tempfile.TemporaryDirectory() as d:\n    path = Path(os.path.join(d, 'new_dir'))\n    new_dir = mkdir(path)\n    assert new_dir.exists()\n    test_eq(new_dir, path)\n        \n    # test overwrite\n    with open(new_dir/'test.txt', 'w') as f: f.writelines('test')\n    test_eq(len(list(walk(new_dir))), 1) # assert file is present\n    new_dir = mkdir(new_dir, overwrite=True)\n    test_eq(len(list(walk(new_dir))), 0) # assert file was deleted\n\n\nsource\n\n\n\n\ndef image_size(\n    fn\n):\n\nTuple of (w,h) for png, gif, or jpg; None otherwise\n\ntest_eq(image_size(fname), (1200,803))\n\n\nfrom PIL import Image\nfrom IPython.display import Image as IPImage\n\n\nimg = Image.new('RGB', (50, 50), color='red')\nimg\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n\ndef img_bytes(\n    img, fmt:str='PNG'\n):\n\n\nib = img_bytes(img)\nIPImage(ib)\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n\ndef detect_mime(\n    data\n):\n\nGet the MIME type for bytes data, covering common PDF, audio, video, and image types\n\ndetect_mime(ib)\n\n'image/png'\n\n\n\nsource\n\n\n\n\ndef bunzip(\n    fn\n):\n\nbunzip fn, raising exception if output already exists\n\nf = Path('files/test.txt')\nif f.exists(): f.unlink()\nbunzip('files/test.txt.bz2')\nt = f.open().readlines()\ntest_eq(len(t),1)\ntest_eq(t[0], 'test\\n')\nf.unlink()\n\n\nsource\n\n\n\n\ndef loads(\n    s, kw:VAR_KEYWORD\n):\n\nSame as json.loads, but handles None\n\nsource\n\n\n\n\ndef loads_multi(\n    s:str\n):\n\nGenerator of &gt;=0 decoded json dicts, possibly with non-json ignored text at start and end\n\ntst = \"\"\"\n# ignored\n{ \"a\":1 }\nhello\n{\n\"b\":2\n}\n\"\"\"\n\ntest_eq(list(loads_multi(tst)), [{'a': 1}, {'b': 2}])\n\n\nsource\n\n\n\n\ndef dumps(\n    obj, kw:VAR_KEYWORD\n):\n\nSame as json.dumps, but uses ujson if available\n\nsource\n\n\n\n\ndef untar_dir(\n    fname, dest, rename:bool=False, overwrite:bool=False\n):\n\nuntar file into dest, creating a directory if the root contains more than one item\n\ndef test_untar(foldername, rename=False, **kwargs):\n    with tempfile.TemporaryDirectory() as d:\n        nm = os.path.join(d, 'a')\n        shutil.make_archive(nm, 'gztar', **kwargs)\n        with tempfile.TemporaryDirectory() as d2:\n            d2 = Path(d2)\n            untar_dir(nm+'.tar.gz', d2, rename=rename)\n            test_eq(d2.ls(), [d2/foldername])\n\nIf the contents of fname contain just one file or directory, it is placed directly in dest:\n\n# using `base_dir` in `make_archive` results in `images` directory included in file names\ntest_untar('images', base_dir='images')\n\nIf rename then the directory created is named based on the archive, without extension:\n\ntest_untar('a', base_dir='images', rename=True)\n\nIf the contents of fname contain multiple files and directories, a new folder in dest is created with the same name as fname (but without extension):\n\n# using `root_dir` in `make_archive` results in `images` directory *not* included in file names\ntest_untar('a', root_dir='images')\n\n\nsource\n\n\n\n\ndef repo_details(\n    url\n):\n\nTuple of owner,name from ssh or https git repo url\n\ntest_eq(repo_details('https://github.com/fastai/fastai.git'), ['fastai', 'fastai'])\ntest_eq(repo_details('git@github.com:fastai/nbdev.git\\n'), ['fastai', 'nbdev'])\n\n\nsource\n\n\n\n\ndef shell(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nShortcut for subprocess.run(shell=True)\n\nsource\n\n\n\n\ndef ssh(\n    host, args:str='', user:str='ubuntu', sock:NoneType=None\n):\n\nRun SSH command with given arguments\n\nsource\n\n\n\n\ndef rsync_multi(\n    ip, files, user:str='ubuntu', persist:str='5m'\n):\n\nTransfer multiple files with rename using persistent SSH connection\n\nsource\n\n\n\n\ndef run(\n    cmd, rest:VAR_POSITIONAL, same_in_win:bool=False, ignore_ex:bool=False, as_bytes:bool=False, stderr:bool=True\n):\n\nPass cmd (splitting with shlex if string) to subprocess.run; return stdout; raise IOError if fails\nYou can pass a string (which will be split based on standard shell rules), a list, or pass args directly:\n\nrun('echo', same_in_win=True)\nrun('pip', '--version', same_in_win=True)\nrun(['pip', '--version'], same_in_win=True)\n\n'pip 25.3 from /Users/jhoward/aai-ws/.venv/lib/python3.12/site-packages/pip (python 3.12)'\n\n\n\nif sys.platform == 'win32':\n    assert 'ipynb' in run('cmd /c dir /p')\n    assert 'ipynb' in run(['cmd', '/c', 'dir', '/p'])\n    assert 'ipynb' in run('cmd', '/c', 'dir',  '/p')\nelse:\n    assert 'ipynb' in run('ls -ls')\n    assert 'ipynb' in run(['ls', '-l'])\n    assert 'ipynb' in run('ls', '-l')\n\nSome commands fail in non-error situations, like grep. Use ignore_ex in those cases, which will return a tuple of stdout and returncode:\n\nif sys.platform == 'win32':\n    test_eq(run('cmd /c findstr asdfds 00_test.ipynb', ignore_ex=True)[0], 1)\nelse:\n    test_eq(run('grep asdfds 00_test.ipynb', ignore_ex=True)[0], 1)\n\nrun automatically decodes returned bytes to a str. Use as_bytes to skip that:\n\nif sys.platform == 'win32':\n    test_eq(run('cmd /c echo hi'), 'hi')\nelse:\n    test_eq(run('echo hi', as_bytes=True), b'hi\\n')\n\n\nsource\n\n\n\n\ndef open_file(\n    fn, mode:str='r', kwargs:VAR_KEYWORD\n):\n\nOpen a file, with optional compression if gz or bz2 suffix\n\nsource\n\n\n\n\ndef save_pickle(\n    fn, o\n):\n\nSave a pickle file, to a file name or opened file\n\nsource\n\n\n\n\ndef load_pickle(\n    fn\n):\n\nLoad a pickle file from a file name or opened file\n\nfor suf in '.pkl','.bz2','.gz':\n    # delete=False is added for Windows\n    # https://stackoverflow.com/questions/23212435/permission-denied-to-write-to-my-temporary-file\n    with tempfile.NamedTemporaryFile(suffix=suf, delete=False) as f:\n        fn = Path(f.name)\n        save_pickle(fn, 't')\n        t = load_pickle(fn)\n    f.close()\n    test_eq(t,'t')\n\n\nsource\n\n\n\n\ndef parse_env(\n    s:str=None, fn:Union[str, Path]=None\n)-&gt;dict:\n\nParse a shell-style environment string or file\n\ntestf = \"\"\"# comment\n   # another comment\n export FOO=\"bar#baz\"\nBAR=thing # comment \"ok\"\n  baz='thong'\nQUX=quux\nexport ZAP = \"zip\" # more comments\n   FOOBAR = 42   # trailing space and comment\"\"\"\n\nexp = dict(FOO='bar#baz', BAR='thing', baz='thong', QUX='quux', ZAP='zip', FOOBAR='42')\n\ntest_eq(parse_env(testf),  exp)\n\n\nsource\n\n\n\n\ndef expand_wildcards(\n    code\n):\n\nExpand all wildcard imports in the given code string.\n\ninp = \"\"\"from math import *\nfrom os import *\nfrom random import *\ndef func(): return sin(pi) + path.join('a', 'b') + randint(1, 10)\"\"\"\n\nexp = \"\"\"from math import pi, sin\nfrom os import path\nfrom random import randint\ndef func(): return sin(pi) + path.join('a', 'b') + randint(1, 10)\"\"\"\n\ntest_eq(expand_wildcards(inp), exp)\n\ninp = \"\"\"from itertools import *\ndef func(): pass\"\"\"\ntest_eq(expand_wildcards(inp), inp)\n\ninp = \"\"\"def outer():\n    from math import *\n    def inner():\n        from os import *\n        return sin(pi) + path.join('a', 'b')\"\"\"\n\nexp = \"\"\"def outer():\n    from math import pi, sin\n    def inner():\n        from os import path\n        return sin(pi) + path.join('a', 'b')\"\"\"\n\ntest_eq(expand_wildcards(inp), exp)",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#file-functions",
    "href": "xtras.html#file-functions",
    "title": "Utility functions",
    "section": "",
    "text": "Utilities (other than extensions to Pathlib.Path) for dealing with IO.\n\nsource\n\n\n\ndef walk(\n    path:Path \\| str, # path to start searching\n    symlinks:bool=True, # follow symlinks?\n    keep_file:callable=&lt;function ret_true at 0x7f717bfc96c0&gt;, # function that returns True for wanted files\n    keep_folder:callable=&lt;function ret_true at 0x7f717bfc96c0&gt;, # function that returns True for folders to enter\n    skip_folder:callable=&lt;function ret_false at 0x7f717bfc9760&gt;, # function that returns True for folders to skip\n    func:callable=&lt;function join at 0x7f717c718cc0&gt;, # function to apply to each matched file\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n):\n\nGenerator version of os.walk, using functions to filter files and folders\n\nsource\n\n\n\n\ndef exttypes(\n    types\n):\n\nGet exts for comma-separated or list typ; if not found in list, return list with just types. Supported: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n\nprint(exttypes('py,doc'))\nprint(exttypes('zig,txt'))\n\n['ipynb', 'py', 'md', 'rst']\n['zig', 'txt']\n\n\n\nsource\n\n\n\n\ndef globtastic(\n    path:Path \\| str='.', # path to start searching\n    recursive:bool=True, # search subfolders\n    symlinks:bool=True, # follow symlinks?\n    file_glob:str=None, # Only include files matching glob\n    file_re:str=None, # Only include files matching regex\n    folder_re:str=None, # Only enter folders matching regex\n    skip_file_glob:str=None, # Skip files matching glob\n    skip_file_re:str=None, # Skip files matching regex\n    skip_folder_re:str=None, # Skip folders matching regex,\n    func:callable=&lt;function join at 0x7f717c718cc0&gt;, # function to apply to each matched file\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n    types:str \\| list=None, # list or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n    exts:str \\| list=None, # list or comma-separated str of exts to include\n)-&gt;L: # Paths to matched files\n\nA more powerful glob, including regex matches, symlink handling, and skip parameters\n\nglobtastic('.', skip_folder_re='^[_.]', folder_re='core', file_glob='*.*py*', file_re='c')\n\n['./fastcore/basics.py', './fastcore/dispatch.py', './fastcore/docments.py', './fastcore/docscrape.py', './fastcore/script.py']\n\n\n\nglobtastic(skip_folder_re='^[_.]', folder_re='core', types='py', file_re='c', skip_file_re='^_', sort=True)\n\n['./fastcore/all.py', './fastcore/ansi.py', './fastcore/basics.py', './fastcore/dispatch.py', './fastcore/docments.py', './fastcore/docscrape.py', './fastcore/foundation.py', './fastcore/imghdr.py', './fastcore/imports.py', './fastcore/meta.py', './fastcore/nb_imports.py', './fastcore/net.py', './fastcore/parallel.py', './fastcore/py2pyi.py', './fastcore/script.py', './fastcore/shutil.py', './fastcore/style.py', './fastcore/test.py', './fastcore/tools.py', './fastcore/transform.py', './fastcore/utils.py', './fastcore/xdg.py', './fastcore/xml.py', './fastcore/xtras.py']\n\n\n\nsource\n\n\n\n\ndef pglob(\n    path:Path \\| str='.', # path to start searching\n    func:callable=&lt;class 'pathlib.Path'&gt;, # function to apply to each matched file\n    recursive:bool=True, symlinks:bool=True, file_glob:str=None, file_re:str=None, folder_re:str=None,\n    skip_file_glob:str=None, skip_file_re:str=None, skip_folder_re:str=None, ret_folders:bool=False, sort:bool=True,\n    types:str \\| list=None, exts:str \\| list=None\n)-&gt;L: # Paths to matched files\n\nShortcut for globtastic(..., call=Path)\n\npglob('..', skip_folder_re='^[_.]', types='doc', skip_file_re='^_')[:6]\n\n[Path('../CHANGELOG.md'), Path('../CODE_OF_CONDUCT.md'), Path('../CONTRIBUTING.md'), Path('../README.md')]\n\n\n\nsource\n\n\n\n\ndef maybe_open(\n    f, mode:str='r', kwargs:VAR_KEYWORD\n):\n\nContext manager: open f if it is a path (and close on exit)\nThis is useful for functions where you want to accept a path or file. maybe_open will not close your file handle if you pass one in.\n\ndef _f(fn):\n    with maybe_open(fn) as f: return f.encoding\n\nfname = '00_test.ipynb'\nsys_encoding = 'cp1252' if sys.platform == 'win32' else 'utf-8'\ntest_eq(_f(fname).lower(), sys_encoding)\nwith open(fname) as fh: test_eq(_f(fh).lower(), sys_encoding)\n\nFor example, we can use this to reimplement imghdr.what from the Python standard library, which is written in Python 3.9 as:\n\nfrom fastcore import imghdr\n\n\ndef what(file, h=None):\n    f = None\n    try:\n        if h is None:\n            if isinstance(file, (str,os.PathLike)):\n                f = open(file, 'rb')\n                h = f.read(32)\n            else:\n                location = file.tell()\n                h = file.read(32)\n                file.seek(location)\n        for tf in imghdr.tests:\n            res = tf(h, f)\n            if res: return res\n    finally:\n        if f: f.close()\n    return None\n\nHere’s an example of the use of this function:\n\nfname = 'images/puppy.jpg'\nwhat(fname)\n\n'jpeg'\n\n\nWith maybe_open, Self, and L.map_first, we can rewrite this in a much more concise and (in our opinion) clear way:\n\ndef what(file, h=None):\n    if h is None:\n        with maybe_open(file, 'rb') as f: h = f.peek(32)\n    return L(imghdr.tests).map_first(Self(h,file))\n\n…and we can check that it still works:\n\ntest_eq(what(fname), 'jpeg')\n\n…along with the version passing a file handle:\n\nwith open(fname,'rb') as f: test_eq(what(f), 'jpeg')\n\n…along with the h parameter version:\n\nwith open(fname,'rb') as f: test_eq(what(None, h=f.read(32)), 'jpeg')\n\n\nsource\n\n\n\n\ndef mkdir(\n    path, exist_ok:bool=False, parents:bool=False, overwrite:bool=False, kwargs:VAR_KEYWORD\n):\n\nCreates and returns a directory defined by path, optionally removing previous existing directory if overwrite is True\n\nwith tempfile.TemporaryDirectory() as d:\n    path = Path(os.path.join(d, 'new_dir'))\n    new_dir = mkdir(path)\n    assert new_dir.exists()\n    test_eq(new_dir, path)\n        \n    # test overwrite\n    with open(new_dir/'test.txt', 'w') as f: f.writelines('test')\n    test_eq(len(list(walk(new_dir))), 1) # assert file is present\n    new_dir = mkdir(new_dir, overwrite=True)\n    test_eq(len(list(walk(new_dir))), 0) # assert file was deleted\n\n\nsource\n\n\n\n\ndef image_size(\n    fn\n):\n\nTuple of (w,h) for png, gif, or jpg; None otherwise\n\ntest_eq(image_size(fname), (1200,803))\n\n\nfrom PIL import Image\nfrom IPython.display import Image as IPImage\n\n\nimg = Image.new('RGB', (50, 50), color='red')\nimg\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n\ndef img_bytes(\n    img, fmt:str='PNG'\n):\n\n\nib = img_bytes(img)\nIPImage(ib)\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n\ndef detect_mime(\n    data\n):\n\nGet the MIME type for bytes data, covering common PDF, audio, video, and image types\n\ndetect_mime(ib)\n\n'image/png'\n\n\n\nsource\n\n\n\n\ndef bunzip(\n    fn\n):\n\nbunzip fn, raising exception if output already exists\n\nf = Path('files/test.txt')\nif f.exists(): f.unlink()\nbunzip('files/test.txt.bz2')\nt = f.open().readlines()\ntest_eq(len(t),1)\ntest_eq(t[0], 'test\\n')\nf.unlink()\n\n\nsource\n\n\n\n\ndef loads(\n    s, kw:VAR_KEYWORD\n):\n\nSame as json.loads, but handles None\n\nsource\n\n\n\n\ndef loads_multi(\n    s:str\n):\n\nGenerator of &gt;=0 decoded json dicts, possibly with non-json ignored text at start and end\n\ntst = \"\"\"\n# ignored\n{ \"a\":1 }\nhello\n{\n\"b\":2\n}\n\"\"\"\n\ntest_eq(list(loads_multi(tst)), [{'a': 1}, {'b': 2}])\n\n\nsource\n\n\n\n\ndef dumps(\n    obj, kw:VAR_KEYWORD\n):\n\nSame as json.dumps, but uses ujson if available\n\nsource\n\n\n\n\ndef untar_dir(\n    fname, dest, rename:bool=False, overwrite:bool=False\n):\n\nuntar file into dest, creating a directory if the root contains more than one item\n\ndef test_untar(foldername, rename=False, **kwargs):\n    with tempfile.TemporaryDirectory() as d:\n        nm = os.path.join(d, 'a')\n        shutil.make_archive(nm, 'gztar', **kwargs)\n        with tempfile.TemporaryDirectory() as d2:\n            d2 = Path(d2)\n            untar_dir(nm+'.tar.gz', d2, rename=rename)\n            test_eq(d2.ls(), [d2/foldername])\n\nIf the contents of fname contain just one file or directory, it is placed directly in dest:\n\n# using `base_dir` in `make_archive` results in `images` directory included in file names\ntest_untar('images', base_dir='images')\n\nIf rename then the directory created is named based on the archive, without extension:\n\ntest_untar('a', base_dir='images', rename=True)\n\nIf the contents of fname contain multiple files and directories, a new folder in dest is created with the same name as fname (but without extension):\n\n# using `root_dir` in `make_archive` results in `images` directory *not* included in file names\ntest_untar('a', root_dir='images')\n\n\nsource\n\n\n\n\ndef repo_details(\n    url\n):\n\nTuple of owner,name from ssh or https git repo url\n\ntest_eq(repo_details('https://github.com/fastai/fastai.git'), ['fastai', 'fastai'])\ntest_eq(repo_details('git@github.com:fastai/nbdev.git\\n'), ['fastai', 'nbdev'])\n\n\nsource\n\n\n\n\ndef shell(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nShortcut for subprocess.run(shell=True)\n\nsource\n\n\n\n\ndef ssh(\n    host, args:str='', user:str='ubuntu', sock:NoneType=None\n):\n\nRun SSH command with given arguments\n\nsource\n\n\n\n\ndef rsync_multi(\n    ip, files, user:str='ubuntu', persist:str='5m'\n):\n\nTransfer multiple files with rename using persistent SSH connection\n\nsource\n\n\n\n\ndef run(\n    cmd, rest:VAR_POSITIONAL, same_in_win:bool=False, ignore_ex:bool=False, as_bytes:bool=False, stderr:bool=True\n):\n\nPass cmd (splitting with shlex if string) to subprocess.run; return stdout; raise IOError if fails\nYou can pass a string (which will be split based on standard shell rules), a list, or pass args directly:\n\nrun('echo', same_in_win=True)\nrun('pip', '--version', same_in_win=True)\nrun(['pip', '--version'], same_in_win=True)\n\n'pip 25.3 from /Users/jhoward/aai-ws/.venv/lib/python3.12/site-packages/pip (python 3.12)'\n\n\n\nif sys.platform == 'win32':\n    assert 'ipynb' in run('cmd /c dir /p')\n    assert 'ipynb' in run(['cmd', '/c', 'dir', '/p'])\n    assert 'ipynb' in run('cmd', '/c', 'dir',  '/p')\nelse:\n    assert 'ipynb' in run('ls -ls')\n    assert 'ipynb' in run(['ls', '-l'])\n    assert 'ipynb' in run('ls', '-l')\n\nSome commands fail in non-error situations, like grep. Use ignore_ex in those cases, which will return a tuple of stdout and returncode:\n\nif sys.platform == 'win32':\n    test_eq(run('cmd /c findstr asdfds 00_test.ipynb', ignore_ex=True)[0], 1)\nelse:\n    test_eq(run('grep asdfds 00_test.ipynb', ignore_ex=True)[0], 1)\n\nrun automatically decodes returned bytes to a str. Use as_bytes to skip that:\n\nif sys.platform == 'win32':\n    test_eq(run('cmd /c echo hi'), 'hi')\nelse:\n    test_eq(run('echo hi', as_bytes=True), b'hi\\n')\n\n\nsource\n\n\n\n\ndef open_file(\n    fn, mode:str='r', kwargs:VAR_KEYWORD\n):\n\nOpen a file, with optional compression if gz or bz2 suffix\n\nsource\n\n\n\n\ndef save_pickle(\n    fn, o\n):\n\nSave a pickle file, to a file name or opened file\n\nsource\n\n\n\n\ndef load_pickle(\n    fn\n):\n\nLoad a pickle file from a file name or opened file\n\nfor suf in '.pkl','.bz2','.gz':\n    # delete=False is added for Windows\n    # https://stackoverflow.com/questions/23212435/permission-denied-to-write-to-my-temporary-file\n    with tempfile.NamedTemporaryFile(suffix=suf, delete=False) as f:\n        fn = Path(f.name)\n        save_pickle(fn, 't')\n        t = load_pickle(fn)\n    f.close()\n    test_eq(t,'t')\n\n\nsource\n\n\n\n\ndef parse_env(\n    s:str=None, fn:Union[str, Path]=None\n)-&gt;dict:\n\nParse a shell-style environment string or file\n\ntestf = \"\"\"# comment\n   # another comment\n export FOO=\"bar#baz\"\nBAR=thing # comment \"ok\"\n  baz='thong'\nQUX=quux\nexport ZAP = \"zip\" # more comments\n   FOOBAR = 42   # trailing space and comment\"\"\"\n\nexp = dict(FOO='bar#baz', BAR='thing', baz='thong', QUX='quux', ZAP='zip', FOOBAR='42')\n\ntest_eq(parse_env(testf),  exp)\n\n\nsource\n\n\n\n\ndef expand_wildcards(\n    code\n):\n\nExpand all wildcard imports in the given code string.\n\ninp = \"\"\"from math import *\nfrom os import *\nfrom random import *\ndef func(): return sin(pi) + path.join('a', 'b') + randint(1, 10)\"\"\"\n\nexp = \"\"\"from math import pi, sin\nfrom os import path\nfrom random import randint\ndef func(): return sin(pi) + path.join('a', 'b') + randint(1, 10)\"\"\"\n\ntest_eq(expand_wildcards(inp), exp)\n\ninp = \"\"\"from itertools import *\ndef func(): pass\"\"\"\ntest_eq(expand_wildcards(inp), inp)\n\ninp = \"\"\"def outer():\n    from math import *\n    def inner():\n        from os import *\n        return sin(pi) + path.join('a', 'b')\"\"\"\n\nexp = \"\"\"def outer():\n    from math import pi, sin\n    def inner():\n        from os import path\n        return sin(pi) + path.join('a', 'b')\"\"\"\n\ntest_eq(expand_wildcards(inp), exp)",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#collections",
    "href": "xtras.html#collections",
    "title": "Utility functions",
    "section": "Collections",
    "text": "Collections\n\nsource\n\ndict2obj\n\ndef dict2obj(\n    d:NoneType=None, list_func:_L_Meta=&lt;class 'fastcore.foundation.L'&gt;,\n    dict_func:type=&lt;class 'fastcore.basics.AttrDict'&gt;, kwargs:VAR_KEYWORD\n):\n\nConvert (possibly nested) dicts (or lists of dicts) to AttrDict\nThis is a convenience to give you “dotted” access to (possibly nested) dictionaries, e.g:\n\nd1 = dict(a=1, b=dict(c=2,d=3))\nd2 = dict2obj(d1)\ntest_eq(d2.b.c, 2)\ntest_eq(d2.b['c'], 2)\n\nkwargs can also be used:\n\nd3 = dict2obj(a=1, b=dict(c=2,d=3))\ntest_eq(d3.b.c, 2)\ntest_eq(d3.b['c'], 2)\n\nIt can also be used on lists of dicts.\n\n_list_of_dicts = [d1, d1]\nds = dict2obj(_list_of_dicts)\ntest_eq(ds[0].b.c, 2)\n\n\nsource\n\n\nobj2dict\n\ndef obj2dict(\n    d\n):\n\nConvert (possibly nested) AttrDicts (or lists of AttrDicts) to dict\nobj2dict can be used to reverse what is done by dict2obj:\n\ntest_eq(obj2dict(d2), d1)\ntest_eq(obj2dict(ds), _list_of_dicts)\n\n\nsource\n\n\nrepr_dict\n\ndef repr_dict(\n    d\n):\n\nPrint nested dicts and lists, such as returned by dict2obj\n\nprint(repr_dict(d2))\n\n- a: 1\n- b: \n  - c: 2\n  - d: 3\n\n\n\nsource\n\n\nis_listy\n\ndef is_listy(\n    x\n):\n\nisinstance(x, (tuple,list,L,slice,Generator))\n\nassert is_listy((1,))\nassert is_listy([1])\nassert is_listy(L([1]))\nassert is_listy(slice(2))\nassert not is_listy(array([1]))\n\n\nsource\n\n\nmapped\n\ndef mapped(\n    f, it\n):\n\nmap f over it, unless it’s not listy, in which case return f(it)\n\ndef _f(x,a=1): return x-a\n\ntest_eq(mapped(_f,1),0)\ntest_eq(mapped(_f,[1,2]),[0,1])\ntest_eq(mapped(_f,(1,)),(0,))",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#extensions-to-pathlib.path",
    "href": "xtras.html#extensions-to-pathlib.path",
    "title": "Utility functions",
    "section": "Extensions to Pathlib.Path",
    "text": "Extensions to Pathlib.Path\nThe following methods are added to the standard python libary Pathlib.Path.\n\nsource\n\nPath.readlines\n\ndef readlines(\n    hint:int=-1, encoding:str='utf8'\n):\n\nRead the content of self\n\nsource\n\n\nPath.read_json\n\ndef read_json(\n    encoding:NoneType=None, errors:NoneType=None\n):\n\nSame as read_text followed by loads\n\nsource\n\n\nPath.mk_write\n\ndef mk_write(\n    data, encoding:NoneType=None, errors:NoneType=None, mode:int=511, uid:int=-1, gid:int=-1\n):\n\nMake all parent dirs of self, and write data\n\nsource\n\n\nPath.write_json\n\ndef write_json(\n    data, encoding:NoneType=None, errors:NoneType=None, mode:int=511, uid:int=-1, gid:int=-1, kw:VAR_KEYWORD\n):\n\nSame as dumpsfollowed by mk_write\n\nsource\n\n\nPath.relpath\n\ndef relpath(\n    start:NoneType=None\n):\n\nSame as os.path.relpath, but returns a Path, and resolves symlinks\n\np = Path('../fastcore/').resolve()\np\n\nPath('/Users/jhoward/aai-ws/fastcore/fastcore')\n\n\n\np.relpath(Path.cwd())\n\nPath('../fastcore')\n\n\n\nsource\n\n\nPath.ls\n\ndef ls(\n    n_max:NoneType=None, file_type:NoneType=None, file_exts:NoneType=None\n):\n\nContents of path as a list\nWe add an ls() method to pathlib.Path which is simply defined as list(Path.iterdir()), mainly for convenience in REPL environments such as notebooks.\n\npath = Path()\nt = path.ls()\nassert len(t)&gt;0\nt1 = path.ls(10)\ntest_eq(len(t1), 10)\nt2 = path.ls(file_exts='.ipynb')\nassert len(t)&gt;len(t2)\nt[0]\n\nPath('llms.txt')\n\n\nYou can also pass an optional file_type MIME prefix and/or a list of file extensions.\n\nlib_path = (path/'../fastcore')\ntxt_files=lib_path.ls(file_type='text')\nassert len(txt_files) &gt; 0 and txt_files[0].suffix=='.py'\nipy_files=path.ls(file_exts=['.ipynb'])\nassert len(ipy_files) &gt; 0 and ipy_files[0].suffix=='.ipynb'\ntxt_files[0],ipy_files[0]\n\n(Path('../fastcore/shutil.py'), Path('000_tour.ipynb'))\n\n\n\nsource\n\n\nPath.normpath\n\ndef normpath(\n    \n):\n\nNormalize path, eliminating double slashes, etc.\nnormpath normalizes a path by collapsing redundant separators and up-level references (e.g., ..).\n\np = Path('foo//bar/../baz')\np.normpath()\n\nPath('foo/baz')\n\n\n\nsource\n\n\nPath.__repr__\n\ndef __repr__(\n    \n):\n\nReturn repr(self).\nfastai also updates the repr of Path such that, if Path.BASE_PATH is defined, all paths are printed relative to that path (as long as they are contained in Path.BASE_PATH:\n\nt = ipy_files[0].absolute()\ntry:\n    Path.BASE_PATH = t.parent.parent\n    test_eq(repr(t), f\"Path('nbs/{t.name}')\")\nfinally: Path.BASE_PATH = None\n\n\nsource\n\n\nPath.delete\n\ndef delete(\n    \n):\n\nDelete a file, symlink, or directory tree",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#reindexing-collections",
    "href": "xtras.html#reindexing-collections",
    "title": "Utility functions",
    "section": "Reindexing Collections",
    "text": "Reindexing Collections\n\nsource\n\nReindexCollection\n\ndef ReindexCollection(\n    coll, idxs:NoneType=None, cache:NoneType=None, tfm:function=&lt;function noop at 0x7f717c16cd60&gt;\n):\n\nReindexes collection coll with indices idxs and optional LRU cache of size cache\nThis is useful when constructing batches or organizing data in a particular manner (i.e. for deep learning). This class is primarly used in organizing data for language models in fastai.\nYou can supply a custom index upon instantiation with the idxs argument, or you can call the reindex method to supply a new index for your collection.\nHere is how you can reindex a list such that the elements are reversed:\n\nrc=ReindexCollection(['a', 'b', 'c', 'd', 'e'], idxs=[4,3,2,1,0])\nlist(rc)\n\n['e', 'd', 'c', 'b', 'a']\n\n\nAlternatively, you can use the reindex method:\n\nsource\n\nReindexCollection.reindex\n\ndef reindex(\n    idxs\n):\n\nReplace self.idxs with idxs\n\nrc=ReindexCollection(['a', 'b', 'c', 'd', 'e'])\nrc.reindex([4,3,2,1,0])\nlist(rc)\n\n['e', 'd', 'c', 'b', 'a']\n\n\nYou can optionally specify a LRU cache, which uses functools.lru_cache upon instantiation:\n\nsz = 50\nt = ReindexCollection(L.range(sz), cache=2)\n\n#trigger a cache hit by indexing into the same element multiple times\nt[0], t[0]\nt._get.cache_info()\n\nCacheInfo(hits=1, misses=1, maxsize=2, currsize=1)\n\n\nYou can optionally clear the LRU cache by calling the cache_clear method:\n\nsource\n\n\nReindexCollection.cache_clear\n\ndef cache_clear(\n    \n):\n\nClear LRU cache\n\nsz = 50\nt = ReindexCollection(L.range(sz), cache=2)\n\n#trigger a cache hit by indexing into the same element multiple times\nt[0], t[0]\nt.cache_clear()\nt._get.cache_info()\n\nCacheInfo(hits=0, misses=0, maxsize=2, currsize=0)\n\n\n\nsource\n\n\nReindexCollection.shuffle\n\ndef shuffle(\n    \n):\n\nRandomly shuffle indices\nNote that an ordered index is automatically constructed for the data structure even if one is not supplied.\n\nrc=ReindexCollection(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\nrc.shuffle()\nlist(rc)\n\n['b', 'a', 'g', 'h', 'd', 'e', 'c', 'f']\n\n\n\nsz = 50\nt = ReindexCollection(L.range(sz), cache=2)\ntest_eq(list(t), range(sz))\ntest_eq(t[sz-1], sz-1)\ntest_eq(t._get.cache_info().hits, 1)\nt.shuffle()\ntest_eq(t._get.cache_info().hits, 1)\ntest_ne(list(t), range(sz))\ntest_eq(set(t), set(range(sz)))\nt.cache_clear()\ntest_eq(t._get.cache_info().hits, 0)\ntest_eq(t.count(0), 1)",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#savereturn-and-save_iter-variants",
    "href": "xtras.html#savereturn-and-save_iter-variants",
    "title": "Utility functions",
    "section": "SaveReturn and save_iter Variants",
    "text": "SaveReturn and save_iter Variants\nThese utilities solve a common problem in Python: how to extract additional information from generator functions beyond just the yielded values.\nIn Python, generator functions can yield values and also return a final value, but the return value is normally lost when you iterate over the generator:\n\ndef example_generator():\n    total = 0\n    for i in range(3):\n        total += i\n        yield i\n    return total  # This gets lost!\n\n# The return value (3) is lost\nvalues = list(example_generator())  # [0, 1, 2]\n\n\nsource\n\nSaveReturn\n\ndef SaveReturn(\n    its\n):\n\nWrap an iterator such that the generator function’s return value is stored in .value\n\n\nExported source\nclass SaveReturn:\n    \"Wrap an iterator such that the generator function's return value is stored in `.value`\"\n    def __init__(self, its): self.its = its\n    def __iter__(self):\n        self.value = yield from self.its\n        return self.value\n\n\nSaveReturn is the simplest approach to solving this problem - it wraps any existing (non-async) generator and captures its return value. This works because yield from (used internally in SaveReturn) returns the value from the return of the generator function.\n\ndef sum_range(n):\n    total = 0\n    for i in range(n):\n        total += i\n        yield i\n    return total  # This value is returned by yield from\n\nsr = SaveReturn(sum_range(5))\nvalues = list(sr)  # This will consume the generator and get the return value\nprint(f\"Values: {values}\")\nsr.value\n\nValues: [0, 1, 2, 3, 4]\n\n\n10\n\n\nIn order to provide an accurate signature for save_iter, we need a version of wraps that removes leading parameters:\n\nsource\n\n\ntrim_wraps\n\ndef trim_wraps(\n    f, n:int=1\n):\n\nLike wraps, but removes the first n parameters from the signature\ntrim_wraps is a decorator factory that works like functools.wraps, but removes the first n parameters from the wrapped function’s signature. This is useful when creating wrapper functions that consume some parameters internally and shouldn’t expose them in the public API.\n\ndef adder(base, x, y): return base + x + y\n\ndef make_adder(base_value):\n    @trim_wraps(adder)\n    def _(x, y): return adder(base_value, x, y)\n    return _\n\nadd_10 = make_adder(10)\nprint(f\"{add_10.__name__}{inspect.signature(add_10)}\")\n\nadder(x, y)\n\n\n\nsource\n\n\nsave_iter\n\ndef save_iter(\n    g\n):\n\nDecorator that allows a generator function to store values in the returned iterator object\nsave_iter modifies generator functions to store state in the iterator object itself. The generator receives an object as its first parameter, which it can use to store attributes. You can store values during iteration, not just at the end, and you can store multiple attributes if needed.\n\n@save_iter\ndef sum_range(o, n):  # Note: 'o' parameter added\n    total = 0\n    for i in range(n):\n        total += i\n        yield i\n    o.value = total  # Store directly on the iterator object\n\nBecause iternally save_iter uses trim_wraps, the signature of sum_range correctly shows that you should not pass o to it; it’s injected by the decorating function.\n\nprint(sum_range.__signature__)\n\n(n)\n\n\n\nsr = sum_range(5)\nprint(f\"Values: {list(sr)}\")\nprint(f\"Sum stored: {sr.value}\")\n\nValues: [0, 1, 2, 3, 4]\nSum stored: 10\n\n\n\nsource\n\n\nasave_iter\n\ndef asave_iter(\n    g\n):\n\nLike save_iter, but for async iterators\nasave_iter provides the same functionality as save_iter, but for async generator functions. yield from and return can not be used with async generator functions, so SaveReturn can’t be used here.\n\n@asave_iter\nasync def asum_range(self, n):\n    total = 0\n    for i in range(n):\n        total += i\n        yield i\n    self.value = total\n\nasr = asum_range(5)\nprint(f\"Values: {[o async for o in asr]}\")\nprint(f\"Sum stored: {asr.value}\")\n\nValues: [0, 1, 2, 3, 4]\nSum stored: 10",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "xtras.html#other-helpers",
    "href": "xtras.html#other-helpers",
    "title": "Utility functions",
    "section": "Other Helpers",
    "text": "Other Helpers\n\nsource\n\nunqid\n\ndef unqid(\n    seeded:bool=False\n):\n\nGenerate a unique id suitable for use as a Python identifier\nunqid generates a random unique identifier that is safe to use as a Python variable name (starts with _, uses only alphanumeric characters and underscores). It’s based on UUID4, encoded in URL-safe base64.\nIf seeded=True, uses random.getrandbits which respects random.seed(), making it reproducible. Otherwise uses uuid4() which is always random.\n\nunqid()\n\n'_7WDcaL3JT7qV037u3Werzw'\n\n\nWith seeding for reproducibility:\n\nrandom.seed(42)\na = unqid(seeded=True)\nrandom.seed(42)\nb = unqid(seeded=True)\ntest_eq(a, b)\n\nWithout seeding - always unique:\n\ntest_ne(unqid(), unqid())\n\n\nsource\n\n\nrtoken_hex\n\ndef rtoken_hex(\n    nbytes:int=16, # Number of bytes to generate\n)-&gt;str: # hex string of length nbytes*2\n\nGenerate a random hex string using Python’s random module.\nThis is the same as secrets.token_hex, but is reproducible/seedable.\n\nimport secrets\n\n\nsecrets.token_hex(4),rtoken_hex(4)\n\n('408ea190', '8c7d7247')\n\n\n\nsource\n\n\nfriendly_name\n\ndef friendly_name(\n    levels:int=3, suffix:int=4\n):\n\nGenerate a random human-readable name with customizable word levels and suffix length\nfriendly_name generates random, human-readable names by combining adjectives, nouns, verbs, and adverbs with a random alphanumeric suffix. This is useful for creating memorable identifiers for temporary files, test data, or user-friendly resource names.\n\nfriendly_name()  # Default: 3 word levels + 4-char suffix\n\n'objective-forest-builds-0y6d'\n\n\nNames are hyphen-separated and follow the pattern adjective-noun-verb-adverb, randomly chosen from lists of size 102, 116, 110, and 30, respectively. The levels param selects how many of the names to include:\n\nfriendly_name(2)  # 2 words + 4-char suffix\n\n'lavender-hummingbird-divu'\n\n\nsuffix sets the length of the random alphanumeric ending. Each suffix item is taken from the 36 options of lowercase letters plus digits.\n\nfriendly_name(4, 6)  # All 4 word types + 6-char suffix\n\n'elated-koala-begins-softly-zpqk51'\n\n\n\nsource\n\n\nn_friendly_names\n\ndef n_friendly_names(\n    levels:int=3, suffix:int=4\n):\n\nNumber of possible combos for `friendly_names\nThe number of combinations if all levels are included is:\n\nprint(f'{n_friendly_names(4):,}')\n\n65,581,614,489,600\n\n\nThe default settings give:\n\nprint(f'{n_friendly_names():,}')\n\n2,186,053,816,320\n\n\n\nsource\n\n\nexec_eval\n\ndef exec_eval(\n    code, # Code to exec/eval\n    g:NoneType=None, # Globals namespace dict\n    l:NoneType=None, # Locals namespace dict\n):\n\nEvaluate code in g (defaults to globals()) and l (defaults to locals())\nThis is a combination of eval and exec, which behaves like ipython and Jupyter. If the last line is an expression, it is evaluated and the result is returned:\n\nexec_eval('''\ndef f(x): return x+1\nf(1)\n''')\n\n2\n\n\nBy default, the code uses the caller’s globals and locals. For instance, here f is available since it’s been added to our symbol table:\n\nexec_eval('print(f(2))')\n\n3\n\n\nPass a dict as the g param in order to use an arbitrary namespace:\n\nexec_eval('print(f)', {'f': 'Hi I am f.'})\n\nHi I am f.\n\n\nThis function helps us identify the first declared raw function of a dispatched function:\n\nfrom plum import Function\n\n\ndef f1(x): return \"Any\"\ndef f2(x:int): return \"Int\"\n\ndf = Function(f1).dispatch(f1).dispatch(f2)\n\ntest_eq(_unwrapped_type_dispatch_func(df), f1)\n\n\nsource\n\n\nget_source_link\n\ndef get_source_link(\n    func\n):\n\nReturn link to func in source code\nget_source_link allows you get a link to source code related to an object. For nbdev related projects such as fastcore, we can get the full link to a GitHub repo. For nbdev projects, be sure to properly set the git_url in settings.ini (derived from lib_name and branch on top of the prefix you will need to adapt) so that those links are correct.\nFor example, below we get the link to fastcore.test.test_eq:\n\nfrom fastcore.test import test_eq\n\n\nassert 'fastcore/test.py' in get_source_link(test_eq)\nassert get_source_link(test_eq).startswith('https://github.com/AnswerDotAI/fastcore')\nget_source_link(test_eq)\n\n'https://github.com/AnswerDotAI/fastcore/fastcore/test.py#L38'\n\n\n\nsource\n\n\nsparkline\n\ndef sparkline(\n    data, mn:NoneType=None, mx:NoneType=None, empty_zero:bool=False\n):\n\nSparkline for data, with Nones (and zero, if empty_zero) shown as empty column\n\ndata = [9,6,None,1,4,0,8,15,10]\nprint(f'without \"empty_zero\": {sparkline(data, empty_zero=False)}')\nprint(f'   with \"empty_zero\": {sparkline(data, empty_zero=True )}')\n\nwithout \"empty_zero\": ▅▂ ▁▂▁▃▇▅\n   with \"empty_zero\": ▅▂ ▁▂ ▃▇▅\n\n\nYou can set a maximum and minimum for the y-axis of the sparkline with the arguments mn and mx respectively:\n\nsparkline([1,2,3,400], mn=0, mx=3)\n\n'▂▅▇▇'\n\n\n\nsource\n\n\nmodify_exception\n\ndef modify_exception(\n    e:Exception, # An exception\n    msg:str=None, # A custom message\n    replace:bool=False, # Whether to replace e.args with [msg]\n)-&gt;Exception:\n\nModifies e with a custom message attached\n\nmsg = \"This is my custom message!\"\n\ntest_fail(lambda: (_ for _ in ()).throw(modify_exception(Exception(), None)), contains='')\ntest_fail(lambda: (_ for _ in ()).throw(modify_exception(Exception(), msg)), contains=msg)\ntest_fail(lambda: (_ for _ in ()).throw(modify_exception(Exception(\"The first message\"), msg)), contains=\"The first message This is my custom message!\")\ntest_fail(lambda: (_ for _ in ()).throw(modify_exception(Exception(\"The first message\"), msg, True)), contains=\"This is my custom message!\")\n\n\nsource\n\n\nround_multiple\n\ndef round_multiple(\n    x, mult, round_down:bool=False\n):\n\nRound x to nearest multiple of mult\n\ntest_eq(round_multiple(63,32), 64)\ntest_eq(round_multiple(50,32), 64)\ntest_eq(round_multiple(40,32), 32)\ntest_eq(round_multiple( 0,32),  0)\ntest_eq(round_multiple(63,32, round_down=True), 32)\ntest_eq(round_multiple((63,40),32), (64,32))\n\n\nsource\n\n\nset_num_threads\n\ndef set_num_threads(\n    nt\n):\n\nGet numpy (and others) to use nt threads\nThis sets the number of threads consistently for many tools, by:\n\nSet the following environment variables equal to nt: OPENBLAS_NUM_THREADS,NUMEXPR_NUM_THREADS,OMP_NUM_THREADS,MKL_NUM_THREADS\nSets nt threads for numpy and pytorch.\n\n\nsource\n\n\njoin_path_file\n\ndef join_path_file(\n    file, path, ext:str=''\n):\n\nReturn path/file if file is a string or a Path, file otherwise\n\npath = Path.cwd()/'_tmp'/'tst'\nf = join_path_file('tst.txt', path)\nassert path.exists()\ntest_eq(f, path/'tst.txt')\nwith open(f, 'w') as f_: assert join_path_file(f_, path) == f_\nshutil.rmtree(Path.cwd()/'_tmp')\n\n\nsource\n\n\nautostart\n\ndef autostart(\n    g\n):\n\nDecorator that automatically starts a generator\n\nsource\n\nEventTimer\n\ndef EventTimer(\n    store:int=5, span:int=60\n):\n\nAn event timer with history of store items of time span\nAdd events with add, and get number of events and their frequency (freq).\n\n# Random wait function for testing\ndef _randwait(): yield from (sleep(random.random()/200) for _ in range(100))\n\nc = EventTimer(store=5, span=0.03)\nfor o in _randwait(): c.add(1)\nprint(f'Num Events: {c.events}, Freq/sec: {c.freq:.01f}')\nprint('Most recent: ', sparkline(c.hist), *L(c.hist).map('{:.01f}'))\n\nNum Events: 1, Freq/sec: 73.6\nMost recent:  ▁▁▂▅▇ 33.0 26.9 54.1 89.8 120.6\n\n\n\nsource\n\n\n\nstringfmt_names\n\ndef stringfmt_names(\n    s:str\n)-&gt;list:\n\nUnique brace-delimited names in s\n\ns = '/pulls/{pull_number}/reviews/{review_id}'\ntest_eq(stringfmt_names(s), ['pull_number','review_id'])\n\n\nsource\n\nPartialFormatter\n\ndef PartialFormatter(\n    \n):\n\nA string.Formatter that doesn’t error on missing fields, and tracks missing fields and unused args\n\nsource\n\n\n\npartial_format\n\ndef partial_format(\n    s:str, kwargs:VAR_KEYWORD\n):\n\nstring format s, ignoring missing field errors, returning missing and extra fields\nThe result is a tuple of (formatted_string,missing_fields,extra_fields), e.g:\n\nres,missing,xtra = partial_format(s, pull_number=1, foo=2)\ntest_eq(res, '/pulls/1/reviews/{review_id}')\ntest_eq(missing, ['review_id'])\ntest_eq(xtra, {'foo':2})\n\n\nsource\n\n\ntruncstr\n\ndef truncstr(\n    s:str, maxlen:int, suf:str='…', space:str='', sizevar:str=None\n)-&gt;str:\n\nTruncate s to length maxlen, adding suffix suf if truncated\n\nw = 'abacadabra'\ntest_eq(truncstr(w, 10), w)\ntest_eq(truncstr(w, 5), 'abac…')\ntest_eq(truncstr(w, 5, suf=''), 'abaca')\ntest_eq(truncstr(w, 11, space='_'), w+\"_\")\ntest_eq(truncstr(w, 10, space='_'), w[:-1]+'…')\ntest_eq(truncstr(w, 5, suf='!!'), 'aba!!')\n\nsizevar lets you include the original string length in your suffix. E.g when you set sizevar='_n_', any {_n_} in your suffix gets replaced with the actual length of the string before truncation. For instance, here the (11) tells you the original string was 11 characters long:\n\ntest_eq(truncstr('hello world', 8, suf='…({_n_})', sizevar='_n_'), 'hel…(11)')\n\n\nsource\n\n\nutc2local\n\ndef utc2local(\n    dt:datetime\n)-&gt;datetime:\n\nConvert dt from UTC to local time\n\ndt = datetime(2000,1,1,12)\nprint(f'{dt} UTC is {utc2local(dt)} local time')\n\n2000-01-01 12:00:00 UTC is 2000-01-01 22:00:00+10:00 local time\n\n\n\nsource\n\n\nlocal2utc\n\ndef local2utc(\n    dt:datetime\n)-&gt;datetime:\n\nConvert dt from local to UTC time\n\nprint(f'{dt} local is {local2utc(dt)} UTC time')\n\n2000-01-01 12:00:00 local is 2000-01-01 02:00:00+00:00 UTC time\n\n\n\nsource\n\n\ntrace\n\ndef trace(\n    f\n):\n\nAdd set_trace to an existing function f\nYou can add a breakpoint to an existing function, e.g:\nPath.cwd = trace(Path.cwd)\nPath.cwd()\nNow, when the function is called it will drop you into the debugger. Note, you must issue the s command when you begin to step into the function that is being traced.\n\nsource\n\n\nmodified_env\n\ndef modified_env(\n    delete:VAR_POSITIONAL, replace:VAR_KEYWORD\n):\n\nContext manager temporarily modifying os.environ by deleting delete and replacing replace\n\n# USER isn't in Cloud Linux Environments\nenv_test = 'USERNAME' if sys.platform == \"win32\" else 'SHELL'\noldusr = os.environ[env_test]\n\nreplace_param = {env_test: 'a'}\nwith modified_env('PATH', **replace_param):\n    test_eq(os.environ[env_test], 'a')\n    assert 'PATH' not in os.environ\n\nassert 'PATH' in os.environ\ntest_eq(os.environ[env_test], oldusr)\n\n\nsource\n\nContextManagers\n\ndef ContextManagers(\n    mgrs\n):\n\nWrapper for contextlib.ExitStack which enters a collection of context managers\n\nsource\n\n\n\nshufflish\n\ndef shufflish(\n    x, pct:float=0.04\n):\n\nRandomly relocate items of x up to pct of len(x) from their starting location\n\nsource\n\n\nconsole_help\n\ndef console_help(\n    libname:str, # name of library for console script listing\n):\n\nShow help for all console scripts from libname\n\nsource\n\n\nhl_md\n\ndef hl_md(\n    s, lang:str='html', show:bool=True\n):\n\nSyntax highlight s using lang.\nWhen we display code in a notebook, it’s nice to highlight it, so we create a function to simplify that:\n\nhl_md('&lt;test&gt;&lt;xml foo=\"bar\"&gt;a child&lt;/xml&gt;&lt;/test&gt;')\n\n&lt;test&gt;&lt;xml foo=\"bar\"&gt;a child&lt;/xml&gt;&lt;/test&gt;\n\n\n\nsource\n\n\ntype2str\n\ndef type2str(\n    typ:type\n)-&gt;str:\n\nStringify typ\n\ntest_eq(type2str(Optional[float]), 'Union[float, None]')\n\n\nsource\n\n\ndataclass_src\n\ndef dataclass_src(\n    cls\n):\n\n\nDC = make_dataclass('DC', [('x', int), ('y', Optional[float], None), ('z', float, None)])\nprint(dataclass_src(DC))\n\n@dataclass\nclass DC:\n    x: int\n    y: Union[float, None] = None\n    z: float = None\n\n\n\n\nsource\n\n\nUnset\n\ndef Unset(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nCreate a collection of name/value pairs.\nExample enumeration:\n\n\n\nclass Color(Enum): … RED = 1 … BLUE = 2 … GREEN = 3\n\n\n\nAccess them by:\n\nattribute access:\n\n\n\nColor.RED &lt;Color.RED: 1&gt;\n\n\n\nvalue lookup:\n\n\n\nColor(1) &lt;Color.RED: 1&gt;\n\n\n\nname lookup:\n\n\n\nColor[‘RED’] &lt;Color.RED: 1&gt;\n\n\n\n\nEnumerations can be iterated over, and know how many members they have:\n\n\n\nlen(Color) 3\n\n\n\n\n\n\nlist(Color) [&lt;Color.RED: 1&gt;, &lt;Color.BLUE: 2&gt;, &lt;Color.GREEN: 3&gt;]\n\n\n\nMethods can be added to enumerations, and members can have their own attributes – see the documentation for details.\n\nsource\n\n\nnullable_dc\n\ndef nullable_dc(\n    cls\n):\n\nLike dataclass, but default of UNSET added to fields without defaults\n\n@nullable_dc\nclass Person: name: str; age: int; city: str = \"Unknown\"\nPerson(name=\"Bob\")\n\nPerson(name='Bob', age=UNSET, city='Unknown')\n\n\n\nsource\n\n\nmake_nullable\n\ndef make_nullable(\n    clas\n):\n\n\n@dataclass\nclass Person: name: str; age: int; city: str = \"Unknown\"\n\nmake_nullable(Person)\nPerson(\"Bob\", city='NY')\n\nPerson(name='Bob', age=UNSET, city='NY')\n\n\n\nPerson(name=\"Bob\")\n\nPerson(name='Bob', age=UNSET, city='Unknown')\n\n\n\nPerson(\"Bob\", 34)\n\nPerson(name='Bob', age=34, city='Unknown')\n\n\n\nsource\n\n\nflexiclass\n\ndef flexiclass(\n    cls, # The class to convert\n)-&gt;dataclass:\n\nConvert cls into a dataclass like make_nullable. Converts in place and also returns the result.\nThis can be used as a decorator…\n\n@flexiclass\nclass Person: name: str; age: int; city: str = \"Unknown\"\n\nbob = Person(name=\"Bob\")\nbob\n\nPerson(name='Bob', age=UNSET, city='Unknown')\n\n\n…or can update the behavior of an existing class (or dataclass):\n\nclass Person: name: str; age: int; city: str = \"Unknown\"\n\nflexiclass(Person)\nbob = Person(name=\"Bob\")\nbob\n\nPerson(name='Bob', age=UNSET, city='Unknown')\n\n\nAction occurs in-place:\n\nclass Person: name: str; age: int; city: str = \"Unknown\"\n\nflexiclass(Person)\nis_dataclass(Person)\n\nTrue\n\n\n\nsource\n\n\nasdict\n\ndef asdict(\n    o\n)-&gt;dict:\n\nConvert o to a dict, supporting dataclasses, namedtuples, iterables, and __dict__ attrs.\nAny UNSET values are not included.\n\nasdict(bob)\n\n{'name': 'Bob', 'city': 'Unknown'}\n\n\nSet the optional __flds__ parameter to customise the field list, and the optional __skip__ parameter to skip some names.\n\nclass CustomObj:\n    def __init__(self): self.a,self.b,self.c,self.d = 1,2,3,4\n    __flds__ = ['a','b','c','d']\n    __skip__ = ['b']\n\nobj = CustomObj()\ntest_eq(asdict(obj), {'a': 1, 'c': 3, 'd': 4})\n\nTo customise dict conversion behavior for a class, implement the _asdict method (this is used in the Python stdlib for named tuples).\n\nsource\n\n\nvars_pub\n\ndef vars_pub(\n    x\n):\n\nGet public non-skipped vars\nThe vars_pub function returns a list of public (non-underscore-prefixed) variable names from an object, excluding any names listed in the object’s optional __skip__ attribute.\n\nclass TestObj:\n    def __init__(self): self.pub_attr,self._priv_attr,self.another_pub,self.skip_me = 1,2,3,4\n    __skip__ = ['skip_me']\n\nobj = TestObj()\ntest_eq(vars_pub(obj), ['pub_attr', 'another_pub'])\n\nWithout __skip__, all pub vars are returned\n\nclass SimpleObj:\n    def __init__(self): self.a,self._b,self.c = 1,2,3\n\nsimple = SimpleObj()\ntest_eq(vars_pub(simple), ['a', 'c'])\n\n\nsource\n\n\nis_typeddict\n\ndef is_typeddict(\n    cls:type\n)-&gt;bool:\n\nCheck if cls is a TypedDict\n\nclass MyDict(TypedDict): name:str\n\nassert is_typeddict(MyDict)\nassert not is_typeddict({'a':1})\n\n\nsource\n\n\nis_namedtuple\n\ndef is_namedtuple(\n    cls\n):\n\nTrue if cls is a namedtuple type\n\nassert is_namedtuple(namedtuple('tst', ['a']))\nassert not is_namedtuple(tuple)\n\n\nsource\n\n\nCachedIter\n\ndef CachedIter(\n    o\n):\n\nCache the result returned by an iterator\n\ndef f():\n    yield 1\n    return 2\n\nr = CachedIter(f())\nfor o in r: print(o)\nr.value\n\n1\n\n\n2\n\n\n\nsource\n\n\nCachedAwaitable\n\ndef CachedAwaitable(\n    o\n):\n\nCache the result from an awaitable\n\nsource\n\n\nreawaitable\n\ndef reawaitable(\n    func:callable\n):\n\nWraps the result of an asynchronous function into an object which can be awaited more than once\nCachedCoro and reawaitable are partly based on python issue tracker code from Serhiy Storchaka. They allow an awaitable to be called multiple times.\n\n@reawaitable\nasync def fetch_data():\n    await asyncio.sleep(0.1)\n    return \"data\"\n\nr = fetch_data()\nprint(await r)  # \"data\"\nprint(await r)  # \"data\" (no delay)\n\ndata\ndata\n\n\n\nsource\n\n\nflexicache\n\ndef flexicache(\n    funcs:VAR_POSITIONAL, maxsize:int=128\n):\n\nLike lru_cache, but customisable with policy funcs\nThis is a flexible lru cache function that you can pass a list of functions to. Those functions define the cache eviction policy. For instance, time_policy is provided for time-based cache eviction, and mtime_policy evicts based on a file’s modified-time changing. The policy functions are passed the last value that function returned was (initially None), and return a new value to indicate the cache has expired. When the cache expires, all functions are called with None to force getting new values.\n\nsource\n\n\ntime_policy\n\ndef time_policy(\n    seconds\n):\n\nA flexicache policy that expires cached items after seconds have passed\n\nsource\n\n\nmtime_policy\n\ndef mtime_policy(\n    filepath\n):\n\nA flexicache policy that expires cached items after filepath modified-time changes\n\n@flexicache(time_policy(10), mtime_policy('000_tour.ipynb'))\ndef cached_func(x, y): return x+y\n\ncached_func(1,2)\n\n3\n\n\n\n@flexicache(time_policy(10), mtime_policy('000_tour.ipynb'))\nasync def cached_func(x, y): return x+y\n\nprint(await cached_func(1,2))\nawait cached_func(1,2)\n\n3\n\n\n3\n\n\n\nsource\n\n\ntimed_cache\n\ndef timed_cache(\n    seconds:int=60, maxsize:int=128\n):\n\nLike lru_cache, but also with time-based eviction\n\n# demonstrate that flexicache is LRU\n@flexicache(maxsize=2)\ndef cached_func(x): return time()\n\ntime_1 = cached_func(1)\ntest_eq(time_1, cached_func(1))\n\ntime_2 = cached_func(2)\ntest_eq(time_1, cached_func(1))\ntest_eq(time_2, cached_func(2))\n\ntime_3 = cached_func(3) # Removes 1\n\ntest_eq(time_2, cached_func(2)) # cache remains\ntest_eq(time_3, cached_func(3)) # cache remains\ntest_ne(time_1, cached_func(1)) # NEQ, removes 2\ntest_ne(time_2, cached_func(2))  # NEQ, removes 3\ntest_eq(cached_func(1), cached_func(1))\n\nThis function is a small convenience wrapper for using flexicache with time_policy.\n\n@timed_cache(seconds=0.05, maxsize=2)\ndef cached_func(x): return x * 2, time()\n\n# basic caching\nresult1, time1 = cached_func(2)\ntest_eq(result1, 4)\nsleep(0.001)\nresult2, time2 = cached_func(2)\ntest_eq(result2, 4)\ntest_eq(time1, time2)\n\n# caching different values\nresult3, _ = cached_func(3)\ntest_eq(result3, 6)\n\n# maxsize\n_, time4 = cached_func(4)\n_, time2_new = cached_func(2)\ntest_close(time2, time2_new, eps=0.1)\n_, time3_new = cached_func(3)\ntest_ne(time3_new, time())\n\n# time expiration\nsleep(0.05)\n_, time4_new = cached_func(4)\ntest_ne(time4_new, time())",
    "crumbs": [
      "Utility functions"
    ]
  },
  {
    "objectID": "py2pyi.html#basics",
    "href": "py2pyi.html#basics",
    "title": "Create delegated pyi",
    "section": "Basics",
    "text": "Basics\n\nsource\n\nimp_mod\n\ndef imp_mod(\n    module_path, package:NoneType=None\n):\n\nImport dynamically the module referenced in fn\n\nfn = Path('test_py2pyi.py')\n\n\nmod = imp_mod(fn)\na = mod.A()\na.h()\n\n1\n\n\n\ntree = _get_tree(mod)\n\n\n\n\nAST.__repr__\n\ndef __repr__(\n    \n):\n\n\n# for o in enumerate(tree.body): print(o)\n\n\nnode = tree.body[4]\nnode\n\ndef f(a: int, b: str='a') -&gt; str:\n    \"\"\"I am f\"\"\"\n    return 1\n\n\n\nisinstance(node, functypes)\n\nTrue\n\n\n\nsource\n\n\nhas_deco\n\ndef has_deco(\n    node:Union, name:str\n)-&gt;bool:\n\nCheck if a function node node has a decorator named name\n\nnm = 'delegates'\nhas_deco(node, nm)\n\nFalse\n\n\n\nnode = tree.body[5]\nnode\n\n@delegates(f)\ndef g(c, d: X, **kwargs) -&gt; str:\n    \"\"\"I am g\"\"\"\n    return 2\n\n\n\nhas_deco(node, nm)\n\nTrue",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "py2pyi.html#function-processing",
    "href": "py2pyi.html#function-processing",
    "title": "Create delegated pyi",
    "section": "Function processing",
    "text": "Function processing\n\ndef _proc_body   (node, mod): print('_proc_body', type(node))\ndef _proc_func   (node, mod): print('_proc_func', type(node))\ndef _proc_class  (node, mod): print('_proc_class', type(node))\ndef _proc_patched(node, mod): print('_proc_patched', type(node))\n\n\nparent_node = copy.deepcopy(tree.body[7])\npatched_node = copy.deepcopy(tree.body[10])\ntest_is(has_deco(patched_node, \"patch\"), True)\ntest_eq(str(patched_node.args.args[0].annotation), parent_node.name)\n\n_clean_patched_node(patched_node)\ntest_is(has_deco(patched_node, \"patch\"), False)\ntest_eq(patched_node.args.args[0].annotation, None)\n\n\nempty_cls1, empty_cls2, empty_cls3 = ast.parse('''\nclass A: \n    \"\"\"An empty class.\"\"\"\nclass B: \n    pass\nclass C: \n    ...\n''').body\n\ntest_is(_is_empty_class(empty_cls1), True)\ntest_is(_is_empty_class(empty_cls2), True)\ntest_is(_is_empty_class(empty_cls3), True)\n\nnon_empty_cls, empty_func = ast.parse('''\nclass A: \n    a = 1\ndef f():\n    ...\n''').body\ntest_is(_is_empty_class(non_empty_cls), False)\ntest_is(_is_empty_class(empty_func), False)\n\n\n# we could have reused `parent_node` and `patched_node` from the previous cells.\n# copying them here allows us to run this cell multiple times which makes it a little easier to write tests.\n\nparent_node = copy.deepcopy(tree.body[7])\npatched_node = copy.deepcopy(tree.body[11])\ntest_eq(len(parent_node.body),1)\n_add_patched_node_to_parent(patched_node, parent_node)\ntest_eq(len(parent_node.body),2)\ntest_eq(parent_node.body[-1], patched_node)\n\n# patched node replaces an existing class method (A.h)\npatched_h_node = ast.parse(\"\"\"\n@patch\ndef h(self: A, *args, **kwargs):\n    ...\n\"\"\", mode='single').body[0]\n\n_add_patched_node_to_parent(patched_h_node, parent_node)\ntest_eq(len(parent_node.body), 2)\ntest_eq(parent_node.body[0], patched_h_node)\n\n# patched node is added to an empty class\nempty_cls, patched_node = ast.parse('''\nclass Z: \n    \"\"\"An empty class.\"\"\"\n\n@patch\ndef a(self: Z, *args, **kwargs):\n    ...\n''').body\n\ntest_eq(len(empty_cls.body), 1)\ntest_ne(empty_cls.body[0], patched_node)\n_add_patched_node_to_parent(patched_node, empty_cls)\ntest_eq(len(empty_cls.body), 1)\ntest_eq(empty_cls.body[0], patched_node)\n\n\nraw_tree = _get_tree(mod)\nprocessed_tree = _proc_mod(mod)\nn_raw_tree_nodes = len(raw_tree.body)\n# mod contains 3 patch methods so our processed_tree should have 3 less nodes \ntest_eq(len(processed_tree.body), n_raw_tree_nodes-3)\n\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n_proc_func &lt;class 'ast.FunctionDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n\n\n\n_proc_mod(mod);\n\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n_proc_func &lt;class 'ast.FunctionDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_body &lt;class 'ast.FunctionDef'&gt;\n\n\n\nnode.name\n\n'g'\n\n\n\nsym = getattr(mod, node.name)\nsym\n\n&lt;function test_py2pyi.g(c, d: test_py2pyi.X, *, b: str = 'a') -&gt; str&gt;\n\n\n\nsig = signature(sym)\nprint(sig)\n\n(c, d: test_py2pyi.X, *, b: str = 'a') -&gt; str\n\n\n\nsource\n\nsig2str\n\ndef sig2str(\n    sig\n):\n\n\nsource\n\n\nast_args\n\ndef ast_args(\n    func\n):\n\n\nnewargs = ast_args(sym)\nnewargs\n\nc, d: test_py2pyi.X, *, b: str='a'\n\n\n\nnode.args\n\nc, d: X, **kwargs\n\n\n\nnode.args = newargs\nnode\n\n@delegates(f)\ndef g(c, d: test_py2pyi.X, *, b: str='a') -&gt; str:\n    \"\"\"I am g\"\"\"\n    return 2\n\n\n\n_body_ellip(node)\nnode\n\n@delegates(f)\ndef g(c, d: test_py2pyi.X, *, b: str='a') -&gt; str:\n    \"\"\"I am g\"\"\"\n    ...\n\n\n\ntree = _get_tree(mod)\nnode = tree.body[5]\nnode\n\n@delegates(f)\ndef g(c, d: X, **kwargs) -&gt; str:\n    \"\"\"I am g\"\"\"\n    return 2\n\n\n\n_update_func(node, sym)\nnode\n\ndef g(c, d: X, *, b: str='a') -&gt; str:\n    \"\"\"I am g\"\"\"\n    ...\n\n\n\ntree = _proc_mod(mod)\ntree.body[5]\n\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_class &lt;class 'ast.ClassDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n_proc_patched &lt;class 'ast.FunctionDef'&gt;\n\n\ndef g(c, d: X, *, b: str='a') -&gt; str:\n    \"\"\"I am g\"\"\"\n    ...",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "py2pyi.html#patch",
    "href": "py2pyi.html#patch",
    "title": "Create delegated pyi",
    "section": "Patch",
    "text": "Patch\n\ntree = _get_tree(mod)\nnode = tree.body[9]\nnode\n\n@patch\n@delegates(j)\ndef k(self: (A, B), b: bool=False, **kwargs):\n    return 1\n\n\n\nann = node.args.args[0].annotation\n\n\nif hasattr(ann, 'elts'): ann = ann.elts[0]\n\n\nnm = ann.id\nnm\n\n'A'\n\n\n\ncls = getattr(mod, nm)\nsym = getattr(cls, node.name)\n\n\nsig2str(signature(sym))\n\n\"(self: (test_py2pyi.A, test_py2pyi.B), b: bool = False, *, d: str = 'a')\"\n\n\n\n_update_func(node, sym)\n\n\nnode\n\n@patch\ndef k(self: (A, B), b: bool=False, *, d: str='a'):\n    ...\n\n\n\ntree = _get_tree(mod)\ntree.body[9]\n\n@patch\n@delegates(j)\ndef k(self: (A, B), b: bool=False, **kwargs):\n    return 1",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "py2pyi.html#class-and-file",
    "href": "py2pyi.html#class-and-file",
    "title": "Create delegated pyi",
    "section": "Class and file",
    "text": "Class and file\n\ntree = _get_tree(mod)\nnode = tree.body[7]\nnode\n\nclass A:\n\n    @delegates(j)\n    def h(self, b: bool=False, **kwargs):\n        a = 1\n        return a\n\n\n\nnode.body\n\n[@delegates(j)\n def h(self, b: bool=False, **kwargs):\n     a = 1\n     return a]\n\n\n\ntree = _proc_mod(mod)\ntree.body[7]\n\nclass A:\n\n    def h(self, b: bool=False, *, d: str='a'):\n        ...\n\n    def k(self, b: bool=False, *, d: str='a'):\n        ...\n\n    def m(self, b: bool=False, *, d: str='a'):\n        ...\n\n    def n(self, b: bool=False, **kwargs):\n        \"\"\"No delegates here mmm'k?\"\"\"\n        ...\n\n\n\nsource\n\ncreate_pyi\n\ndef create_pyi(\n    fn, package:NoneType=None\n):\n\nConvert fname.py to fname.pyi by removing function bodies and expanding delegates kwargs\n\ncreate_pyi(fn)\n\n\n# fn = Path('/Users/jhoward/git/fastcore/fastcore/docments.py')\n# create_pyi(fn, 'fastcore')",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "py2pyi.html#script",
    "href": "py2pyi.html#script",
    "title": "Create delegated pyi",
    "section": "Script",
    "text": "Script\n\nsource\n\npy2pyi\n\ndef py2pyi(\n    fname:str, # The file name to convert\n    package:str=None, # The parent package\n):\n\nConvert fname.py to fname.pyi by removing function bodies and expanding delegates kwargs\n\nsource\n\n\nreplace_wildcards\n\ndef replace_wildcards(\n    path:str, # Path to the Python file to process\n):\n\nExpand wildcard imports in the specified Python file.",
    "crumbs": [
      "Create delegated pyi"
    ]
  },
  {
    "objectID": "xdg.html",
    "href": "xdg.html",
    "title": "XDG",
    "section": "",
    "text": "See the XDG Base Directory Specification for more information.",
    "crumbs": [
      "XDG"
    ]
  },
  {
    "objectID": "xdg.html#overview",
    "href": "xdg.html#overview",
    "title": "XDG",
    "section": "Overview",
    "text": "Overview\nxdg_cache_home, xdg_config_home, xdg_data_home, and xdg_state_home return pathlib.Path objects containing the value of the environment variable named XDG_CACHE_HOME, XDG_CONFIG_HOME, XDG_DATA_HOME, and XDG_STATE_HOME respectively, or the default defined in the specification if the environment variable is unset, empty, or contains a relative path rather than absolute path.\nxdg_config_dirs and xdg_data_dirs return a list of pathlib.Path objects containing the value, split on colons, of the environment variable named XDG_CONFIG_DIRS and XDG_DATA_DIRS respectively, or the default defined in the specification if the environment variable is unset or empty. Relative paths are ignored, as per the specification.\nxdg_runtime_dir returns a pathlib.Path object containing the value of the XDG_RUNTIME_DIR environment variable, or None if the environment variable is not set, or contains a relative path rather than absolute path.",
    "crumbs": [
      "XDG"
    ]
  },
  {
    "objectID": "xdg.html#helpers",
    "href": "xdg.html#helpers",
    "title": "XDG",
    "section": "Helpers",
    "text": "Helpers\nWe’ll start by defining a context manager that temporarily sets an environment variable to demonstrate the behaviour of each helper function:\n\nfrom contextlib import contextmanager\n\n\n@contextmanager\ndef env(variable, value):\n    old = os.environ.get(variable, None)\n    try:\n        os.environ[variable] = value\n        yield\n    finally:\n        if old is None: del os.environ[variable]\n        else: os.environ[variable] = old\n\n\nsource\n\nxdg_cache_home\n\ndef xdg_cache_home(\n    \n):\n\nPath corresponding to XDG_CACHE_HOME\n\nfrom fastcore.test import *\n\n\ntest_eq(xdg_cache_home(), Path.home()/'.cache')\nwith env('XDG_CACHE_HOME', '/home/fastai/.cache'):\n    test_eq(xdg_cache_home(), Path('/home/fastai/.cache'))\n\n\nsource\n\n\nxdg_config_dirs\n\ndef xdg_config_dirs(\n    \n):\n\nPaths corresponding to XDG_CONFIG_DIRS\n\ntest_eq(xdg_config_dirs(), [Path('/etc/xdg')])\nwith env('XDG_CONFIG_DIRS', '/home/fastai/.xdg:/home/fastai/.config'):\n    test_eq(xdg_config_dirs(), [Path('/home/fastai/.xdg'), Path('/home/fastai/.config')])\n\n\nsource\n\n\nxdg_config_home\n\ndef xdg_config_home(\n    \n):\n\nPath corresponding to XDG_CONFIG_HOME\n\ntest_eq(xdg_config_home(), Path.home()/'.config')\nwith env('XDG_CONFIG_HOME', '/home/fastai/.config'):\n    test_eq(xdg_config_home(), Path('/home/fastai/.config'))\n\n\nsource\n\n\nxdg_data_dirs\n\ndef xdg_data_dirs(\n    \n):\n\nPaths corresponding to XDG_DATA_DIRS`\n\nsource\n\n\nxdg_data_home\n\ndef xdg_data_home(\n    \n):\n\nPath corresponding to XDG_DATA_HOME\n\ntest_eq(xdg_data_home(), Path.home()/'.local/share')\nwith env('XDG_DATA_HOME', '/home/fastai/.data'):\n    test_eq(xdg_data_home(), Path('/home/fastai/.data'))\n\n\nsource\n\n\nxdg_runtime_dir\n\ndef xdg_runtime_dir(\n    \n):\n\nPath corresponding to XDG_RUNTIME_DIR\n\nsource\n\n\nxdg_state_home\n\ndef xdg_state_home(\n    \n):\n\nPath corresponding to XDG_STATE_HOME\n\ntest_eq(xdg_state_home(), Path.home()/'.local/state')\nwith env('XDG_STATE_HOME', '/home/fastai/.state'):\n    test_eq(xdg_state_home(), Path('/home/fastai/.state'))\n\n\nCopyright © 2016-2021 Scott Stevenson scott@stevenson.io\nModifications copyright © 2022 onwards Jeremy Howard",
    "crumbs": [
      "XDG"
    ]
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Basic functionality",
    "section": "",
    "text": "source\n\n\n\ndef ifnone(\n    a, b\n):\n\nb if a is None else a\nSince b if a is None else a is such a common pattern, we wrap it in a function. However, be careful, because python will evaluate both a and b when calling ifnone (which it doesn’t do if using the if version directly).\n\ntest_eq(ifnone(None,1), 1)\ntest_eq(ifnone(2   ,1), 2)\n\n\nsource\n\n\n\n\ndef maybe_attr(\n    o, attr\n):\n\ngetattr(o,attr,o)\nReturn the attribute attr for object o. If the attribute doesn’t exist, then return the object o instead.\n\nclass myobj: myattr='foo'\n\ntest_eq(maybe_attr(myobj, 'myattr'), 'foo')\ntest_eq(maybe_attr(myobj, 'another_attr'), myobj)\n\n\nsource\n\n\n\n\ndef basic_repr(\n    flds:NoneType=None\n):\n\nMinimal __repr__\nIn types which provide rich display functionality in Jupyter, their __repr__ is also called in order to provide a fallback text representation. Unfortunately, this includes a memory address which changes on every invocation, making it non-deterministic. This causes diffs to get messy and creates conflicts in git. To fix this, put __repr__=basic_repr() inside your class.\n\nclass SomeClass: __repr__=basic_repr()\nrepr(SomeClass())\n\n'SomeClass()'\n\n\nIf you pass a list of attributes (flds) of an object, then this will generate a string with the name of each attribute and its corresponding value. The format of this string is key=value, where key is the name of the attribute, and value is the value of the attribute. For each value, attempt to use the __name__ attribute, otherwise fall back to using the value’s __repr__ when constructing the string.\n\nclass SomeClass:\n    a=1\n    b='foo'\n    __repr__=basic_repr('a,b')\n    __name__='some-class'\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\nNested objects work too:\n\nclass AnotherClass:\n    c=SomeClass()\n    d='bar'\n    __repr__=basic_repr(['c', 'd'])\n\nrepr(AnotherClass())\n\n\"AnotherClass(c=SomeClass(a=1, b='foo'), d='bar')\"\n\n\nInstance variables (but not class variables) are shown if basic_repr is called with no arguments:\n\nclass SomeClass:\n    def __init__(self, a=1, b='foo'): self.a,self.b = a,b\n    __repr__=basic_repr()\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\n\nsource\n\n\n\n\ndef BasicRepr(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nBase class for objects needing a basic __repr__\nAs a shortcut for creating a __repr__ for instance variables, you can inherit from BasicRepr:\n\nclass SomeClass(BasicRepr):\n    def __init__(self, a=1, b='foo'): self.a,self.b = a,b\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\n\nsource\n\n\n\n\ndef is_array(\n    x\n):\n\nTrue if x supports __array__ or iloc\n\nis_array(np.array(1)),is_array([1])\n\n(True, False)\n\n\n\nsource\n\n\n\n\ndef listify(\n    o:NoneType=None, rest:VAR_POSITIONAL, use_list:bool=False, match:NoneType=None\n):\n\nConvert o to a list\nConversion is designed to “do what you mean”, e.g:\n\ntest_eq(listify('hi'), ['hi'])\ntest_eq(listify(b'hi'), [b'hi'])\ntest_eq(listify(array(1)), [array(1)])\ntest_eq(listify(1), [1])\ntest_eq(listify([1,2]), [1,2])\ntest_eq(listify(range(3)), [0,1,2])\ntest_eq(listify(None), [])\ntest_eq(listify(1,2), [1,2])\n\n\narr = np.arange(9).reshape(3,3)\nlistify(arr)\n\n[array([[0, 1, 2],\n        [3, 4, 5],\n        [6, 7, 8]])]\n\n\n\nlistify(array([1,2]))\n\n[array([1, 2])]\n\n\nGenerators are turned into lists too:\n\ngen = (o for o in range(3))\ntest_eq(listify(gen), [0,1,2])\n\nUse match to provide a length to match:\n\ntest_eq(listify(1,match=3), [1,1,1])\n\nIf match is a sequence, it’s length is used:\n\ntest_eq(listify(1,match=range(3)), [1,1,1])\n\nIf the listified item is not of length 1, it must be the same length as match:\n\ntest_eq(listify([1,1,1],match=3), [1,1,1])\ntest_fail(lambda: listify([1,1],match=3))\n\n\nsource\n\n\n\n\ndef tuplify(\n    o, use_list:bool=False, match:NoneType=None\n):\n\nMake o a tuple\n\ntest_eq(tuplify(None),())\ntest_eq(tuplify([1,2,3]),(1,2,3))\ntest_eq(tuplify(1,match=[1,2,3]),(1,1,1))\n\n\nsource\n\n\n\n\ndef true(\n    x\n):\n\nTest whether x is truthy; collections with &gt;0 elements are considered True\n\n[(o,true(o)) for o in\n (array(0),array(1),array([0]),array([0,1]),1,0,'',None)]\n\n[(array(0), False),\n (array(1), True),\n (array([0]), True),\n (array([0, 1]), True),\n (1, True),\n (0, False),\n ('', False),\n (None, False)]\n\n\n\nsource\n\n\n\n\ndef NullType(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nAn object that is False and can be called, chained, and indexed\n\nbool(null.hi().there[3])\n\nFalse\n\n\n\nsource\n\n\n\n\ndef tonull(\n    x\n):\n\nConvert None to null\n\nbool(tonull(None).hi().there[3])\n\nFalse\n\n\n\nsource\n\n\n\n\ndef get_class(\n    nm, fld_names:VAR_POSITIONAL, sup:NoneType=None, doc:NoneType=None, funcs:NoneType=None, anno:NoneType=None,\n    flds:VAR_KEYWORD\n):\n\nDynamically create a class, optionally inheriting from sup, containing fld_names\n\n_t = get_class('_t', 'a', b=2, anno={'b':int})\nt = _t()\ntest_eq(t.a, None)\ntest_eq(t.b, 2)\nt = _t(1, b=3)\ntest_eq(t.a, 1)\ntest_eq(t.b, 3)\nt = _t(1, 3)\ntest_eq(t.a, 1)\ntest_eq(t.b, 3)\ntest_eq(t, pickle.loads(pickle.dumps(t)))\ntest_eq(_t.__annotations__, {'b':int, 'a':typing.Any})\nrepr(t)\n\n'_t(a=1, b=3)'\n\n\nMost often you’ll want to call mk_class, since it adds the class to your module. See mk_class for more details and examples of use (which also apply to get_class).\n\nsource\n\n\n\n\ndef mk_class(\n    nm, fld_names:VAR_POSITIONAL, sup:NoneType=None, doc:NoneType=None, funcs:NoneType=None, mod:NoneType=None,\n    anno:NoneType=None, flds:VAR_KEYWORD\n):\n\nCreate a class using get_class and add to the caller’s module\nAny kwargs will be added as class attributes, and sup is an optional (tuple of) base classes.\n\nmk_class('_t', a=1, sup=dict)\nt = _t()\ntest_eq(t.a, 1)\nassert(isinstance(t,dict))\n\nA __init__ is provided that sets attrs for any kwargs, and for any args (matching by position to fields), along with a __repr__ which prints all attrs. The docstring is set to doc. You can pass funcs which will be added as attrs with the function names.\n\ndef foo(self): return 1\nmk_class('_t', 'a', sup=dict, doc='test doc', funcs=foo)\n\nt = _t(3, b=2)\ntest_eq(t.a, 3)\ntest_eq(t.b, 2)\ntest_eq(t.foo(), 1)\ntest_eq(t.__doc__, 'test doc')\nt\n\n{}\n\n\n\nsource\n\n\n\n\ndef wrap_class(\n    nm, fld_names:VAR_POSITIONAL, sup:NoneType=None, doc:NoneType=None, funcs:NoneType=None, flds:VAR_KEYWORD\n):\n\nDecorator: makes function a method of a new class nm passing parameters to mk_class\n\n@wrap_class('_t', a=2)\ndef bar(self,x): return x+1\n\nt = _t()\ntest_eq(t.a, 2)\ntest_eq(t.bar(3), 4)\n\n\nsource\n\n\n\ndef ignore_exceptions(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nContext manager to ignore exceptions\n\nwith ignore_exceptions(): \n    # Exception will be ignored\n    raise Exception\n\n\nsource\n\n\n\n\n\ndef exec_local(\n    code, var_name\n):\n\nCall exec on code and return the var var_name\n\ntest_eq(exec_local(\"a=1\", \"a\"), 1)\n\n\nsource\n\n\n\n\ndef risinstance(\n    types, obj:NoneType=None\n):\n\nCurried isinstance but with args reversed\n\nassert risinstance(int, 1)\nassert not risinstance(str, 0)\nassert risinstance(int)(1)\nassert not risinstance(int)(None)\n\ntypes can also be strings:\n\nassert risinstance(('str','int'), 'a')\nassert risinstance('str', 'a')\nassert not risinstance('int', 'a')\n\n\nsource\n\n\n\n\ndef ver2tuple(\n    v:str\n)-&gt;tuple:\n\n\ntest_eq(ver2tuple('3.8.1'), (3,8,1))\ntest_eq(ver2tuple('3.1'), (3,1,0))\ntest_eq(ver2tuple('3.'), (3,0,0))\ntest_eq(ver2tuple('3'), (3,0,0))",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#basics",
    "href": "basics.html#basics",
    "title": "Basic functionality",
    "section": "",
    "text": "source\n\n\n\ndef ifnone(\n    a, b\n):\n\nb if a is None else a\nSince b if a is None else a is such a common pattern, we wrap it in a function. However, be careful, because python will evaluate both a and b when calling ifnone (which it doesn’t do if using the if version directly).\n\ntest_eq(ifnone(None,1), 1)\ntest_eq(ifnone(2   ,1), 2)\n\n\nsource\n\n\n\n\ndef maybe_attr(\n    o, attr\n):\n\ngetattr(o,attr,o)\nReturn the attribute attr for object o. If the attribute doesn’t exist, then return the object o instead.\n\nclass myobj: myattr='foo'\n\ntest_eq(maybe_attr(myobj, 'myattr'), 'foo')\ntest_eq(maybe_attr(myobj, 'another_attr'), myobj)\n\n\nsource\n\n\n\n\ndef basic_repr(\n    flds:NoneType=None\n):\n\nMinimal __repr__\nIn types which provide rich display functionality in Jupyter, their __repr__ is also called in order to provide a fallback text representation. Unfortunately, this includes a memory address which changes on every invocation, making it non-deterministic. This causes diffs to get messy and creates conflicts in git. To fix this, put __repr__=basic_repr() inside your class.\n\nclass SomeClass: __repr__=basic_repr()\nrepr(SomeClass())\n\n'SomeClass()'\n\n\nIf you pass a list of attributes (flds) of an object, then this will generate a string with the name of each attribute and its corresponding value. The format of this string is key=value, where key is the name of the attribute, and value is the value of the attribute. For each value, attempt to use the __name__ attribute, otherwise fall back to using the value’s __repr__ when constructing the string.\n\nclass SomeClass:\n    a=1\n    b='foo'\n    __repr__=basic_repr('a,b')\n    __name__='some-class'\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\nNested objects work too:\n\nclass AnotherClass:\n    c=SomeClass()\n    d='bar'\n    __repr__=basic_repr(['c', 'd'])\n\nrepr(AnotherClass())\n\n\"AnotherClass(c=SomeClass(a=1, b='foo'), d='bar')\"\n\n\nInstance variables (but not class variables) are shown if basic_repr is called with no arguments:\n\nclass SomeClass:\n    def __init__(self, a=1, b='foo'): self.a,self.b = a,b\n    __repr__=basic_repr()\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\n\nsource\n\n\n\n\ndef BasicRepr(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nBase class for objects needing a basic __repr__\nAs a shortcut for creating a __repr__ for instance variables, you can inherit from BasicRepr:\n\nclass SomeClass(BasicRepr):\n    def __init__(self, a=1, b='foo'): self.a,self.b = a,b\n\nrepr(SomeClass())\n\n\"SomeClass(a=1, b='foo')\"\n\n\n\nsource\n\n\n\n\ndef is_array(\n    x\n):\n\nTrue if x supports __array__ or iloc\n\nis_array(np.array(1)),is_array([1])\n\n(True, False)\n\n\n\nsource\n\n\n\n\ndef listify(\n    o:NoneType=None, rest:VAR_POSITIONAL, use_list:bool=False, match:NoneType=None\n):\n\nConvert o to a list\nConversion is designed to “do what you mean”, e.g:\n\ntest_eq(listify('hi'), ['hi'])\ntest_eq(listify(b'hi'), [b'hi'])\ntest_eq(listify(array(1)), [array(1)])\ntest_eq(listify(1), [1])\ntest_eq(listify([1,2]), [1,2])\ntest_eq(listify(range(3)), [0,1,2])\ntest_eq(listify(None), [])\ntest_eq(listify(1,2), [1,2])\n\n\narr = np.arange(9).reshape(3,3)\nlistify(arr)\n\n[array([[0, 1, 2],\n        [3, 4, 5],\n        [6, 7, 8]])]\n\n\n\nlistify(array([1,2]))\n\n[array([1, 2])]\n\n\nGenerators are turned into lists too:\n\ngen = (o for o in range(3))\ntest_eq(listify(gen), [0,1,2])\n\nUse match to provide a length to match:\n\ntest_eq(listify(1,match=3), [1,1,1])\n\nIf match is a sequence, it’s length is used:\n\ntest_eq(listify(1,match=range(3)), [1,1,1])\n\nIf the listified item is not of length 1, it must be the same length as match:\n\ntest_eq(listify([1,1,1],match=3), [1,1,1])\ntest_fail(lambda: listify([1,1],match=3))\n\n\nsource\n\n\n\n\ndef tuplify(\n    o, use_list:bool=False, match:NoneType=None\n):\n\nMake o a tuple\n\ntest_eq(tuplify(None),())\ntest_eq(tuplify([1,2,3]),(1,2,3))\ntest_eq(tuplify(1,match=[1,2,3]),(1,1,1))\n\n\nsource\n\n\n\n\ndef true(\n    x\n):\n\nTest whether x is truthy; collections with &gt;0 elements are considered True\n\n[(o,true(o)) for o in\n (array(0),array(1),array([0]),array([0,1]),1,0,'',None)]\n\n[(array(0), False),\n (array(1), True),\n (array([0]), True),\n (array([0, 1]), True),\n (1, True),\n (0, False),\n ('', False),\n (None, False)]\n\n\n\nsource\n\n\n\n\ndef NullType(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nAn object that is False and can be called, chained, and indexed\n\nbool(null.hi().there[3])\n\nFalse\n\n\n\nsource\n\n\n\n\ndef tonull(\n    x\n):\n\nConvert None to null\n\nbool(tonull(None).hi().there[3])\n\nFalse\n\n\n\nsource\n\n\n\n\ndef get_class(\n    nm, fld_names:VAR_POSITIONAL, sup:NoneType=None, doc:NoneType=None, funcs:NoneType=None, anno:NoneType=None,\n    flds:VAR_KEYWORD\n):\n\nDynamically create a class, optionally inheriting from sup, containing fld_names\n\n_t = get_class('_t', 'a', b=2, anno={'b':int})\nt = _t()\ntest_eq(t.a, None)\ntest_eq(t.b, 2)\nt = _t(1, b=3)\ntest_eq(t.a, 1)\ntest_eq(t.b, 3)\nt = _t(1, 3)\ntest_eq(t.a, 1)\ntest_eq(t.b, 3)\ntest_eq(t, pickle.loads(pickle.dumps(t)))\ntest_eq(_t.__annotations__, {'b':int, 'a':typing.Any})\nrepr(t)\n\n'_t(a=1, b=3)'\n\n\nMost often you’ll want to call mk_class, since it adds the class to your module. See mk_class for more details and examples of use (which also apply to get_class).\n\nsource\n\n\n\n\ndef mk_class(\n    nm, fld_names:VAR_POSITIONAL, sup:NoneType=None, doc:NoneType=None, funcs:NoneType=None, mod:NoneType=None,\n    anno:NoneType=None, flds:VAR_KEYWORD\n):\n\nCreate a class using get_class and add to the caller’s module\nAny kwargs will be added as class attributes, and sup is an optional (tuple of) base classes.\n\nmk_class('_t', a=1, sup=dict)\nt = _t()\ntest_eq(t.a, 1)\nassert(isinstance(t,dict))\n\nA __init__ is provided that sets attrs for any kwargs, and for any args (matching by position to fields), along with a __repr__ which prints all attrs. The docstring is set to doc. You can pass funcs which will be added as attrs with the function names.\n\ndef foo(self): return 1\nmk_class('_t', 'a', sup=dict, doc='test doc', funcs=foo)\n\nt = _t(3, b=2)\ntest_eq(t.a, 3)\ntest_eq(t.b, 2)\ntest_eq(t.foo(), 1)\ntest_eq(t.__doc__, 'test doc')\nt\n\n{}\n\n\n\nsource\n\n\n\n\ndef wrap_class(\n    nm, fld_names:VAR_POSITIONAL, sup:NoneType=None, doc:NoneType=None, funcs:NoneType=None, flds:VAR_KEYWORD\n):\n\nDecorator: makes function a method of a new class nm passing parameters to mk_class\n\n@wrap_class('_t', a=2)\ndef bar(self,x): return x+1\n\nt = _t()\ntest_eq(t.a, 2)\ntest_eq(t.bar(3), 4)\n\n\nsource\n\n\n\ndef ignore_exceptions(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nContext manager to ignore exceptions\n\nwith ignore_exceptions(): \n    # Exception will be ignored\n    raise Exception\n\n\nsource\n\n\n\n\n\ndef exec_local(\n    code, var_name\n):\n\nCall exec on code and return the var var_name\n\ntest_eq(exec_local(\"a=1\", \"a\"), 1)\n\n\nsource\n\n\n\n\ndef risinstance(\n    types, obj:NoneType=None\n):\n\nCurried isinstance but with args reversed\n\nassert risinstance(int, 1)\nassert not risinstance(str, 0)\nassert risinstance(int)(1)\nassert not risinstance(int)(None)\n\ntypes can also be strings:\n\nassert risinstance(('str','int'), 'a')\nassert risinstance('str', 'a')\nassert not risinstance('int', 'a')\n\n\nsource\n\n\n\n\ndef ver2tuple(\n    v:str\n)-&gt;tuple:\n\n\ntest_eq(ver2tuple('3.8.1'), (3,8,1))\ntest_eq(ver2tuple('3.1'), (3,1,0))\ntest_eq(ver2tuple('3.'), (3,0,0))\ntest_eq(ver2tuple('3'), (3,0,0))",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#noop",
    "href": "basics.html#noop",
    "title": "Basic functionality",
    "section": "NoOp",
    "text": "NoOp\nThese are used when you need a pass-through function.\n\n\nnoop\n\ndef noop(\n    x:NoneType=None, args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nDo nothing\n\nnoop()\ntest_eq(noop(1),1)\n\n\n\n\nnoops\n\ndef noops(\n    x:NoneType=None, args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nDo nothing (method)\n\nclass _t: foo=noops\ntest_eq(_t().foo(1),1)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#infinite-lists",
    "href": "basics.html#infinite-lists",
    "title": "Basic functionality",
    "section": "Infinite Lists",
    "text": "Infinite Lists\nThese lists are useful for things like padding an array or adding index column(s) to arrays.\nInf defines the following properties:\n\ncount: itertools.count()\nzeros: itertools.cycle([0])\nones : itertools.cycle([1])\nnones: itertools.cycle([None])\n\n\ntest_eq([o for i,o in zip(range(5), Inf.count)],\n        [0, 1, 2, 3, 4])\n\ntest_eq([o for i,o in zip(range(5), Inf.zeros)],\n        [0]*5)\n\ntest_eq([o for i,o in zip(range(5), Inf.ones)],\n        [1]*5)\n\ntest_eq([o for i,o in zip(range(5), Inf.nones)],\n        [None]*5)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#operator-functions",
    "href": "basics.html#operator-functions",
    "title": "Basic functionality",
    "section": "Operator Functions",
    "text": "Operator Functions\n\nsource\n\nin_\n\ndef in_(\n    x, a\n):\n\nTrue if x in a\n\n# test if element is in another\nassert in_('c', ('b', 'c', 'a'))\nassert in_(4, [2,3,4,5])\nassert in_('t', 'fastai')\ntest_fail(in_('h', 'fastai'))\n\n# use in_ as a partial\nassert in_('fastai')('t')\nassert in_([2,3,4,5])(4)\ntest_fail(in_('fastai')('h'))\n\nIn addition to in_, the following functions are provided matching the behavior of the equivalent versions in operator: lt gt le ge eq ne add sub mul truediv is_ is_not mod.\n\nlt(3,5),gt(3,5),is_(None,None),in_(0,[1,2]),mod(3,2)\n\n(True, False, True, False, 1)\n\n\nSimilarly to _in, they also have additional functionality: if you only pass one param, they return a partial function that passes that param as the second positional parameter.\n\nlt(5)(3),gt(5)(3),is_(None)(None),in_([1,2])(0),mod(2)(3)\n\n(True, False, True, False, 1)\n\n\n\nsource\n\n\nret_true\n\ndef ret_true(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nPredicate: always True\n\nassert ret_true(1,2,3)\nassert ret_true(False)\n\n\nsource\n\n\nret_false\n\ndef ret_false(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nPredicate: always False\n\nsource\n\n\nstop\n\ndef stop(\n    e:type=&lt;class 'StopIteration'&gt;\n):\n\nRaises exception e (by default StopIteration)\n\nsource\n\n\ngen\n\ndef gen(\n    func, seq, cond:function=&lt;function ret_true at 0x7f3e4b76bb00&gt;\n):\n\nLike (func(o) for o in seq if cond(func(o))) but handles StopIteration\n\ntest_eq(gen(noop, Inf.count, lt(5)),\n        range(5))\ntest_eq(gen(operator.neg, Inf.count, gt(-5)),\n        [0,-1,-2,-3,-4])\ntest_eq(gen(lambda o:o if o&lt;5 else stop(), Inf.count),\n        range(5))\n\n\nsource\n\n\nchunked\n\ndef chunked(\n    it, chunk_sz:NoneType=None, drop_last:bool=False, n_chunks:NoneType=None\n):\n\nReturn batches from iterator it of size chunk_sz (or return n_chunks total)\n\nsource\n\n\nchunked\n\ndef chunked(\n    it, chunk_sz:NoneType=None, drop_last:bool=False, n_chunks:NoneType=None, pad:bool=False, pad_val:NoneType=None\n):\n\nReturn batches from iterator it of size chunk_sz (or return n_chunks total)\nNote that you must pass either chunk_sz, or n_chunks, but not both.\n\nt = list(range(10))\ntest_eq(chunked(t,3),      [[0,1,2], [3,4,5], [6,7,8], [9]])\ntest_eq(chunked(t,3,True), [[0,1,2], [3,4,5], [6,7,8],    ])\n\nt = map(lambda o:stop() if o==6 else o, Inf.count)\ntest_eq(chunked(t,3), [[0, 1, 2], [3, 4, 5]])\nt = map(lambda o:stop() if o==7 else o, Inf.count)\ntest_eq(chunked(t,3), [[0, 1, 2], [3, 4, 5], [6]])\n\nt = np.arange(10)\ntest_eq(chunked(t,3),      [[0,1,2], [3,4,5], [6,7,8], [9]])\ntest_eq(chunked(t,3,True), [[0,1,2], [3,4,5], [6,7,8],    ])\n\ntest_eq(chunked([], 3),          [])\ntest_eq(chunked([], n_chunks=3), [])\n\nPass pad=True and an optional pad_val to pad the last chunk:\n\nt = list(range(10))\ntest_eq(chunked(t,3,pad=True), [[0,1,2], [3,4,5], [6,7,8], [9,None,None]])\ntest_eq(chunked(t,3,pad=True,pad_val=0), [[0,1,2], [3,4,5], [6,7,8], [9,0,0]])\ntest_eq(chunked(t,4,pad=True,pad_val=-1), [[0,1,2,3], [4,5,6,7], [8,9,-1,-1]])\ntest_eq(chunked(range(5),2,pad=True), [[0,1], [2,3], [4,None]])\n\n\nsource\n\n\notherwise\n\ndef otherwise(\n    x, tst, y\n):\n\ny if tst(x) else x\n\ntest_eq(otherwise(2+1, gt(3), 4), 3)\ntest_eq(otherwise(2+1, gt(2), 4), 4)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#attribute-helpers",
    "href": "basics.html#attribute-helpers",
    "title": "Basic functionality",
    "section": "Attribute Helpers",
    "text": "Attribute Helpers\nThese functions reduce boilerplate when setting or manipulating attributes or properties of objects.\n\nsource\n\ncustom_dir\n\ndef custom_dir(\n    c, add\n):\n\nImplement custom __dir__, adding add to cls\ncustom_dir allows you extract the __dict__ property of a class and appends the list add to it.\n\nclass _T: \n    def f(): pass\n\ns = custom_dir(_T(), add=['foo', 'bar'])\nassert {'foo', 'bar', 'f'}.issubset(s)\n\n\nsource\n\n\nAttrDict\n\ndef AttrDict(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\ndict subclass that also provides access to keys as attrs\n\nd = AttrDict(a=1,b=\"two\")\ntest_eq(d.a, 1)\ntest_eq(d['b'], 'two')\ntest_eq(d.get('c','nope'), 'nope')\nd.b = 2\ntest_eq(d.b, 2)\ntest_eq(d['b'], 2)\nd['b'] = 3\ntest_eq(d['b'], 3)\ntest_eq(d.b, 3)\nassert 'a' in dir(d)\n\nAttrDict will pretty print in Jupyter Notebooks:\n\n_test_dict = {'a':1, 'b': {'c':1, 'd':2}, 'c': {'c':1, 'd':2}, 'd': {'c':1, 'd':2},\n              'e': {'c':1, 'd':2}, 'f': {'c':1, 'd':2, 'e': 4, 'f':[1,2,3,4,5]}}\nAttrDict(_test_dict)\n\n{ 'a': 1,\n  'b': {'c': 1, 'd': 2},\n  'c': {'c': 1, 'd': 2},\n  'd': {'c': 1, 'd': 2},\n  'e': {'c': 1, 'd': 2},\n  'f': {'c': 1, 'd': 2, 'e': 4, 'f': [1, 2, 3, 4, 5]}}\n\n\n\nsource\n\n\nAttrDictDefault\n\ndef AttrDictDefault(\n    args:VAR_POSITIONAL, default_:NoneType=None, kwargs:VAR_KEYWORD\n):\n\nAttrDict subclass that returns None for missing attrs\n\nd = AttrDictDefault(a=1,b=\"two\", default_='nope')\ntest_eq(d.a, 1)\ntest_eq(d['b'], 'two')\ntest_eq(d.c, 'nope')\n\n\nsource\n\n\nNS\n\ndef NS(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nSimpleNamespace subclass that also adds iter and dict support\nThis is very similar to AttrDict, but since it starts with SimpleNamespace, it has some differences in behavior. You can use it just like SimpleNamespace:\n\nd = NS(**_test_dict)\nd\n\nnamespace(a=1,\n          b={'c': 1, 'd': 2},\n          c={'c': 1, 'd': 2},\n          d={'c': 1, 'd': 2},\n          e={'c': 1, 'd': 2},\n          f={'c': 1, 'd': 2, 'e': 4, 'f': [1, 2, 3, 4, 5]})\n\n\n…but you can also index it to get/set:\n\nd['a']\n\n1\n\n\n…and iterate t:\n\nlist(d)\n\n['a', 'b', 'c', 'd', 'e', 'f']\n\n\n\nsource\n\n\nget_annotations_ex\n\ndef get_annotations_ex(\n    obj, globals:NoneType=None, locals:NoneType=None\n):\n\nBackport of py3.10 get_annotations that returns globals/locals\nIn Python 3.10 inspect.get_annotations was added. However previous versions of Python are unable to evaluate type annotations correctly if from future import __annotations__ is used. Furthermore, all annotations are evaluated, even if only some subset are needed. get_annotations_ex provides the same functionality as inspect.get_annotations, but works on earlier versions of Python, and returns the globals and locals needed to evaluate types.\n\nsource\n\n\neval_type\n\ndef eval_type(\n    t, glb, loc\n):\n\neval a type or collection of types, if needed, for annotations in py3.10+\nIn py3.10, or if from future import __annotations__ is used, a is a str:\n\nclass _T2a: pass\ndef func(a: _T2a): pass\nann,glb,loc = get_annotations_ex(func)\n\neval_type(ann['a'], glb, loc)\n\n__main__._T2a\n\n\n| is supported for defining Union types when using eval_type even for python versions prior to 3.9:\n\nclass _T2b: pass\ndef func(a: _T2a|_T2b): pass\nann,glb,loc = get_annotations_ex(func)\n\neval_type(ann['a'], glb, loc)\n\ntyping.Union[__main__._T2a, __main__._T2b]\n\n\n\nsource\n\n\ntype_hints\n\ndef type_hints(\n    f\n):\n\nLike typing.get_type_hints but returns {} if not allowed type\n\ndef type_hints(f):\n    \"Like `typing.get_type_hints` but returns `{}` if not allowed type\"\n    if not isinstance(f, _allowed_types): return {}\n    ann,glb,loc = get_annotations_ex(f)\n    return {k:_eval_type(v,glb,loc) for k,v in ann.items()}\n\nFor example, type func is allowed so type_hints returns the same value as typing.get_hints:\n\ndef f(a:int)-&gt;bool: ... # a function with type hints (allowed)\nexp = {'a':int,'return':bool}\ntest_eq(type_hints(f), typing.get_type_hints(f))\ntest_eq(type_hints(f), exp)\n\nHowever, class is not an allowed type, so type_hints returns {}:\n\nclass _T:\n    def __init__(self, a:int=0)-&gt;bool: ...\nassert not type_hints(_T)\n\n\nsource\n\n\nannotations\n\ndef annotations(\n    o\n):\n\nAnnotations for o, or type(o)\nThis supports a wider range of situations than type_hints, by checking type() and __init__ for annotations too:\n\nfor o in _T,_T(),_T.__init__,f: test_eq(annotations(o), exp)\nassert not annotations(int)\nassert not annotations(print)\n\n\nsource\n\n\nanno_ret\n\ndef anno_ret(\n    func\n):\n\nGet the return annotation of func\n\ndef f(x) -&gt; float: return x\ntest_eq(anno_ret(f), float)\n\ndef f(x) -&gt; typing.Tuple[float,float]: return x\nassert anno_ret(f)==typing.Tuple[float,float]\n\nIf your return annotation is None, anno_ret will return NoneType (and not None):\n\ndef f(x) -&gt; None: return x\n\ntest_eq(anno_ret(f), NoneType)\nassert anno_ret(f) is not None # returns NoneType instead of None\n\nIf your function does not have a return type, or if you pass in None instead of a function, then anno_ret returns None:\n\ndef f(x): return x\n\ntest_eq(anno_ret(f), None)\ntest_eq(anno_ret(None), None) # instead of passing in a func, pass in None\n\n\nsource\n\n\nsignature_ex\n\ndef signature_ex(\n    obj, eval_str:bool=False\n):\n\nBackport of inspect.signature(..., eval_str=True to &lt;py310\n\nsource\n\n\nunion2tuple\n\ndef union2tuple(\n    t\n):\n\n\ntest_eq(union2tuple(Union[int,str]), (int,str))\ntest_eq(union2tuple(int), int)\nassert union2tuple(Tuple[int,str])==Tuple[int,str]\ntest_eq(union2tuple((int,str)), (int,str))\nif UnionType: test_eq(union2tuple(int|str), (int,str))\n\n\nsource\n\n\nargnames\n\ndef argnames(\n    f, frame:bool=False\n):\n\nNames of arguments to function or frame f\n\ntest_eq(argnames(f), ['x'])\n\n\nsource\n\n\nwith_cast\n\ndef with_cast(\n    f\n):\n\nDecorator which uses any parameter annotations as preprocessing functions\n\n@with_cast\ndef _f(a, b:Path, c:str='', d=0): return (a,b,c,d)\n\ntest_eq(_f(1, '.', 3), (1,Path('.'),'3',0))\ntest_eq(_f(1, '.'), (1,Path('.'),'',0))\n\n@with_cast\ndef _g(a:int=0)-&gt;str: return a\n\ntest_eq(_g(4.0), '4')\ntest_eq(_g(4.4), '4')\ntest_eq(_g(2), '2')\n\n\nsource\n\n\nstore_attr\n\ndef store_attr(\n    names:NoneType=None, but:str='', cast:bool=False, store_args:NoneType=None, attrs:VAR_KEYWORD\n):\n\nStore params named in comma-separated names from calling context into attrs in self\nIn it’s most basic form, you can use store_attr to shorten code like this:\n\nclass T:\n    def __init__(self, a,b,c): self.a,self.b,self.c = a,b,c\n\n…to this:\n\nclass T:\n    def __init__(self, a,b,c): store_attr('a,b,c', self)\n\nThis class behaves as if we’d used the first form:\n\nt = T(1,c=2,b=3)\nassert t.a==1 and t.b==3 and t.c==2\n\n\nclass T1:\n    def __init__(self, a,b,c): store_attr()\n\nIn addition, it stores the attrs as a dict in __stored_args__, which you can use for display, logging, and so forth.\n\ntest_eq(t.__stored_args__, {'a':1, 'b':3, 'c':2})\n\nSince you normally want to use the first argument (often called self) for storing attributes, it’s optional:\n\nclass T:\n    def __init__(self, a,b,c:str): store_attr('a,b,c')\n\nt = T(1,c=2,b=3)\nassert t.a==1 and t.b==3 and t.c==2\n\nWith cast=True any parameter annotations will be used as preprocessing functions for the corresponding arguments:\n\nclass T:\n    def __init__(self, a:listify, b, c:str): store_attr('a,b,c', cast=True)\n\nt = T(1,c=2,b=3)\nassert t.a==[1] and t.b==3 and t.c=='2'\n\nYou can inherit from a class using store_attr, and just call it again to add in any new attributes added in the derived class:\n\nclass T2(T):\n    def __init__(self, d, **kwargs):\n        super().__init__(**kwargs)\n        store_attr('d')\n\nt = T2(d=1,a=2,b=3,c=4)\nassert t.a==2 and t.b==3 and t.c==4 and t.d==1\n\nYou can skip passing a list of attrs to store. In this case, all arguments passed to the method are stored:\n\nclass T:\n    def __init__(self, a,b,c): store_attr()\n\nt = T(1,c=2,b=3)\nassert t.a==1 and t.b==3 and t.c==2\n\n\nclass T4(T):\n    def __init__(self, d, **kwargs):\n        super().__init__(**kwargs)\n        store_attr()\n\nt = T4(4, a=1,c=2,b=3)\nassert t.a==1 and t.b==3 and t.c==2 and t.d==4\n\n\nclass T4:\n    def __init__(self, *, a: int, b: float = 1):\n        store_attr()\n        \nt = T4(a=3)\nassert t.a==3 and t.b==1\nt = T4(a=3, b=2)\nassert t.a==3 and t.b==2\n\nYou can skip some attrs by passing but:\n\nclass T:\n    def __init__(self, a,b,c): store_attr(but='a')\n\nt = T(1,c=2,b=3)\nassert t.b==3 and t.c==2\nassert not hasattr(t,'a')\n\nYou can also pass keywords to store_attr, which is identical to setting the attrs directly, but also stores them in __stored_args__.\n\nclass T:\n    def __init__(self): store_attr(a=1)\n\nt = T()\nassert t.a==1\n\nYou can also use store_attr inside functions.\n\ndef create_T(a, b):\n    t = SimpleNamespace()\n    store_attr(self=t)\n    return t\n\nt = create_T(a=1, b=2)\nassert t.a==1 and t.b==2\n\n\nsource\n\n\nattrdict\n\ndef attrdict(\n    o, ks:VAR_POSITIONAL, default:NoneType=None\n):\n\nDict from each k in ks to getattr(o,k)\n\nclass T:\n    def __init__(self, a,b,c): store_attr()\n\nt = T(1,c=2,b=3)\ntest_eq(attrdict(t,'b','c'), {'b':3, 'c':2})\n\n\nsource\n\n\nproperties\n\ndef properties(\n    cls, ps:VAR_POSITIONAL\n):\n\nChange attrs in cls with names in ps to properties\n\nclass T:\n    def a(self): return 1\n    def b(self): return 2\nproperties(T,'a')\n\ntest_eq(T().a,1)\ntest_eq(T().b(),2)\n\n\nsource\n\n\ncamel2words\n\ndef camel2words(\n    s, space:str=' '\n):\n\nConvert CamelCase to ‘spaced words’\n\ntest_eq(camel2words('ClassAreCamel'), 'Class Are Camel')\n\n\nsource\n\n\ncamel2snake\n\ndef camel2snake(\n    name\n):\n\nConvert CamelCase to snake_case\n\ntest_eq(camel2snake('ClassAreCamel'), 'class_are_camel')\ntest_eq(camel2snake('Already_Snake'), 'already__snake')\n\n\nsource\n\n\nsnake2camel\n\ndef snake2camel(\n    s\n):\n\nConvert snake_case to CamelCase\n\ntest_eq(snake2camel('a_b_cc'), 'ABCc')\n\n\nsource\n\n\nclass2attr\n\ndef class2attr(\n    cls_name\n):\n\nReturn the snake-cased name of the class; strip ending cls_name if it exists.\n\nclass Parent:\n    @property\n    def name(self): return class2attr(self, 'Parent')\n\nclass ChildOfParent(Parent): pass\nclass ParentChildOf(Parent): pass\n\np = Parent()\ncp = ChildOfParent()\ncp2 = ParentChildOf()\n\ntest_eq(p.name, 'parent')\ntest_eq(cp.name, 'child_of')\ntest_eq(cp2.name, 'parent_child_of')\n\n\nsource\n\n\ngetcallable\n\ndef getcallable(\n    o, attr\n):\n\nCalls getattr with a default of noop\n\nclass Math:\n    def addition(self,a,b): return a+b\n\nm = Math()\n\ntest_eq(getcallable(m, \"addition\")(a=1,b=2), 3)\ntest_eq(getcallable(m, \"subtraction\")(a=1,b=2), None)\n\n\nsource\n\n\ngetattrs\n\ndef getattrs(\n    o, attrs:VAR_POSITIONAL, default:NoneType=None\n):\n\nList of all attrs in o\n\nfrom fractions import Fraction\n\n\ngetattrs(Fraction(1,2), 'numerator', 'denominator')\n\n[1, 2]\n\n\n\nsource\n\n\nhasattrs\n\ndef hasattrs(\n    o, attrs\n):\n\nTest whether o contains all attrs\n\nassert hasattrs(1,('imag','real'))\nassert not hasattrs(1,('imag','foo'))\n\n\nsource\n\n\nsetattrs\n\ndef setattrs(\n    dest, flds, src\n):\n\n\nd = dict(a=1,bb=\"2\",ignore=3)\no = SimpleNamespace()\nsetattrs(o, \"a,bb\", d)\ntest_eq(o.a, 1)\ntest_eq(o.bb, \"2\")\n\n\nd = SimpleNamespace(a=1,bb=\"2\",ignore=3)\no = SimpleNamespace()\nsetattrs(o, \"a,bb\", d)\ntest_eq(o.a, 1)\ntest_eq(o.bb, \"2\")\n\n\nsource\n\n\ntry_attrs\n\ndef try_attrs(\n    obj, attrs:VAR_POSITIONAL\n):\n\nReturn first attr that exists in obj\n\ntest_eq(try_attrs(1, 'real'), 1)\ntest_eq(try_attrs(1, 'foobar', 'real'), 1)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#attribute-delegation",
    "href": "basics.html#attribute-delegation",
    "title": "Basic functionality",
    "section": "Attribute Delegation",
    "text": "Attribute Delegation\n\nsource\n\nGetAttrBase\n\ndef GetAttrBase(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nBasic delegation of __getattr__ and __dir__\n\nsource\n\nGetAttr\n\ndef GetAttr(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nInherit from this to have all attr accesses in self._xtra passed down to self.default\nInherit from GetAttr to have attr access passed down to an instance attribute. This makes it easy to create composites that don’t require callers to know about their components. For a more detailed discussion of how this works as well as relevant context, we suggest reading the delegated composition section of this blog article.\nYou can customise the behaviour of GetAttr in subclasses via; - _default - By default, this is set to 'default', so attr access is passed down to self.default - _default can be set to the name of any instance attribute that does not start with dunder __ - _xtra - By default, this is None, so all attr access is passed down - You can limit which attrs get passed down by setting _xtra to a list of attribute names\nTo illuminate the utility of GetAttr, suppose we have the following two classes, _WebPage which is a superclass of _ProductPage, which we wish to compose like so:\n\nclass _WebPage:\n    def __init__(self, title, author=\"Jeremy\"):\n        self.title,self.author = title,author\n\nclass _ProductPage:\n    def __init__(self, page, price): self.page,self.price = page,price\n        \npage = _WebPage('Soap', author=\"Sylvain\")\np = _ProductPage(page, 15.0)\n\nHow do we make it so we can just write p.author, instead of p.page.author to access the author attribute? We can use GetAttr, of course! First, we subclass GetAttr when defining _ProductPage. Next, we set self.default to the object whose attributes we want to be able to access directly, which in this case is the page argument passed on initialization:\n\nclass _ProductPage(GetAttr):\n    def __init__(self, page, price): self.default,self.price = page,price #self.default allows you to access page directly.\n\np = _ProductPage(page, 15.0)\n\nNow, we can access the author attribute directly from the instance:\n\ntest_eq(p.author, 'Sylvain')\n\nIf you wish to store the object you are composing in an attribute other than self.default, you can set the class attribute _data as shown below. This is useful in the case where you might have a name collision with self.default:\n\nclass _C(GetAttr):\n    _default = '_data' # use different component name; `self._data` rather than `self.default`\n    def __init__(self,a): self._data = a\n    def foo(self): noop\n\nt = _C('Hi')\ntest_eq(t._data, 'Hi') \ntest_fail(lambda: t.default) # we no longer have self.default\ntest_eq(t.lower(), 'hi')\ntest_eq(t.upper(), 'HI')\nassert 'lower' in dir(t)\nassert 'upper' in dir(t)\n\nBy default, all attributes and methods of the object you are composing are retained. In the below example, we compose a str object with the class _C. This allows us to directly call string methods on instances of class _C, such as str.lower() or str.upper():\n\nclass _C(GetAttr):\n    # allow all attributes and methods to get passed to `self.default` (by leaving _xtra=None)\n    def __init__(self,a): self.default = a\n    def foo(self): noop\n\nt = _C('Hi')\ntest_eq(t.lower(), 'hi')\ntest_eq(t.upper(), 'HI')\nassert 'lower' in dir(t)\nassert 'upper' in dir(t)\n\nHowever, you can choose which attributes or methods to retain by defining a class attribute _xtra, which is a list of allowed attribute and method names to delegate. In the below example, we only delegate the lower method from the composed str object when defining class _C:\n\nclass _C(GetAttr):\n    _xtra = ['lower'] # specify which attributes get passed to `self.default`\n    def __init__(self,a): self.default = a\n    def foo(self): noop\n\nt = _C('Hi')\ntest_eq(t.default, 'Hi')\ntest_eq(t.lower(), 'hi')\ntest_fail(lambda: t.upper()) # upper wasn't in _xtra, so it isn't available to be called\nassert 'lower' in dir(t)\nassert 'upper' not in dir(t)\n\nYou must be careful to properly set an instance attribute in __init__ that corresponds to the class attribute _default. The below example sets the class attribute _default to data, but erroneously fails to define self.data (and instead defines self.default).\nFailing to properly set instance attributes leads to errors when you try to access methods directly:\n\nclass _C(GetAttr):\n    _default = 'data' # use a bad component name; i.e. self.data does not exist\n    def __init__(self,a): self.default = a\n    def foo(self): noop\n        \n# TODO: should we raise an error when we create a new instance ...\nt = _C('Hi')\ntest_eq(t.default, 'Hi')\n# ... or is it enough for all GetAttr features to raise errors\ntest_fail(lambda: t.data)\ntest_fail(lambda: t.lower())\ntest_fail(lambda: t.upper())\ntest_fail(lambda: dir(t))\n\n\nsource\n\n\n\ndelegate_attr\n\ndef delegate_attr(\n    k, to\n):\n\nUse in __getattr__ to delegate to attr to without inheriting from GetAttr\ndelegate_attr is a functional way to delegate attributes, and is an alternative to GetAttr. We recommend reading the documentation of GetAttr for more details around delegation.\nYou can use achieve delegation when you define __getattr__ by using delegate_attr:\n\nclass _C:\n    def __init__(self, o): self.o = o # self.o corresponds to the `to` argument in delegate_attr.\n    def __getattr__(self, k): return delegate_attr(self, k, to='o')\n    \n\nt = _C('HELLO') # delegates to a string\ntest_eq(t.lower(), 'hello')\n\nt = _C(np.array([5,4,3])) # delegates to a numpy array\ntest_eq(t.sum(), 12)\n\nt = _C(pd.DataFrame({'a': [1,2], 'b': [3,4]})) # delegates to a pandas.DataFrame\ntest_eq(t.b.max(), 4)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#extensible-types",
    "href": "basics.html#extensible-types",
    "title": "Basic functionality",
    "section": "Extensible Types",
    "text": "Extensible Types\nShowPrint is a base class that defines a show method, which is used primarily for callbacks in fastai that expect this method to be defined.\nInt, Float, and Str extend int, float and str respectively by adding an additional show method by inheriting from ShowPrint.\nThe code for Int is shown below:\nExamples:\n\nInt(0).show()\nFloat(2.0).show()\nStr('Hello').show()\n\n0\n2.0\nHello",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#collection-functions",
    "href": "basics.html#collection-functions",
    "title": "Basic functionality",
    "section": "Collection functions",
    "text": "Collection functions\nFunctions that manipulate popular python collections.\n\nsource\n\npartition\n\ndef partition(\n    coll, f\n):\n\nPartition a collection by a predicate\n\nts,fs = partition(range(10), mod(2))\ntest_eq(fs, [0,2,4,6,8])\ntest_eq(ts, [1,3,5,7,9])\n\n\nsource\n\n\npartition_dict\n\ndef partition_dict(\n    d, f\n):\n\nPartition a dict by a predicate that takes key/value params\n\nd = {'a':1, 'b':2, 'c':3, 'd':4}\nts,fs = partition_dict(d, lambda k,v: v%2)\ntest_eq(fs, {'b':2, 'd':4})\ntest_eq(ts, {'a':1, 'c':3})\n\n\nts,fs = partition_dict(d, lambda k,v: k in 'bc')\ntest_eq(ts, {'b':2, 'c':3})\ntest_eq(fs, {'a':1, 'd':4})\n\n\nsource\n\n\nflatten\n\ndef flatten(\n    o\n):\n\nConcatenate all collections and items as a generator\n\nsource\n\n\nconcat\n\ndef concat(\n    colls\n)-&gt;list:\n\nConcatenate all collections and items as a list\n\nconcat([(o for o in range(2)),[2,3,4], 5])\n\n[0, 1, 2, 3, 4, 5]\n\n\n\nconcat([[\"abc\", \"xyz\"], [\"foo\", \"bar\"]])\n\n['abc', 'xyz', 'foo', 'bar']\n\n\n\nsource\n\n\nstrcat\n\ndef strcat(\n    its, sep:str=''\n)-&gt;str:\n\nConcatenate stringified items its\n\ntest_eq(strcat(['a',2]), 'a2')\ntest_eq(strcat(['a',2], ';'), 'a;2')\n\n\nsource\n\n\ndetuplify\n\ndef detuplify(\n    x\n):\n\nIf x is a tuple with one thing, extract it\n\ntest_eq(detuplify(()),None)\ntest_eq(detuplify([1]),1)\ntest_eq(detuplify([1,2]), [1,2])\ntest_eq(detuplify(np.array([[1,2]])), np.array([[1,2]]))\n\n\nsource\n\n\nreplicate\n\ndef replicate(\n    item, match\n):\n\nCreate tuple of item copied len(match) times\n\nt = [1,1]\ntest_eq(replicate([1,2], t),([1,2],[1,2]))\ntest_eq(replicate(1, t),(1,1))\n\n\nsource\n\n\nsetify\n\ndef setify(\n    o\n):\n\nTurn any list like-object into a set.\n\n# test\ntest_eq(setify(None),set())\ntest_eq(setify('abc'),{'abc'})\ntest_eq(setify([1,2,2]),{1,2})\ntest_eq(setify(range(0,3)),{0,1,2})\ntest_eq(setify({1,2}),{1,2})\n\n\nsource\n\n\nmerge\n\ndef merge(\n    ds:VAR_POSITIONAL\n):\n\nMerge all dictionaries in ds\n\ntest_eq(merge(), {})\ntest_eq(merge(dict(a=1,b=2)), dict(a=1,b=2))\ntest_eq(merge(dict(a=1,b=2), dict(b=3,c=4), None), dict(a=1, b=3, c=4))\n\n\nsource\n\n\nrange_of\n\ndef range_of(\n    x\n):\n\nAll indices of collection x (i.e. list(range(len(x))))\n\ntest_eq(range_of([1,1,1,1]), [0,1,2,3])\n\n\nsource\n\n\ngroupby\n\ndef groupby(\n    x, key, val:function=&lt;function noop at 0x7f3e5ec2cd60&gt;\n):\n\nLike itertools.groupby but doesn’t need to be sorted, and isn’t lazy, plus some extensions\n\ntest_eq(groupby('aa ab bb'.split(), itemgetter(0)), {'a':['aa','ab'], 'b':['bb']})\n\nYou can use an int as key or val (which uses itemgetter; passing a str will use attrgetter), eg:\n\ntest_eq(groupby('aa ab bb'.split(), 0), {'a':['aa','ab'], 'b':['bb']})\n\n…and you can use a tuple as key or val (which creates a tuple from the provided keys or vals), eg:\n\ntest_eq(groupby('aaa abc bba'.split(), 0, (1,2)), {'a':[('a','a'),('b','c')], 'b':[('b','a')]})\n\nHere’s an example of how to invert a grouping, and using a val function:\n\nd = {0: [1, 3, 7], 2: [3], 3: [5], 4: [8], 5: [4], 7: [5]}\ngroupby(((o,k) for k,v in d.items() for o in v), 0, 1)\n\n{1: [0], 3: [0, 2], 7: [0], 5: [3, 7], 8: [4], 4: [5]}\n\n\n\nsource\n\n\nlast_index\n\ndef last_index(\n    x, o\n):\n\nFinds the last index of occurence of x in o (returns -1 if no occurence)\n\ntest_eq(last_index(9, [1, 2, 9, 3, 4, 9, 10]), 5)\ntest_eq(last_index(6, [1, 2, 9, 3, 4, 9, 10]), -1)\n\n\nsource\n\n\nfilter_dict\n\ndef filter_dict(\n    d, func\n):\n\nFilter a dict using func, applied to keys and values\n\nletters = {o:chr(o) for o in range(65,73)}\nletters\n\n{65: 'A', 66: 'B', 67: 'C', 68: 'D', 69: 'E', 70: 'F', 71: 'G', 72: 'H'}\n\n\n\nfilter_dict(letters, lambda k,v: k&lt;67 or v in 'FG')\n\n{65: 'A', 66: 'B', 70: 'F', 71: 'G'}\n\n\n\nsource\n\n\nfilter_keys\n\ndef filter_keys(\n    d, func\n):\n\nFilter a dict using func, applied to keys\n\nfilter_keys(letters, lt(67))\n\n{65: 'A', 66: 'B'}\n\n\n\nsource\n\n\nfilter_values\n\ndef filter_values(\n    d, func\n):\n\nFilter a dict using func, applied to values\n\nfilter_values(letters, in_('FG'))\n\n{70: 'F', 71: 'G'}\n\n\n\nsource\n\n\ncycle\n\ndef cycle(\n    o\n):\n\nLike itertools.cycle except creates list of Nones if o is empty\n\ntest_eq(itertools.islice(cycle([1,2,3]),5), [1,2,3,1,2])\ntest_eq(itertools.islice(cycle([]),3), [None]*3)\ntest_eq(itertools.islice(cycle(None),3), [None]*3)\ntest_eq(itertools.islice(cycle(1),3), [1,1,1])\n\n\nsource\n\n\nzip_cycle\n\ndef zip_cycle(\n    x, args:VAR_POSITIONAL\n):\n\nLike itertools.zip_longest but cycles through elements of all but first argument\n\ntest_eq(zip_cycle([1,2,3,4],list('abc')), [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'a')])\n\n\nsource\n\n\nsorted_ex\n\ndef sorted_ex(\n    iterable, key:NoneType=None, reverse:bool=False, cmp:NoneType=None, kwargs:VAR_KEYWORD\n):\n\nLike sorted, but if key is str use attrgetter; if int use itemgetter; use cmp comparator function or key with kwargs\nAttributes can be used for sorting by passing their name as a string:\n\nclass TestObj:\n    def __init__(self, x): self.x = x\nobjs = [TestObj(i) for i in [3,1,2]]\ntest_eq([o.x for o in sorted_ex(objs, 'x')], [1,2,3])\n\nTuple/list items can be sorted by index position:\n\nitems = [(1,'c'), (2,'b'), (3,'a')]\ntest_eq(sorted_ex(items, 1), [(3,'a'), (2,'b'), (1,'c')])\n\nA custom key function transforms values:\n\ntest_eq(sorted_ex([3,1,2], lambda x: -x), [3,2,1])\n\nYou can use a comparison function (returning -1/1/0):\n\ntest_eq(sorted_ex([3,1,2], cmp=lambda a,b: 1 if a&gt;b else -1 if a&lt;b else 0), [1,2,3])\n\nAdditional parameters can be passed to key/cmp functions:\n\ndef key_with_kwargs(x, offset=0): return x + offset\ntest_eq(sorted_ex([3,1,2], key=key_with_kwargs, offset=10), [1,2,3])\n\nReverse sort capability:\n\ntest_eq(sorted_ex([1,2,3], reverse=True), [3,2,1])\n\n\nsource\n\n\nnot_\n\ndef not_(\n    f\n):\n\nCreate new function that negates result of f\n\ndef f(a): return a&gt;0\ntest_eq(f(1),True)\ntest_eq(not_(f)(1),False)\ntest_eq(not_(f)(a=-1),True)\n\n\nsource\n\n\nargwhere\n\ndef argwhere(\n    iterable, f, negate:bool=False, kwargs:VAR_KEYWORD\n):\n\nLike filter_ex, but return indices for matching items\n\nsource\n\n\nfilter_ex\n\ndef filter_ex(\n    iterable, f:function=&lt;function noop at 0x7f3e5ec2cd60&gt;, negate:bool=False, gen:bool=False, kwargs:VAR_KEYWORD\n):\n\nLike filter, but passing kwargs to f, defaulting f to noop, and adding negate and gen\n\nsource\n\n\nrange_of\n\ndef range_of(\n    a, b:NoneType=None, step:NoneType=None\n):\n\nAll indices of collection a, if a is a collection, otherwise range\n\ntest_eq(range_of([1,1,1,1]), [0,1,2,3])\ntest_eq(range_of(4), [0,1,2,3])\n\n\nsource\n\n\nrenumerate\n\ndef renumerate(\n    iterable, start:int=0\n):\n\nSame as enumerate, but returns index as 2nd element instead of 1st\n\ntest_eq(renumerate('abc'), (('a',0),('b',1),('c',2)))\n\n\nsource\n\n\nfirst\n\ndef first(\n    x, f:NoneType=None, negate:bool=False, kwargs:VAR_KEYWORD\n):\n\nFirst element of x, optionally filtered by f, or None if missing\n\ntest_eq(first(['a', 'b', 'c', 'd', 'e']), 'a')\ntest_eq(first([False]), False)\ntest_eq(first([False], noop), None)\n\n\nsource\n\n\nlast\n\ndef last(\n    x, f:NoneType=None, negate:bool=False, kwargs:VAR_KEYWORD\n):\n\nLast element of x, optionally filtered by f, or None if missing\n\ntest_eq(last(['a', 'b', 'c', 'd', 'e']), 'e')\ntest_eq(last([False]), False)\ntest_eq(last([False], noop), None)\n\n\nsource\n\n\nonly\n\ndef only(\n    o\n):\n\nReturn the only item of o, raise if o doesn’t have exactly one item\n\nsource\n\n\nnested_attr\n\ndef nested_attr(\n    o, attr, default:NoneType=None\n):\n\nSame as getattr, but if attr includes a ., then looks inside nested objects\n\nclass CustomIndexable:\n    def __init__(self): self.data = {'a':1,'b':'v','c':{'d':5}}\n    def __getitem__(self, key): return self.data[key]\n\ncustom_indexable = CustomIndexable()\ntest_eq(nested_attr(custom_indexable,'a'),1)\ntest_eq(nested_attr(custom_indexable,'c.d'),5)\ntest_eq(nested_attr(custom_indexable,'e'),None)\n\nclass TestObj: def init(self): self.nested = {‘key’: [1, 2, {‘inner’: ‘value’}]} test_obj = TestObj()\ntest_eq(nested_attr(test_obj, ‘nested.key.2.inner’),‘value’) test_eq(nested_attr([1, 2, 3], ‘1’),2)\n\nb = {'a':1,'b':'v','c':{'d':5}}\ntest_eq(nested_attr(b,'b'),'v')\ntest_eq(nested_attr(b,'c.d'),5)\n\n\na = SimpleNamespace(b=(SimpleNamespace(c=1)))\ntest_eq(nested_attr(a, 'b.c'), getattr(getattr(a, 'b'), 'c'))\ntest_eq(nested_attr(a, 'b.d'), None)\ntest_eq(nested_attr(b, 'a'), 1)\n\n\nsource\n\n\nnested_setdefault\n\ndef nested_setdefault(\n    o, attr, default\n):\n\nSame as setdefault, but if attr includes a ., then looks inside nested objects\n\nsource\n\n\nnested_callable\n\ndef nested_callable(\n    o, attr\n):\n\nSame as nested_attr but if not found will return noop\n\na = SimpleNamespace(b=(SimpleNamespace(c=1)))\ntest_eq(nested_callable(a, 'b.c'), getattr(getattr(a, 'b'), 'c'))\ntest_eq(nested_callable(a, 'b.d'), noop)\n\n\nsource\n\n\nnested_idx\n\ndef nested_idx(\n    coll, idxs:VAR_POSITIONAL\n):\n\nIndex into nested collections, dicts, etc, with idxs\n\na = {'b':[1,{'c':2}]}\ntest_eq(nested_idx(a, 'nope'), None)\ntest_eq(nested_idx(a, 'nope', 'nup'), None)\ntest_eq(nested_idx(a, 'b', 3), None)\ntest_eq(nested_idx(a), a)\ntest_eq(nested_idx(a, 'b'), [1,{'c':2}])\ntest_eq(nested_idx(a, 'b', 1), {'c':2})\ntest_eq(nested_idx(a, 'b', 1, 'c'), 2)\n\n\na = SimpleNamespace(b=[1,{'c':2}])\ntest_eq(nested_idx(a, 'nope'), None)\ntest_eq(nested_idx(a, 'nope', 'nup'), None)\ntest_eq(nested_idx(a, 'b', 3), None)\ntest_eq(nested_idx(a), a)\ntest_eq(nested_idx(a, 'b'), [1,{'c':2}])\ntest_eq(nested_idx(a, 'b', 1), {'c':2})\ntest_eq(nested_idx(a, 'b', 1, 'c'), 2)\n\n\nsource\n\n\nset_nested_idx\n\ndef set_nested_idx(\n    coll, value, idxs:VAR_POSITIONAL\n):\n\nSet value indexed like `nested_idx\n\nset_nested_idx(a, 3, 'b', 0)\ntest_eq(nested_idx(a, 'b', 0), 3)\n\n\nsource\n\n\nval2idx\n\ndef val2idx(\n    x\n):\n\nDict from value to index\n\ntest_eq(val2idx([1,2,3]), {3:2,1:0,2:1})\n\n\nsource\n\n\nuniqueify\n\ndef uniqueify(\n    x, sort:bool=False, bidir:bool=False, start:NoneType=None\n):\n\nUnique elements in x, optional sort, optional return reverse correspondence, optional prepend with elements.\n\nt = [1,1,0,5,0,3]\ntest_eq(uniqueify(t),[1,0,5,3])\ntest_eq(uniqueify(t, sort=True),[0,1,3,5])\ntest_eq(uniqueify(t, start=[7,8,6]), [7,8,6,1,0,5,3])\nv,o = uniqueify(t, bidir=True)\ntest_eq(v,[1,0,5,3])\ntest_eq(o,{1:0, 0: 1, 5: 2, 3: 3})\nv,o = uniqueify(t, sort=True, bidir=True)\ntest_eq(v,[0,1,3,5])\ntest_eq(o,{0:0, 1: 1, 3: 2, 5: 3})\n\n\nsource\n\n\nloop_first_last\n\ndef loop_first_last(\n    values\n):\n\nIterate and generate a tuple with a flag for first and last value.\n\ntest_eq(loop_first_last(range(3)), [(True,False,0), (False,False,1), (False,True,2)])\n\n\nsource\n\n\nloop_first\n\ndef loop_first(\n    values\n):\n\nIterate and generate a tuple with a flag for first value.\n\ntest_eq(loop_first(range(3)), [(True,0), (False,1), (False,2)])\n\n\nsource\n\n\nloop_last\n\ndef loop_last(\n    values\n):\n\nIterate and generate a tuple with a flag for last value.\n\ntest_eq(loop_last(range(3)), [(False,0), (False,1), (True,2)])\n\n\nsource\n\n\nfirst_match\n\ndef first_match(\n    lst, f, default:NoneType=None\n):\n\nFirst element of lst matching predicate f, or default if none\n\na = [0,2,4,5,6,7,10]\ntest_eq(first_match(a, lambda o:o%2), 3)\n\n\nsource\n\n\nlast_match\n\ndef last_match(\n    lst, f, default:NoneType=None\n):\n\nLast element of lst matching predicate f, or default if none\n\ntest_eq(last_match(a, lambda o:o%2), 5)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#fastuple",
    "href": "basics.html#fastuple",
    "title": "Basic functionality",
    "section": "fastuple",
    "text": "fastuple\nA tuple with extended functionality.\n\nsource\n\nfastuple\n\ndef fastuple(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nA tuple with elementwise ops and more friendly init behavior\n\n\nFriendly init behavior\nCommon failure modes when trying to initialize a tuple in python:\ntuple(3)\n&gt; TypeError: 'int' object is not iterable\nor\ntuple(3, 4)\n&gt; TypeError: tuple expected at most 1 arguments, got 2\nHowever, fastuple allows you to define tuples like this and in the usual way:\n\ntest_eq(fastuple(3), (3,))\ntest_eq(fastuple(3,4), (3, 4))\ntest_eq(fastuple((3,4)), (3, 4))\n\n\n\nElementwise operations\n\nsource\n\nfastuple.add\n\ndef add(\n    args:VAR_POSITIONAL\n):\n\n+ is already defined in tuple for concat, so use add instead\n\ntest_eq(fastuple.add((1,1),(2,2)), (3,3))\ntest_eq_type(fastuple(1,1).add(2), fastuple(3,3))\ntest_eq(fastuple('1','2').add('2'), fastuple('12','22'))\n\n\nsource\n\n\nfastuple.mul\n\ndef mul(\n    args:VAR_POSITIONAL\n):\n\n* is already defined in tuple for replicating, so use mul instead\n\ntest_eq_type(fastuple(1,1).mul(2), fastuple(2,2))\n\n\n\n\nOther Elementwise Operations\nAdditionally, the following elementwise operations are available: - le: less than or equal - eq: equal - gt: greater than - min: minimum of\n\ntest_eq(fastuple(3,1).le(1), (False, True))\ntest_eq(fastuple(3,1).eq(1), (False, True))\ntest_eq(fastuple(3,1).gt(1), (True, False))\ntest_eq(fastuple(3,1).min(2), (2,1))\n\nYou can also do other elementwise operations like negate a fastuple, or subtract two fastuples:\n\ntest_eq(-fastuple(1,2), (-1,-2))\ntest_eq(~fastuple(1,0,1), (False,True,False))\n\ntest_eq(fastuple(1,1)-fastuple(2,2), (-1,-1))\n\n\ntest_eq(type(fastuple(1)), fastuple)\ntest_eq_type(fastuple(1,2), fastuple(1,2))\ntest_ne(fastuple(1,2), fastuple(1,3))\ntest_eq(fastuple(), ())",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#functions-on-functions",
    "href": "basics.html#functions-on-functions",
    "title": "Basic functionality",
    "section": "Functions on Functions",
    "text": "Functions on Functions\nUtilities for functional programming or for defining, modifying, or debugging functions.\n\nsource\n\nbind\n\ndef bind(\n    func, pargs:VAR_POSITIONAL, pkwargs:VAR_KEYWORD\n):\n\nSame as partial, except you can use arg0 arg1 etc param placeholders\nbind is the same as partial, but also allows you to reorder positional arguments using variable name(s) arg{i} where i refers to the zero-indexed positional argument. bind as implemented currently only supports reordering of up to the first 5 positional arguments.\nConsider the function myfunc below, which has 3 positional arguments. These arguments can be referenced as arg0, arg1, and arg1, respectively.\n\ndef myfn(a,b,c,d=1,e=2): return(a,b,c,d,e)\n\nIn the below example we bind the positional arguments of myfn as follows:\n\nThe second input 14, referenced by arg1, is substituted for the first positional argument.\nWe supply a default value of 17 for the second positional argument.\nThe first input 19, referenced by arg0, is subsituted for the third positional argument.\n\n\ntest_eq(bind(myfn, arg1, 17, arg0, e=3)(19,14), (14,17,19,1,3))\n\nIn this next example:\n\nWe set the default value to 17 for the first positional argument.\nThe first input 19 refrenced by arg0, becomes the second positional argument.\nThe second input 14 becomes the third positional argument.\nWe override the default the value for named argument e to 3.\n\n\ntest_eq(bind(myfn, 17, arg0, e=3)(19,14), (17,19,14,1,3))\n\nThis is an example of using bind like partial and do not reorder any arguments:\n\ntest_eq(bind(myfn)(17,19,14), (17,19,14,1,2))\n\nbind can also be used to change default values. In the below example, we use the first input 3 to override the default value of the named argument e, and supply default values for the first three positional arguments:\n\ntest_eq(bind(myfn, 17,19,14,e=arg0)(3), (17,19,14,1,3))\n\n\nsource\n\n\nmapt\n\ndef mapt(\n    func, iterables:VAR_POSITIONAL\n):\n\nTuplified map\n\nt = [0,1,2,3]\ntest_eq(mapt(operator.neg, t), (0,-1,-2,-3))\n\n\nsource\n\n\nmap_ex\n\ndef map_ex(\n    iterable, f, args:VAR_POSITIONAL, gen:bool=False, kwargs:VAR_KEYWORD\n):\n\nLike map, but use bind, and supports str and indexing\n\ntest_eq(map_ex(t,operator.neg), [0,-1,-2,-3])\n\nIf f is a string then it is treated as a format string to create the mapping:\n\ntest_eq(map_ex(t, '#{}#'), ['#0#','#1#','#2#','#3#'])\n\nIf f is a dictionary (or anything supporting __getitem__) then it is indexed to create the mapping:\n\ntest_eq(map_ex(t, list('abcd')), list('abcd'))\n\nYou can also pass the same arg params that bind accepts:\n\ndef f(a=None,b=None): return b\ntest_eq(map_ex(t, f, b=arg0), range(4))\n\n\nsource\n\n\ncompose\n\ndef compose(\n    funcs:VAR_POSITIONAL, order:NoneType=None\n):\n\nCreate a function that composes all functions in funcs, passing along remaining *args and **kwargs to all\n\nf1 = lambda o,p=0: (o*2)+p\nf2 = lambda o,p=1: (o+1)/p\ntest_eq(f2(f1(3)), compose(f1,f2)(3))\ntest_eq(f2(f1(3,p=3),p=3), compose(f1,f2)(3,p=3))\ntest_eq(f2(f1(3,  3),  3), compose(f1,f2)(3,  3))\n\nf1.order = 1\ntest_eq(f1(f2(3)), compose(f1,f2, order=\"order\")(3))\n\n\nsource\n\n\nmaps\n\ndef maps(\n    args:VAR_POSITIONAL, retain:function=&lt;function noop at 0x7f3e5ec2cd60&gt;\n):\n\nLike map, except funcs are composed first\n\ntest_eq(maps([1]), [1])\ntest_eq(maps(operator.neg, [1,2]), [-1,-2])\ntest_eq(maps(operator.neg, operator.neg, [1,2]), [1,2])\n\n\nsource\n\n\npartialler\n\ndef partialler(\n    f, args:VAR_POSITIONAL, order:NoneType=None, kwargs:VAR_KEYWORD\n):\n\nLike functools.partial but also copies over docstring\n\ndef _f(x,a=1):\n    \"test func\"\n    return x-a\n_f.order=1\n\nf = partialler(_f, 2)\ntest_eq(f.order, 1)\ntest_eq(f(3), -1)\nf = partialler(_f, a=2, order=3)\ntest_eq(f.__doc__, \"test func\")\ntest_eq(f.order, 3)\ntest_eq(f(3), _f(3,2))\n\n\nclass partial0:\n    \"Like `partialler`, but args passed to callable are inserted at started, instead of at end\"\n    def __init__(self, f, *args, order=None, **kwargs):\n        self.f,self.args,self.kwargs = f,args,kwargs\n        self.order = ifnone(order, getattr(f,'order',None))\n        self.__doc__ = f.__doc__\n\n    def __call__(self, *args, **kwargs): return self.f(*args, *self.args, **kwargs, **self.kwargs)\n\n\nf = partial0(_f, 2)\ntest_eq(f.order, 1)\ntest_eq(f(3), 1) # NB: different to `partialler` example\n\n\nsource\n\n\ninstantiate\n\ndef instantiate(\n    t\n):\n\nInstantiate t if it’s a type, otherwise do nothing\n\ntest_eq_type(instantiate(int), 0)\ntest_eq_type(instantiate(1), 1)\n\n\nsource\n\n\nusing_attr\n\ndef using_attr(\n    f, attr\n):\n\nConstruct a function which applies f to the argument’s attribute attr\n\nt = Path('/a/b.txt')\nf = using_attr(str.upper, 'name')\ntest_eq(f(t), 'B.TXT')\n\n\nsource\n\n\nnegate\n\ndef negate(\n    f\n):\n\nReturns the negation of f\n\ndef true():\n    'Returns True'\n    return True\n\n\nfalse = negate(true)\nprint(false.__doc__)\ntest_eq(false(), not true())\n\nReturns `not true(...)`\n\nOriginal: Returns True\n\n\n\nsource\n\n\nspread\n\ndef spread(\n    f\n):\n\nWrap f to accept a single iterable and spread it as positional args\nspread wraps a function so it accepts a single iterable (like a tuple or list) and unpacks it as positional arguments.\nIt can be used to replicate itertools.starmap:\n\ndef add(a, b): return a + b\npairs = [(1,2), (3,4), (5,6)]\nlist(map(spread(add), pairs))  # [3, 7, 11]\n\n[3, 7, 11]\n\n\nIt can also be used to create star versions of functions such as filter, which aren’t otherwise in the stdlib:\n\ndef is_long_segment(x1, y1, x2, y2, maxlen=4): return ((x2-x1)**2 + (y2-y1)**2)**0.5 &gt; maxlen\n\nsegments = [(0,0,2,3), (1,1,4,5), (0,0,6,8)]\nlist(filter(spread(is_long_segment), segments))\n\n[(1, 1, 4, 5), (0, 0, 6, 8)]\n\n\n\nsource\n\n\ndspread\n\ndef dspread(\n    f\n):\n\nWrap f to accept a single dict and spread it as keyword args\ndspread is the dictionary equivalent of spread - it wraps a function to accept a single dictionary and unpacks it as keyword arguments. For instance:\n\ndef greet(name, greeting='Hello'): return f'{greeting}, {name}!'\nconfigs = [{'name': 'Alice'}, {'name': 'Bob', 'greeting': 'Hi'}]\nlist(map(dspread(greet), configs))  # ['Hello, Alice!', 'Hi, Bob!']\n\n['Hello, Alice!', 'Hi, Bob!']\n\n\nA more realistic example showing API request configuration. Each request dictionary may have different keys present, and dspread handles this naturally (missing keys use the function’s defaults):\n\ndef api_request(endpoint, method='GET', timeout=30, headers=None):\n    return f\"{method} {endpoint} (timeout={timeout})\"\n\nrequests = [\n    {'endpoint': '/users', 'method': 'POST', 'timeout': 60},\n    {'endpoint': '/data'},\n    {'endpoint': '/health', 'method': 'HEAD', 'timeout': 5}\n]\nlist(map(dspread(api_request), requests))\n\n['POST /users (timeout=60)',\n 'GET /data (timeout=30)',\n 'HEAD /health (timeout=5)']\n\n\n\n\nSelf (with an uppercase S)\nA Concise Way To Create Lambdas\nThis is a concise way to create lambdas that are calling methods on an object (note the capitalization!)\nSelf.sum(), for instance, is a shortcut for lambda o: o.sum().\n\nf = Self.sum()\nx = np.array([3.,1])\ntest_eq(f(x), 4.)\n\n# This is equivalent to above\nf = lambda o: o.sum()\nx = np.array([3.,1])\ntest_eq(f(x), 4.)\n\nf = Self.argmin()\narr = np.array([1,2,3,4,5])\ntest_eq(f(arr), arr.argmin())\n\nf = Self.sum().is_integer()\nx = np.array([3.,1])\ntest_eq(f(x), True)\n\nf = Self.sum().real.is_integer()\nx = np.array([3.,1])\ntest_eq(f(x), True)\n\nf = Self.imag()\ntest_eq(f(3), 0)\n\nf = Self[1]\ntest_eq(f(x), 1)\n\nSelf is also callable, which creates a function which calls any function passed to it, using the arguments passed to Self:\n\ndef f(a, b=3): return a+b+2\ndef g(a, b=3): return a*b\nfg = Self(1,b=2)\nlist(map(fg, [f,g]))\n\n[5, 2]",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#patching",
    "href": "basics.html#patching",
    "title": "Basic functionality",
    "section": "Patching",
    "text": "Patching\n\nsource\n\ncopy_func\n\ndef copy_func(\n    f\n):\n\nCopy a non-builtin function (NB copy.copy does not work for this)\nSometimes it may be desirable to make a copy of a function that doesn’t point to the original object. When you use Python’s built in copy.copy or copy.deepcopy to copy a function, you get a reference to the original object:\n\nimport copy as cp\n\n\ndef foo(): pass\na = cp.copy(foo)\nb = cp.deepcopy(foo)\n\na.someattr = 'hello' # since a and b point at the same object, updating a will update b\ntest_eq(b.someattr, 'hello')\n\nassert a is foo and b is foo\n\nHowever, with copy_func, you can retrieve a copy of a function without a reference to the original object:\n\nc = copy_func(foo) # c is an indpendent object\nassert c is not foo\n\n\ndef g(x, *, y=3): return x+y\ntest_eq(copy_func(g)(4), 7)\n\n\nsource\n\n\npatch_to\n\ndef patch_to(\n    cls, as_prop:bool=False, cls_method:bool=False, set_prop:bool=False, nm:NoneType=None, glb:NoneType=None\n):\n\nDecorator: add f to cls\nThe @patch_to decorator allows you to monkey patch a function into a class as a method:\n\nclass _T3(int): pass  \n\n@patch_to(_T3)\ndef func1(self, a): return self+a\n\nt = _T3(1) # we initialized `t` to a type int = 1\ntest_eq(t.func1(2), 3) # we add 2 to `t`, so 2 + 1 = 3\n\nYou can access instance properties in the usual way via self:\n\nclass _T4():\n    def __init__(self, g): self.g = g\n        \n@patch_to(_T4)\ndef greet(self, x): return self.g + x\n        \nt = _T4('hello ') # this sets self.g = 'hello '\ntest_eq(t.greet('world'), 'hello world') #t.greet('world') will append 'world' to 'hello '\n\nYou can instead specify that the method should be a class method by setting cls_method=True:\n\nclass _T5(int): attr = 3 # attr is a class attribute we will access in a later method\n    \n@patch_to(_T5, cls_method=True)\ndef func(cls, x): return cls.attr + x # you can access class attributes in the normal way\n\ntest_eq(_T5.func(4), 7)\n\nAdditionally you can specify that the function you want to patch should be a class attribute with as_prop=True:\n\n@patch_to(_T5, as_prop=True)\ndef add_ten(self): return self + 10\n\nt = _T5(4)\ntest_eq(t.add_ten, 14)\n\nOnce you have a property, you can assign a setter with set_prop=True:\n\nclass _T2():\n    def __init__(self, val): self._val = val\n\n@patch_to(_T2, as_prop=True)\ndef val(self): return self._val\n\nt = _T2(2)\ntest_eq(t.val, 2)\n\n@patch_to(_T2, set_prop=True)\ndef val(self, val): self._val = val\n\nt.val = 3\ntest_eq(t.val, 3)\n\nInstead of passing one class to the @patch_to decorator, you can pass multiple classes in a tuple to simulteanously patch more than one class with the same method:\n\nclass _T6(int): pass\nclass _T7(int): pass\n\n@patch_to((_T6,_T7))\ndef func_mult(self, a): return self*a\n\nt = _T6(2)\ntest_eq(t.func_mult(4), 8)\nt = _T7(2)\ntest_eq(t.func_mult(4), 8)\n\nYou can also rename the function in the patched class:\n\nclass _T8(int): pass  \n\n@patch_to(_T8, nm='add_value')\ndef func2(self, a): return self+a\n\nt = _T8(1)\ntest_eq(t.add_value(2), 3)\ntest_eq(_T8.add_value.__name__, 'add_value')\nassert not hasattr(t, 'func2')\n\n\nsource\n\n\npatch\n\ndef patch(\n    f:NoneType=None, as_prop:bool=False, cls_method:bool=False, set_prop:bool=False, nm:NoneType=None\n):\n\nDecorator: add f to the first parameter’s class (based on f’s type annotations)\n@patch is an alternative to @patch_to that allows you similarly monkey patch class(es) by using type annotations:\n\nclass _T8(int): pass  \n\n@patch\ndef func(self:_T8, a): return self+a\n\nt = _T8(1)  # we initilized `t` to a type int = 1\ntest_eq(t.func(3), 4) # we add 3 to `t`, so 3 + 1 = 4\ntest_eq(t.func.__qualname__, '_T8.func')\n\nSimilarly to patch_to, you can supply a union of classes instead of a single class in your type annotations to patch multiple classes:\n\nclass _T9(int): pass \n\n@patch\ndef func2(x:_T8|_T9, a): return x*a # will patch both _T8 and _T9\n\nt = _T8(2)\ntest_eq(t.func2(4), 8)\ntest_eq(t.func2.__qualname__, '_T8.func2')\n\nt = _T9(2)\ntest_eq(t.func2(4), 8)\ntest_eq(t.func2.__qualname__, '_T9.func2')\n\nJust like patch_to decorator you can use as_prop, set_prop, and cls_method parameters with patch decorator:\n\n@patch(as_prop=True)\ndef add_ten(self:_T5): return self + 10\n\nt = _T5(4)\ntest_eq(t.add_ten, 14)\n\n\nclass _T2():\n    def __init__(self, val): self._val = val\n\n@patch(as_prop=True)\ndef val(self:_T2): return self._val\n\nt = _T2(2)\ntest_eq(t.val, 2)\n\n@patch(set_prop=True)\ndef val(self:_T2, val): self._val = val\n\nt.val = 3\ntest_eq(t.val, 3)\n\n\nclass _T5(int): attr = 3 # attr is a class attribute we will access in a later method\n    \n@patch(cls_method=True)\ndef func(cls:_T5, x): return cls.attr + x # you can access class attributes in the normal way\n\ntest_eq(_T5.func(4), 7)\n\n\nclass _T8(int): pass  \n\n@patch(nm='add_value')\ndef func2(self:_T8, a): return self+a\n\nt = _T8(1)\ntest_eq(t.add_value(2), 3)\ntest_eq(_T8.add_value.__name__, 'add_value')\nassert not hasattr(t, 'func2')\n\nPatching classmethod shouldn’t affect how python’s inheritance works\n\nclass FastParent: pass\n\n@patch(cls_method=True)\ndef type_cls(cls: FastParent): return cls\n\nclass FastChild(FastParent): pass\n\nparent = FastParent()\ntest_eq(parent.type_cls(), FastParent)\n\nchild = FastChild()\ntest_eq(child.type_cls(), FastChild)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#other-helpers",
    "href": "basics.html#other-helpers",
    "title": "Basic functionality",
    "section": "Other Helpers",
    "text": "Other Helpers\n\nsource\n\ncompile_re\n\ndef compile_re(\n    pat\n):\n\nCompile pat if it’s not None\n\nassert compile_re(None) is None\nassert compile_re('a').match('ab')\n\n\nsource\n\nImportEnum\n\ndef ImportEnum(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nAn Enum that can have its values imported\n\n_T = ImportEnum('_T', {'foobar':1, 'goobar':2})\n_T.imports()\ntest_eq(foobar, _T.foobar)\ntest_eq(goobar, _T.goobar)\n\n\nsource\n\n\nStrEnum\n\ndef StrEnum(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nAn ImportEnum that behaves like a str\n\nsource\n\n\n\nstr_enum\n\ndef str_enum(\n    name, vals:VAR_POSITIONAL\n):\n\nSimplified creation of StrEnum types\n\nsource\n\nValEnum\n\ndef ValEnum(\n    args:VAR_POSITIONAL, kwds:VAR_KEYWORD\n):\n\nAn ImportEnum that stringifies using values\n\n_T = str_enum('_T', 'a', 'b')\ntest_eq(f'{_T.a}', 'a')\ntest_eq(_T.a, 'a')\ntest_eq(list(_T.__members__), ['a','b'])\nprint(_T.a, _T.a.upper())\n\na A\n\n\n\nsource\n\n\nStateful\n\ndef Stateful(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nA base class/mixin for objects that should not serialize all their state\n\nclass _T(Stateful):\n    def __init__(self):\n        super().__init__()\n        self.a=1\n        self._state['test']=2\n\nt = _T()\nt2 = pickle.loads(pickle.dumps(t))\ntest_eq(t.a,1)\ntest_eq(t._state['test'],2)\ntest_eq(t2.a,1)\ntest_eq(t2._state,{})\n\nOverride _init_state to do any necessary setup steps that are required during __init__ or during deserialization (e.g. pickle.load). Here’s an example of how Stateful simplifies the official Python example for Handling Stateful Objects.\n\nclass TextReader(Stateful):\n    \"\"\"Print and number lines in a text file.\"\"\"\n    _stateattrs=('file',)\n    def __init__(self, filename):\n        self.filename,self.lineno = filename,0\n        super().__init__()\n\n    def readline(self):\n        self.lineno += 1\n        line = self.file.readline()\n        if line: return f\"{self.lineno}: {line.strip()}\"\n\n    def _init_state(self):\n        self.file = open(self.filename)\n        for _ in range(self.lineno): self.file.readline()\n\n\nreader = TextReader(\"00_test.ipynb\")\nprint(reader.readline())\nprint(reader.readline())\n\nnew_reader = pickle.loads(pickle.dumps(reader))\nprint(reader.readline())\n\n1: {\n2: \"cells\": [\n3: {\n\n\n\nsource\n\n\n\nNotStr\n\ndef NotStr(\n    s\n):\n\nBehaves like a str, but isn’t an instance of one\n\ns = NotStr(\"hello\")\nassert not isinstance(s, str)\ntest_eq(s, 'hello')\ntest_eq(s*2, 'hellohello')\ntest_eq(len(s), 5)\ntest_eq(s[:2], \"he\")\ntest_eq(s[2], \"l\")\n\n\nsource\n\nPrettyString\n\ndef PrettyString(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nLittle hack to get strings to show properly in Jupyter.\nAllow strings with special characters to render properly in Jupyter. Without calling print() strings with special characters are displayed like so:\n\nwith_special_chars='a string\\nwith\\nnew\\nlines and\\ttabs'\nwith_special_chars\n\n'a string\\nwith\\nnew\\nlines and\\ttabs'\n\n\nWe can correct this with PrettyString:\n\nPrettyString(with_special_chars)\n\na string\nwith\nnew\nlines and   tabs\n\n\n\nsource\n\n\n\neven_mults\n\ndef even_mults(\n    start, stop, n\n):\n\nBuild log-stepped array from start to stop in n steps.\n\ntest_eq(even_mults(2,8,3), [2,4,8])\ntest_eq(even_mults(2,32,5), [2,4,8,16,32])\ntest_eq(even_mults(2,8,1), 8)\n\n\nsource\n\n\nnum_cpus\n\ndef num_cpus(\n    \n):\n\nGet number of cpus\n\nnum_cpus()\n\n16\n\n\n\nsource\n\n\nadd_props\n\ndef add_props(\n    f, g:NoneType=None, n:int=2\n):\n\nCreate properties passing each of range(n) to f\n\nclass _T(): a,b = add_props(lambda i,x:i*2)\n\nt = _T()\ntest_eq(t.a,0)\ntest_eq(t.b,2)\n\n\nclass _T(): \n    def __init__(self, v): self.v=v\n    def _set(i, self, v): self.v[i] = v\n    a,b = add_props(lambda i,x: x.v[i], _set)\n\nt = _T([0,2])\ntest_eq(t.a,0)\ntest_eq(t.b,2)\nt.a = t.a+1\nt.b = 3\ntest_eq(t.a,1)\ntest_eq(t.b,3)\n\n\nsource\n\n\nstr2bool\n\ndef str2bool(\n    s\n):\n\nCase-insensitive convert string s too a bool (y,yes,t,true,on,1-&gt;True)\nTrue values are ‘y’, ‘yes’, ‘t’, ‘true’, ‘on’, and ‘1’; false values are ‘n’, ‘no’, ‘f’, ‘false’, ‘off’, and ‘0’. Raises ValueError if ‘val’ is anything else.\n\nfor o in \"y YES t True on 1\".split(): assert str2bool(o)\nfor o in \"n no FALSE off 0\".split(): assert not str2bool(o)\nfor o in 0,None,'',False: assert not str2bool(o)\nfor o in 1,True: assert str2bool(o)\n\n\nsource\n\n\nstr2int\n\ndef str2int(\n    s\n)-&gt;int:\n\nConvert s to an int\n\nsource\n\n\nstr2float\n\ndef str2float(\n    s:str\n):\n\nConvert s to a float\n\nsource\n\n\nstr2list\n\ndef str2list(\n    s:str\n):\n\nConvert s to a list\n\nsource\n\n\nstr2date\n\ndef str2date(\n    s:str\n)-&gt;date:\n\ndate.fromisoformat with empty string handling\n\nsource\n\n\nto_date\n\ndef to_date(\n    arg\n):\n\n\nsource\n\n\nto_list\n\ndef to_list(\n    arg\n):\n\n\nsource\n\n\nto_float\n\ndef to_float(\n    arg\n):\n\n\nsource\n\n\nto_int\n\ndef to_int(\n    arg\n):\n\n\nsource\n\n\nto_bool\n\ndef to_bool(\n    arg\n):\n\n\nsource\n\n\ntyped\n\ndef typed(\n    _func:NoneType=None, cast:bool=False\n):\n\nDecorator to check param and return types at runtime, with optional casting\ntyped validates argument types at runtime. This is in contrast to MyPy which only offers static type checking.\nFor example, a TypeError will be raised if we try to pass an integer into the first argument of the below function:\n\n@typed\ndef discount(price:int, pct:float) -&gt; float:\n    return (1-pct) * price\n\nwith ExceptionExpected(TypeError): discount(100.0, .1)\n\nYou can have automatic casting based on heuristics by specifying typed(cast=True). If casting is not possible, a TypeError is raised.\n\n@typed(cast=True)\ndef discount(price:int, pct:float) -&gt; float:\n    return (1-pct) * price\n\nassert 90.0 == discount(100.5, .1) # will auto cast 100.5 to the int 100\nassert 90.0 == discount(' 100 ', .1) # will auto cast the str \"100\" to the int 100\nwith ExceptionExpected(TypeError): discount(\"a\", .1)\n\nWe can also optionally allow multiple types by enumarating the types in a tuple as illustrated below:\n\n@typed\ndef discount(price:int|float, pct:float): \n    return (1-pct) * price\n\nassert 90.0 == discount(100.0, .1)\n\n@typed(cast=True)\ndef discount(price:int|None, pct:float):\n    return (1-pct) * price\n\nassert 90.0 == discount(100.0, .1)\n\nWe currently do not support union types when casting.\n\n@typed(cast=True)\ndef discount(price:int|float, pct:float):\n    return (1-pct) * price\n\nwith ExceptionExpected(AssertionError): assert 90.0 == discount(\"100.0\", .1)\n\ntyped works with classes, too:\n\nclass Foo:\n    @typed\n    def __init__(self, a:int, b: int, c:str): pass\n    @typed(cast=True)\n    def test(cls, d:str): return d\n\nwith ExceptionExpected(TypeError): Foo(1, 2, 3) \nassert isinstance(Foo(1,2, 'a string').test(10), str)\n\nIt also works with custom types.\n\n@typed\ndef test_foo(foo: Foo): pass\n\nwith ExceptionExpected(TypeError): test_foo(1)\ntest_foo(Foo(1, 2, 'a string'))\n\n\nclass Bar:\n    @typed\n    def __init__(self, a:int): self.a = a\n@typed(cast=True)\ndef test_bar(bar: Bar): return bar\n\nassert isinstance(test_bar(1), Bar)\ntest_eq(test_bar(1).a, 1)\nwith ExceptionExpected(TypeError): test_bar(\"foobar\")\n\n\nsource\n\n\nexec_new\n\ndef exec_new(\n    code\n):\n\nExecute code in a new environment and return it\n\ng = exec_new('a=1')\ntest_eq(g['a'], 1)\n\n\nsource\n\n\nexec_import\n\ndef exec_import(\n    mod, sym\n):\n\nImport sym from mod in a new environment\n\nsource\n\n\nsig_with_params\n\ndef sig_with_params(\n    sig, remove:NoneType=None, keep:NoneType=None, updates:VAR_KEYWORD\n):\n\nsig_with_params lets you modify a function signature by adding, replacing, or removing parameters. This is useful when creating wrapper functions or decorators that need to adjust the signature of the wrapped function.\nYou can remove parameters by name:\n\nfrom inspect import signature, Parameter\n\n\ndef foo(a, b, c=3): pass\nsig = signature(foo)\n\nnew_sig = sig_with_params(sig, remove=['b'])\ntest_eq(list(new_sig.parameters.keys()), ['a', 'c'])\n\nYou can also add new parameters:\n\nnew_param = Parameter('d', Parameter.KEYWORD_ONLY, default=4)\nnew_sig = sig_with_params(sig, d=new_param)\ntest_eq(list(new_sig.parameters.keys()), ['a', 'b', 'c', 'd'])\n\n\nsource\n\n\nfdelegates\n\ndef fdelegates(\n    to\n):\n\nThis is a simplified version of fastcore.meta.delegates that supports only regular functions.",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "basics.html#notebook-functions",
    "href": "basics.html#notebook-functions",
    "title": "Basic functionality",
    "section": "Notebook functions",
    "text": "Notebook functions\n\n\nipython_shell\n\ndef ipython_shell(\n    \n):\n\nSame as get_ipython but returns False if not in IPython\n\n\n\nin_ipython\n\ndef in_ipython(\n    \n):\n\nCheck if code is running in some kind of IPython environment\n\n\n\nin_colab\n\ndef in_colab(\n    \n):\n\nCheck if the code is running in Google Colaboratory\n\n\n\nin_jupyter\n\ndef in_jupyter(\n    \n):\n\nCheck if the code is running in a jupyter notebook\n\n\n\nin_notebook\n\ndef in_notebook(\n    \n):\n\nCheck if the code is running in a jupyter notebook\nThese variables are available as booleans in fastcore.basics as IN_IPYTHON, IN_JUPYTER, IN_COLAB and IN_NOTEBOOK.\n\nIN_IPYTHON, IN_JUPYTER, IN_COLAB, IN_NOTEBOOK\n\n(True, True, False, True)",
    "crumbs": [
      "Basic functionality"
    ]
  },
  {
    "objectID": "script.html",
    "href": "script.html",
    "title": "Script - CLI",
    "section": "",
    "text": "Part of fast.ai’s toolkit for delightful developer experiences.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#overview",
    "href": "script.html#overview",
    "title": "Script - CLI",
    "section": "Overview",
    "text": "Overview\nSometimes, you want to create a quick script, either for yourself, or for others. But in Python, that involves a whole lot of boilerplate and ceremony, especially if you want to support command line arguments, provide help, and other niceties. You can use argparse for this purpose, which comes with Python, but it’s complex and verbose.\nfastcore.script makes life easier. There are much fancier modules to help you write scripts (we recommend Python Fire, and Click is also popular), but fastcore.script is very fast and very simple. In fact, it’s &lt;50 lines of code! Basically, it’s just a little wrapper around argparse that uses modern Python features and some thoughtful defaults to get rid of the boilerplate.\nFor full details, see the docs for core.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#example",
    "href": "script.html#example",
    "title": "Script - CLI",
    "section": "Example",
    "text": "Example\nHere’s a complete example (available in examples/test_fastcore.py):\nfrom fastcore.script import *\n@call_parse\ndef main(msg:str,     # The message\n         upper:bool): # Convert to uppercase?\n    \"Print `msg`, optionally converting to uppercase\"\n    print(msg.upper() if upper else msg)\nIf you copy that info a file and run it, you’ll see:\n$ examples/test_fastcore.py --help\nusage: test_fastcore.py [-h] [--upper] msg\n\nPrint `msg`, optionally converting to uppercase\n\npositional arguments:\n  msg          The message\n\noptional arguments:\n  -h, --help   show this help message and exit\n  --upper      Convert to uppercase? (default: False)\nAs you see, we didn’t need any if __name__ == \"__main__\", we didn’t have to parse arguments, we just wrote a function, added a decorator to it, and added some annotations to our function’s parameters. As a bonus, we can also use this function directly from a REPL such as Jupyter Notebook - it’s not just for command line scripts!\nYou should provide a default (after the =) for any optional parameters. If you don’t provide a default for a parameter, then it will be a positional parameter.\n\n\n\n\n\n\nWarningBoolean Arguments Default to False\n\n\n\nArguments of type bool or store_true default to False regardless of whether you provide a default or not. Use bool_arg as the type instead of bool if you want to set a default value of True. For example:\n@call_parse\ndef main(msg:str=\"Hi\",     # The message\n         upper:bool_arg=True): # Convert to uppercase?",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#param-annotations",
    "href": "script.html#param-annotations",
    "title": "Script - CLI",
    "section": "Param annotations",
    "text": "Param annotations\nIf you want to use the full power of argparse, you can do so by using Param annotations instead of type annotations and docments, like so:\nfrom fastcore.script import *\n@call_parse\ndef main(msg:Param(\"The message\", str),\n         upper:Param(\"Convert to uppercase?\", store_true)):\n    \"Print `msg`, optionally converting to uppercase\"\n    print(msg.upper() if upper else msg)\nIf you use this approach, then each parameter in your function should have an annotation Param(...) (as in the example above). You can pass the following when calling Param: help,type,opt,action,nargs,const,choices,required . Except for opt, all of these are just passed directly to argparse, so you have all the power of that module at your disposal. Generally you’ll want to pass at least help (since this is provided as the help string for that parameter) and type (to ensure that you get the type of data you expect). opt is a bool that defines whether a param is optional or required (positional) - but you’ll generally not need to set this manually, because fastcore.script will set it for you automatically based on default values.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#setuptools-scripts",
    "href": "script.html#setuptools-scripts",
    "title": "Script - CLI",
    "section": "setuptools scripts",
    "text": "setuptools scripts\nThere’s a really nice feature of pip/setuptools that lets you create commandline scripts directly from functions, makes them available in the PATH, and even makes your scripts cross-platform (e.g. in Windows it creates an exe). fastcore.script supports this feature too. The trick to making a function available as a script is to add a console_scripts section to your setup file, of the form: script_name=module:function_name. E.g. in this case we use: test_fastcore.script=fastcore.script.test_cli:main. With this, you can then just type test_fastcore.script at any time, from any directory, and your script will be called (once it’s installed using one of the methods below).\nYou don’t actually have to write a setup.py yourself. Instead, just use nbdev. Then modify settings.ini as appropriate for your module/script. To install your script directly, you can type pip install -e .. Your script, when installed this way (it’s called an editable install), will automatically be up to date even if you edit it - there’s no need to reinstall it after editing. With nbdev you can even make your module and script available for installation directly from pip and conda by running make release.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "script.html#api-details",
    "href": "script.html#api-details",
    "title": "Script - CLI",
    "section": "API details",
    "text": "API details\n\nsource\n\nstore_true\n\ndef store_true(\n    \n):\n\nPlaceholder to pass to Param for store_true action\n\nsource\n\n\nstore_false\n\ndef store_false(\n    \n):\n\nPlaceholder to pass to Param for store_false action\n\nsource\n\n\nbool_arg\n\ndef bool_arg(\n    v\n):\n\nUse as type for Param to get bool behavior\n\nsource\n\n\nclean_type_str\n\ndef clean_type_str(\n    x:str\n):\n\n\nclass Test: pass\n\ntest_eq(clean_type_str(argparse.ArgumentParser), 'argparse.ArgumentParser')\ntest_eq(clean_type_str(Test), 'Test')\ntest_eq(clean_type_str(int), 'int')\ntest_eq(clean_type_str(float), 'float')\ntest_eq(clean_type_str(store_false), 'store_false')\n\n\nsource\n\n\nParam\n\ndef Param(\n    help:str='', type:NoneType=None, opt:bool=True, action:NoneType=None, nargs:NoneType=None, const:NoneType=None,\n    choices:NoneType=None, required:NoneType=None, default:NoneType=None, version:NoneType=None\n):\n\nA parameter in a function used in anno_parser or call_parse\n\ntest_eq(repr(Param(\"Help goes here\")), '&lt;Help goes here&gt;')\ntest_eq(repr(Param(\"Help\", int)), 'int &lt;Help&gt;')\ntest_eq(repr(Param(help=None, type=int)), 'int')\ntest_eq(repr(Param(help=None, type=None)), '')\n\nEach parameter in your function should have an annotation Param(...). You can pass the following when calling Param: help,type,opt,action,nargs,const,choices,required, version (i.e. it takes the same parameters as argparse.ArgumentParser.add_argument, plus opt). Except for opt, all of these are just passed directly to argparse, so you have all the power of that module at your disposal. Generally you’ll want to pass at least help (since this is provided as the help string for that parameter) and type (to ensure that you get the type of data you expect).\nopt is a bool that defines whether a param is optional or required (positional) - but you’ll generally not need to set this manually, because fastcore.script will set it for you automatically based on default values. You should provide a default (after the =) for any optional parameters. If you don’t provide a default for a parameter, then it will be a positional parameter.\nParam’s __repr__ also allows for more informative function annotation when looking up the function’s doc using shift+tab. You see the type annotation (if there is one) and the accompanying help documentation with it.\n\ndef f(required:Param(\"Required param\", int),\n      a:Param(\"param 1\", bool_arg),\n      b:Param(\"param 2\", str)=\"test\"):\n    \"my docs\"\n    ...\n\n\nhelp(f)\n\nHelp on function f in module __main__:\n\nf(required: int &lt;Required param&gt;, a: bool_arg &lt;param 1&gt;, b: str &lt;param 2&gt; = 'test')\n    my docs\n\n\n\n\np = Param(help=\"help\", type=int)\np.set_default(1)\ntest_eq(p.kwargs, {'help': 'help (default: 1)', 'type': int, 'default': 1})\n\n\nsource\n\n\nanno_parser\n\ndef anno_parser(\n    func, prog:str=None\n):\n\nLook at params (annotated with Param) in func and return an ArgumentParser\nThis converts a function with parameter annotations of type Param into an argparse.ArgumentParser object. Function arguments with a default provided are optional, and other arguments are positional.\n\n_en = str_enum('_en', 'aa','bb','cc')\ndef f(required:Param(\"Required param\", int),\n      a:Param(\"param 1\", bool_arg),\n      v:Param(\"Print version\", action='version', version='%(prog)s 2.0.0'),\n      b:Param(\"param 2\", str)=\"test\",\n      c:Param(\"param 3\", _en)=_en.aa):\n    \"my docs\"\n    ...\n\np = anno_parser(f, 'progname')\np.print_help()\n\nusage: progname [-h] [--a] [--v] [--b B] [--c {aa,bb,cc}] required\n\nmy docs\n\npositional arguments:\n  required        Required param\n\noptions:\n  -h, --help      show this help message and exit\n  --a             param 1 (default: False)\n  --v             Print version\n  --b B           param 2 (default: test)\n  --c {aa,bb,cc}  param 3 (default: aa)\n\n\nWe can also check the version and help flags are working.\n\ntry: p.parse_args(['--v'])\nexcept: pass\n\nprogname 2.0.0\n\n\n\ntry: p.parse_args(['-h'])\nexcept: pass\n\nusage: progname [-h] [--a] [--v] [--b B] [--c {aa,bb,cc}] required\n\nmy docs\n\npositional arguments:\n  required        Required param\n\noptions:\n  -h, --help      show this help message and exit\n  --a             param 1 (default: False)\n  --v             Print version\n  --b B           param 2 (default: test)\n  --c {aa,bb,cc}  param 3 (default: aa)\n\n\nIt also works with type annotations and docments:\n\ndef g(required:int,  # Required param\n      a:bool_arg,    # param 1\n      b=\"test\",      # param 2\n      c:_en=_en.aa): # param 3\n    \"my docs\"\n    ...\n\np = anno_parser(g, 'progname')\np.print_help()\n\nusage: progname [-h] [--a] [--b B] [--c {aa,bb,cc}] required\n\nmy docs\n\npositional arguments:\n  required        Required param\n\noptions:\n  -h, --help      show this help message and exit\n  --a             param 1 (default: False)\n  --b B           param 2 (default: test)\n  --c {aa,bb,cc}  param 3 (default: aa)\n\n\nIt also works with Union types:\n\ndef h(n:int|str, exts:str|list=None):\n    \"Test union types\"\n\np = anno_parser(h, 'test')\np.print_help()\n\nusage: test [-h] [--exts EXTS] n\n\nTest union types\n\npositional arguments:\n  n\n\noptions:\n  -h, --help   show this help message and exit\n  --exts EXTS\n\n\n\ntest_eq(p.parse_args(['42', '--exts', 'py']).n, 42)\ntest_eq(p.parse_args(['hello']).n, 'hello')\n\nSometimes it’s convenient to extract arguments from the actual name of the called program. args_from_prog will do this, assuming that names and values of the params are separated by a #. Optionally there can also be a prefix separated by ## (double underscore).\n\nsource\n\n\nargs_from_prog\n\ndef args_from_prog(\n    func, prog\n):\n\nExtract args from prog\n\nexp = {'a': False, 'b': 'baa'}\ntest_eq(args_from_prog(f, 'foo##a#0#b#baa'), exp)\ntest_eq(args_from_prog(f, 'a#0#b#baa'), exp)\n\n\nsource\n\n\ncall_parse\n\ndef call_parse(\n    func:NoneType=None, nested:bool=False\n):\n\nDecorator to create a simple CLI from func using anno_parser\n\n@call_parse\ndef test_add(\n    a:int=0,  # param a\n    b:int=0  # param 1\n):\n    \"Add up `a` and `b`\"\n    return a + b\n\ncall_parse decorated functions work as regular functions and also as command-line interface functions.\n\ntest_eq(test_add(1,2), 3)\n\nThis is the main way to use fastcore.script; decorate your function with call_parse, add Param annotations (as shown above) or type annotations and docments, and it can then be used as a script.\nUse the nested keyword argument to create nested parsers, where earlier parsers consume only their known args from sys.argv before later parsers are used. This is useful to create one command line application that executes another. For example:\nmyrunner --keyword 1 script.py -- &lt;script.py args&gt;\nA separating -- after the first application’s args is recommended though not always required, otherwise args may be parsed in unexpected ways. For example:\nmyrunner script.py -h\nwould display myrunner’s help and not script.py’s.",
    "crumbs": [
      "Script - CLI"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to fastcore",
    "section": "",
    "text": "Python is a powerful, dynamic language. Rather than bake everything into the language, it lets the programmer customize it to make it work for them. fastcore uses this flexibility to add to Python features inspired by other languages we’ve loved, mixins from Ruby, and currying, binding, and more from Haskell. It also adds some “missing features” and clean up some rough edges in the Python standard library, such as simplifying parallel processing, and bringing ideas from NumPy over to Python’s list type.",
    "crumbs": [
      "Welcome to fastcore"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Welcome to fastcore",
    "section": "Getting started",
    "text": "Getting started\nTo install fastcore run: conda install fastcore -c fastai (if you use Anaconda, which we recommend) or pip install fastcore. For an editable install, clone this repo and run: pip install -e \".[dev]\". fastcore is tested to work on Ubuntu, macOS and Windows (versions tested are those shown with the -latest suffix here).\nfastcore contains many features, including:\n\nfastcore.test: Simple testing functions\nfastcore.foundation: Mixins, delegation, composition, and more\nfastcore.xtras: Utility functions to help with functional-style programming, parallel processing, and more\n\nTo get started, we recommend you read through the fastcore tour.",
    "crumbs": [
      "Welcome to fastcore"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Welcome to fastcore",
    "section": "Contributing",
    "text": "Contributing\nAfter you clone this repository, please run nbdev_install_hooks in your terminal. This sets up git hooks, which clean up the notebooks to remove the extraneous stuff stored in the notebooks (e.g. which cells you ran) which causes unnecessary merge conflicts.\nTo run the tests in parallel, launch nbdev_test.\nBefore submitting a PR, check that the local library and notebooks match.\n\nIf you made a change to the notebooks in one of the exported cells, you can export it to the library with nbdev_prepare.\nIf you made a change to the library, you can export it back to the notebooks with nbdev_update.",
    "crumbs": [
      "Welcome to fastcore"
    ]
  },
  {
    "objectID": "docments.html",
    "href": "docments.html",
    "title": "Docments",
    "section": "",
    "text": "docments provides programmatic access to comments in function parameters and return types. It can be used to create more developer-friendly documentation, CLI, etc tools.",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#why",
    "href": "docments.html#why",
    "title": "Docments",
    "section": "Why?",
    "text": "Why?\nWithout docments, if you want to document your parameters, you have to repeat param names in docstrings, since they’re already in the function signature. The parameters have to be kept synchronized in the two places as you change your code. Readers of your code have to look back and forth between two places to understand what’s happening. So it’s more work for you, and for your users.\nFurthermore, to have parameter documentation formatted nicely without docments, you have to use special magic docstring formatting, often with odd quirks, which is a pain to create and maintain, and awkward to read in code. For instance, using numpy-style documentation:\n\ndef add_np(a:int, b:int=0)-&gt;int:\n    \"\"\"The sum of two numbers.\n    \n    Used to demonstrate numpy-style docstrings.\n\nParameters\n----------\na : int\n    the 1st number to add\nb : int\n    the 2nd number to add (default: 0)\n\nReturns\n-------\nint\n    the result of adding `a` to `b`\"\"\"\n    return a+b\n\nBy comparison, here’s the same thing using docments:\n\ndef add(\n    a:int, # the 1st number to add\n    b=0,   # the 2nd number to add\n)-&gt;int:    # the result of adding `a` to `b`\n    \"The sum of two numbers.\"\n    return a+b",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#numpy-docstring-helper-functions",
    "href": "docments.html#numpy-docstring-helper-functions",
    "title": "Docments",
    "section": "Numpy docstring helper functions",
    "text": "Numpy docstring helper functions\ndocments also supports numpy-style docstrings, or a mix or numpy-style and docments parameter documentation. The functions in this section help get and parse this information.\n\nsource\n\ndocstring\n\ndef docstring(\n    sym\n):\n\nGet docstring for sym for functions ad classes\n\ntest_eq(docstring(add), \"The sum of two numbers.\")\n\n\nsource\n\n\nparse_docstring\n\ndef parse_docstring(\n    sym\n):\n\nParse a numpy-style docstring in sym\n\n# parse_docstring(add_np)\n\n\nsource\n\n\nisdataclass\n\ndef isdataclass(\n    s\n):\n\nCheck if s is a dataclass but not a dataclass’ instance\n\nsource\n\n\nget_dataclass_source\n\ndef get_dataclass_source(\n    s\n):\n\nGet source code for dataclass s\n\nsource\n\n\nget_source\n\ndef get_source(\n    s\n):\n\nGet source code for string, function object or dataclass s\n\nparms = _param_locs(add)\nparms\n\n{2: 'a', 3: 'b', 4: 'return'}\n\n\n\n_get_comment(2, 'a', {2: ' the 1st number to add'}, parms)\n\n'the 1st number to add'\n\n\n\nsource\n\n\nget_name\n\ndef get_name(\n    obj\n):\n\nGet the name of obj\n\ntest_eq(get_name(in_ipython), 'in_ipython')\ntest_eq(get_name(L.map), 'map')\n\n\nsource\n\n\nqual_name\n\ndef qual_name(\n    obj\n):\n\nGet the qualified name of obj\n\nassert qual_name(docscrape) == 'fastcore.docscrape'",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#docments",
    "href": "docments.html#docments",
    "title": "Docments",
    "section": "Docments",
    "text": "Docments\nLet’s manually go through each step of _docments to see what it does:\n\ndef _b(\n    z:str='b', # Last\n):\n    return b, a\n\n@delegates(_b)\ndef _c(\n    b:str, # Ignore\n    a:int=2\n): return b, a # Third\n\n@delegates(_c)\ndef _d(\n    c:int, # First\n    b:str, # Second\n    **kwargs\n)-&gt;int: # Return an int\n    return c, _c(b, **kwargs)\n\n\ns = _d\nnps = parse_docstring(s)\nif isclass(s) and not is_dataclass(s): s = s.__init__\ncomments = {o.start[0]:_clean_comment(o.string) for o in _tokens(s) if o.type==COMMENT}\ncomments\n\n{3: ' First', 4: ' Second', 6: ' Return an int'}\n\n\n\nparms = _param_locs(s, returns=True, args_kwargs=True) or {}\nparms\n\n{3: 'c', 4: 'b', 5: 'kwargs', 6: 'return'}\n\n\n\ndocs = {arg:_get_comment(line, arg, comments, parms) for line,arg in parms.items()}\ndocs\n\n{'c': 'First', 'b': 'Second', 'kwargs': None, 'return': 'Return an int'}\n\n\n\nsig = signature(s, eval_str=True)\nres = {name:_get_full(p, docs) for name,p in sig.parameters.items()}\nres\n\n{'c': {'docment': 'First', 'anno': int, 'default': inspect._empty},\n 'b': {'docment': 'Second', 'anno': str, 'default': inspect._empty},\n 'a': {'docment': None, 'anno': int, 'default': 2},\n 'z': {'docment': None, 'anno': str, 'default': 'b'}}\n\n\n\nres['return'] = AttrDict(docment=docs.get('return'), anno=sig.return_annotation, default=empty)\nres = _merge_docs(res, nps)\nres\n\n{'c': {'docment': 'First', 'anno': int, 'default': inspect._empty},\n 'b': {'docment': 'Second', 'anno': str, 'default': inspect._empty},\n 'a': {'docment': None, 'anno': int, 'default': 2},\n 'z': {'docment': None, 'anno': str, 'default': 'b'},\n 'return': {'docment': 'Return an int',\n  'anno': int,\n  'default': inspect._empty}}\n\n\n\n_d.__delwrap__\n\n&lt;function __main__._c(b: str, a: int = 2, *, z: str = 'b')&gt;\n\n\n\nsource\n\ndocments\n\ndef docments(\n    s, full:bool=False, eval_str:bool=False, returns:bool=True, args_kwargs:bool=False\n):\n\nGet docments for s\n\ndocments(_d)\n\n{'a': None, 'b': 'Second', 'c': 'First', 'return': 'Return an int', 'z': 'Last'}\n\n\n\ndocments(_d, full=True)\n\n{ 'a': {'anno': &lt;class 'int'&gt;, 'default': 2, 'docment': None},\n  'b': { 'anno': &lt;class 'str'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'Second'},\n  'c': { 'anno': &lt;class 'int'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'First'},\n  'return': { 'anno': &lt;class 'int'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': 'Return an int'},\n  'z': {'anno': &lt;class 'str'&gt;, 'default': 'b', 'docment': 'Last'}}\n\n\nThe returned dict has parameter names as keys, docments as values. The return value comment appears in the return, unless returns=False. Using the add definition above, we get:\n\ndef add(\n    a:int, # the 1st number to add\n    b=0,   # the 2nd number to add\n)-&gt;int:    # the result of adding `a` to `b`\n    \"The sum of two numbers.\"\n    return a+b\n\n\ndocments(add)\n\n{ 'a': 'the 1st number to add',\n  'b': 'the 2nd number to add',\n  'return': 'the result of adding `a` to `b`'}\n\n\nargs_kwargs=True adds args and kwargs docs too:\n\ndef add(\n    a:int, # the 1st number to add\n    *args, # some args\n    b=0,   # the 2nd number to add\n    **kwargs, # Passed to the `example` function\n)-&gt;int:    # the result of adding `a` to `b`\n    \"The sum of two numbers.\"\n    return a+b\n\n\ndocments(add, args_kwargs=True)\n\n{ 'a': 'the 1st number to add',\n  'args': 'some args',\n  'b': 'the 2nd number to add',\n  'kwargs': 'Passed to the `example` function',\n  'return': 'the result of adding `a` to `b`'}\n\n\nIf you pass full=True, the values are dict of defaults, types, and docments as values. Note that the type annotation is inferred from the default value, if the annotation is empty and a default is supplied. (Note that for full, args_kwargs=True is always set too.)\n\ndocments(add, full=True)\n\n{ 'a': { 'anno': &lt;class 'int'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'the 1st number to add'},\n  'args': { 'anno': &lt;_ParameterKind.VAR_POSITIONAL: 2&gt;,\n            'default': &lt;class 'inspect._empty'&gt;,\n            'docment': 'some args'},\n  'b': { 'anno': &lt;class 'int'&gt;,\n         'default': 0,\n         'docment': 'the 2nd number to add'},\n  'kwargs': { 'anno': &lt;_ParameterKind.VAR_KEYWORD: 4&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': None},\n  'return': { 'anno': &lt;class 'int'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': 'the result of adding `a` to `b`'}}\n\n\nTo evaluate stringified annotations (from python 3.10), use eval_str:\n\ndocments(add, full=True, eval_str=True)['a']\n\n{ 'anno': &lt;class 'int'&gt;,\n  'default': &lt;class 'inspect._empty'&gt;,\n  'docment': 'the 1st number to add'}\n\n\n\ndocments(add, full=True)['a']\n\n{ 'anno': &lt;class 'int'&gt;,\n  'default': &lt;class 'inspect._empty'&gt;,\n  'docment': 'the 1st number to add'}\n\n\nIf you need more space to document a parameter, place one or more lines of comments above the parameter, or above the return type. You can mix-and-match these docment styles:\n\ndef add(\n    # The first operand\n    a:int,\n    # This is the second of the operands to the *addition* operator.\n    # Note that passing a negative value here is the equivalent of the *subtraction* operator.\n    b:int,\n)-&gt;int: # The result is calculated using Python's builtin `+` operator.\n    \"Add `a` to `b`\"\n    return a+b\n\n\ndocments(add)\n\n{ 'a': 'The first operand',\n  'b': 'This is the second of the operands to the *addition* operator.\\n'\n       'Note that passing a negative value here is the equivalent of the '\n       '*subtraction* operator.',\n  'return': \"The result is calculated using Python's builtin `+` operator.\"}\n\n\nDocments works with async functions, too:\n\nasync def add_async(\n    # The first operand\n    a:int,\n    # This is the second of the operands to the *addition* operator.\n    # Note that passing a negative value here is the equivalent of the *subtraction* operator.\n    b:int,\n)-&gt;int: # The result is calculated using Python's builtin `+` operator.\n    \"Add `a` to `b`\"\n    return a+b\n\n\ntest_eq(docments(add_async), docments(add))\n\nYou can also use docments with classes and methods:\n\nclass Adder:\n    \"An addition calculator\"\n    def __init__(self,\n        a:int, # First operand\n        b:int, # 2nd operand\n    ): self.a,self.b = a,b\n    \n    def calculate(self\n                 )-&gt;int: # Integral result of addition operator\n        \"Add `a` to `b`\"\n        return a+b\n\n\ndocments(Adder)\n\n{'a': 'First operand', 'b': '2nd operand', 'return': None, 'self': None}\n\n\n\ndocments(Adder.calculate)\n\n{'return': 'Integral result of addition operator', 'self': None}\n\n\ndocments can also be extracted from numpy-style docstrings:\n\nprint(add_np.__doc__)\n\nThe sum of two numbers.\n\n    Used to demonstrate numpy-style docstrings.\n\nParameters\n----------\na : int\n    the 1st number to add\nb : int\n    the 2nd number to add (default: 0)\n\nReturns\n-------\nint\n    the result of adding `a` to `b`\n\n\n\ndocments(add_np)\n\n{ 'a': 'the 1st number to add',\n  'b': 'the 2nd number to add (default: 0)',\n  'return': 'the result of adding `a` to `b`'}\n\n\nYou can even mix and match docments and numpy parameters:\n\ndef add_mixed(a:int, # the first number to add\n              b\n             )-&gt;int: # the result\n    \"\"\"The sum of two numbers.\n\nParameters\n----------\nb : int\n    the 2nd number to add (default: 0)\"\"\"\n    return a+b\n\n\ndocments(add_mixed, full=True)\n\n{ 'a': { 'anno': &lt;class 'int'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'the first number to add'},\n  'b': { 'anno': &lt;class 'inspect._empty'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'the 2nd number to add (default: 0)'},\n  'return': { 'anno': &lt;class 'int'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': 'the result'}}\n\n\nYou can use docments with dataclasses, however if the class was defined in online notebook, docments will not contain parameters’ comments. This is because the source code is not available in the notebook. After converting the notebook to a module, the docments will be available. Thus, documentation will have correct parameters’ comments.\nDocments even works with delegates:\n\nfrom fastcore.meta import delegates\n\n\ndef _a(a:str=None): return a # First\n\n@delegates(_a)\ndef _b(b:str, # Second\n       **kwargs\n      ): # Return nothing\n    return b, (_a(**kwargs)) \n\ndocments(_b)\n\n{'a': 'First', 'b': 'Second', 'return': None}\n\n\n\ndocments(_b, full=True)\n\n{ 'a': {'anno': &lt;class 'str'&gt;, 'default': None, 'docment': 'First'},\n  'b': { 'anno': &lt;class 'str'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'Second'},\n  'return': { 'anno': &lt;class 'inspect._empty'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': None}}\n\n\nBuiltins just return an empty dict:\n\ndocments(str)\n\n{'args': None, 'kwargs': None, 'return': None, 'self': None}",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#extract-docstrings",
    "href": "docments.html#extract-docstrings",
    "title": "Docments",
    "section": "Extract docstrings",
    "text": "Extract docstrings\n\nsource\n\nsig_source\n\ndef sig_source(\n    obj\n):\n\nFull source of signature line(s) for a function or class.\n\nprint(sig_source(flexiclass))\n\ndef flexiclass(\n        cls # The class to convert\n    ) -&gt; dataclass:\n\n\n\ndef simple(x: dict[str, int]): return x\nprint(sig_source(simple))\n\ndef simple(x: dict[str, int]): return x\n\n\n\ndef multi(a, b=1,\n          c=2,\n          d=3):\n    return a\nprint(sig_source(multi))\n\ndef multi(a, b=1,\n          c=2,\n          d=3):\n\n\n\nsource\n\n\nextract_docstrings\n\ndef extract_docstrings(\n    code\n):\n\nCreate a dict from function/class/method names to tuples of docstrings and param lists\n\nsample_code = \"\"\"\n\"This is a module.\"\n\ndef top_func(a, b, *args, **kw):\n    \"This is top-level.\"\n    pass\n\nclass SampleClass:\n    \"This is a class.\"\n\n    def __init__(self, x, y):\n        \"Constructor for SampleClass.\"\n        pass\n\n    def method1(self, param1):\n        \"This is method1.\"\n        pass\n\n    def _private_method(self):\n        \"This should not be included.\"\n        pass\n\nclass AnotherClass:\n    def __init__(self, a, b):\n        \"This class has no separate docstring.\"\n        pass\"\"\"\n\nexp = {'_module': ('This is a module.', ''),\n       'top_func': ('This is top-level.', 'a, b, *args, **kw'),\n       'SampleClass': ('This is a class.', 'self, x, y'),\n       'SampleClass.method1': ('This is method1.', 'self, param1'),\n       'AnotherClass': ('This class has no separate docstring.', 'self, a, b')}\ntest_eq(extract_docstrings(sample_code), exp)",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#rendering-docment-tables",
    "href": "docments.html#rendering-docment-tables",
    "title": "Docments",
    "section": "Rendering docment Tables",
    "text": "Rendering docment Tables\nRender nicely formatted tables that shows docments for any function or method.\n\nsource\n\nDocmentTbl\n\ndef DocmentTbl(\n    obj, verbose:bool=True, returns:bool=True\n):\n\nCompute the docment table string\nDocmentTbl can render a markdown table showing docments if appropriate. This is an example of how a docments table will render for a function:\n\ndef _f(a,      # description of param a\n       b=True, # description of param b\n       c:str=None\n       ) -&gt; int: ...\n\n_dm = DocmentTbl(_f)\n_dm\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\nReturns\nint\n\n\n\n\n\n\n\nIf one column in the table has no information, for example because there are no default values, that column will not be shown. In the below example, the Default column, will not be shown. Additionally, if the return of the function is not annotated the Returns row will not be rendered:\n\ndef _f(a,\n        b:int, #param b\n        c:str='foo'  #param c\n       )-&gt;str: # Result of doing it\n    \"Do a thing\"\n    ...\n\n\n_dm2 = DocmentTbl(_f)\n_dm2\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\n\n\n\nb\nint\n\nparam b\n\n\nc\nstr\nfoo\nparam c\n\n\nReturns\nstr\n\nResult of doing it\n\n\n\n\n\nDocmentTbl also works on classes. By default, the __init__ will be rendered:\n\nclass _Test:\n    def __init__(self,\n                 a,      # description of param a\n                 b=True, # description of param b\n                 c:str=None):\n        ...\n\n    def foo(self,\n            c:int,      # description of param c\n            d=True, # description of param d\n           ):\n        ...\n\n\nDocmentTbl(_Test)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\n\n\n\nYou can also pass a method to be rendered as well:\n\nDocmentTbl(_Test.foo)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nc\nint\n\ndescription of param c\n\n\nd\nbool\nTrue\ndescription of param d\n\n\n\n\n\n\nsource\n\n\nDocmentList\n\ndef DocmentList(\n    obj\n):\n\nInitialize self. See help(type(self)) for accurate signature.\n\nDocmentList(_f)\n\n\na\nb:int   param b\nc:str=foo   param c\nreturn:str   Result of doing it\n\n\n\n\nsource\n\n\nDocmentText\n\ndef DocmentText(\n    obj, maxline:int=110, docstring:bool=True\n):\n\nInitialize self. See help(type(self)) for accurate signature.\n\nDocmentText(_f).params\n\n[('a', None), ('b:int', 'param b'), (\"c:str='foo'\", 'param c')]\n\n\n\nDocmentText(_f)\n\ndef _f(\n    a, b:int, # param b\n    c:str='foo', # param c\n)-&gt;str: # Result of doing it\n    \"Do a thing\"\n\n\n\ndef _g(\n    a, b:int, cccccccccccccccccccc:int, ccccccccdccccccccccc:int, cccccccccccecccccccc:int, cccccccfcccccccccc:int, ccccccccccccgccccc:int, # hi\n    c:str='foo'\n)-&gt;str:\n    \"Do a thing\"\n\nDocmentText(_g, maxline=80, docstring=False)\n\ndef _g(\n    a, b:int, cccccccccccccccccccc:int, ccccccccdccccccccccc:int,\n    cccccccccccecccccccc:int, cccccccfcccccccccc:int, ccccccccccccgccccc:int, # hi\n    c:str='foo'\n)-&gt;str:\n\n\n\nsource\n\n\nsig2str\n\ndef sig2str(\n    func, maxline:int=110\n):\n\nGenerate function signature with docments as comments\n\nprint(sig2str(_d))\n\ndef _d(\n    c:int, # First\n    b:str, # Second\n    a:int=2, z:str='b', # Last\n)-&gt;int: # Return an int",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "docments.html#documentation-for-an-object",
    "href": "docments.html#documentation-for-an-object",
    "title": "Docments",
    "section": "Documentation For An Object",
    "text": "Documentation For An Object\nRender the signature as well as the docments to show complete documentation for an object.\n\nsource\n\nShowDocRenderer\n\ndef ShowDocRenderer(\n    sym, name:str \\| None=None, title_level:int=3, maxline:int=110\n):\n\nShow documentation for sym\n\nsource\n\n\nMarkdownRenderer\n\ndef MarkdownRenderer(\n    sym, name:str \\| None=None, title_level:int=3, maxline:int=110\n):\n\nMarkdown renderer for show_doc\n\ndef _f(a,\n        b:int, #param b\n        c:str='foo'  #param c\n       )-&gt;str: # Result of doing it\n    \"Do a thing\"\n    ...\n\nMarkdownRenderer(_f)\n\n\ndef _f(\n    a, b:int, # param b\n    c:str='foo', # param c\n)-&gt;str: # Result of doing it\n\nDo a thing\n\n\n\ndef f(a:int=0 # aa\n): pass\n\n@delegates(f)\ndef g(\n    b:int, # bb\n    **kwargs\n): return kwargs\n\n\nMarkdownRenderer(g)\n\n\ndef g(\n    b:int, # bb\n    a:int=0, # aa\n):",
    "crumbs": [
      "Docments"
    ]
  },
  {
    "objectID": "xml.html",
    "href": "xml.html",
    "title": "XML",
    "section": "",
    "text": "from IPython.display import Markdown\nfrom pprint import pprint\n\nfrom fastcore.test import test_eq, test_ne",
    "crumbs": [
      "XML"
    ]
  },
  {
    "objectID": "xml.html#ft-functions",
    "href": "xml.html#ft-functions",
    "title": "XML",
    "section": "FT functions",
    "text": "FT functions\n\nsource\n\nattrmap\n\ndef attrmap(\n    o\n):\n\n\nsource\n\n\nvalmap\n\ndef valmap(\n    o\n):\n\n\nsource\n\n\nFT\n\ndef FT(\n    tag:str, cs:tuple, attrs:dict=None, void_:bool=False, kwargs:VAR_KEYWORD\n):\n\nA ‘Fast Tag’ structure, containing tag,children,and attrs\n\nsource\n\n\nft\n\ndef ft(\n    tag:str, c:VAR_POSITIONAL, void_:bool=False, attrmap:callable=&lt;function attrmap at 0x7f7168f28cc0&gt;,\n    valmap:callable=&lt;function valmap at 0x7f7168f28d60&gt;, ft_cls:type=&lt;class '__main__.FT'&gt;, kw:VAR_KEYWORD\n):\n\nCreate an FT structure for to_xml()\nThe main HTML tags are exported as ft partials.\nAttributes are passed as keywords. Use ‘klass’ and ‘fr’ instead of ‘class’ and ‘for’, to avoid Python reserved word clashes.\n\nsource\n\n\nHtml\n\ndef Html(\n    c:VAR_POSITIONAL, doctype:bool=True, kwargs:VAR_KEYWORD\n)-&gt;FT:\n\nAn HTML tag, optionally preceeded by !DOCTYPE HTML\n\nsamp = Html(\n    Head(Title('Some page')),\n    Body(Div('Some text\\nanother line', (Input(name=\"jph's\"), Img(src=\"filename\", data=1)),\n             cls=['myclass', 'another'],\n             style={'padding':1, 'margin':2}))\n)\npprint(samp)\n\n(!doctype((),{'html': True}),\n html((head((title(('Some page',),{}),),{}), body((div(('Some text\\nanother line', input((),{'name': \"jph's\"}), img((),{'src': 'filename', 'data': 1})),{'class': 'myclass another', 'style': 'padding:1; margin:2'}),),{})),{}))\n\n\n\nelem = P('Some text', id=\"myid\")\nprint(elem.tag)\nprint(elem.children)\nprint(elem.attrs)\n\np\n('Some text',)\n{'id': 'myid'}\n\n\nYou can get and set attrs directly:\n\nelem.id = 'newid'\nprint(elem.id, elem.get('id'), elem.get('foo', 'missing'))\nelem\n\nnewid newid missing\n\n\np(('Some text',),{'id': 'newid'})\n\n\n\nsource\n\n\nSafe\n\ndef Safe(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nstr(object=’’) -&gt; str str(bytes_or_buffer[, encoding[, errors]]) -&gt; str\nCreate a new string object from the given object. If encoding or errors is specified, then the object must expose a data buffer that will be decoded using the given encoding and error handler. Otherwise, returns the result of object.__str__() (if defined) or repr(object). encoding defaults to sys.getdefaultencoding(). errors defaults to ‘strict’.",
    "crumbs": [
      "XML"
    ]
  },
  {
    "objectID": "xml.html#conversion-to-xmlhtml",
    "href": "xml.html#conversion-to-xmlhtml",
    "title": "XML",
    "section": "Conversion to XML/HTML",
    "text": "Conversion to XML/HTML\n\nsource\n\nto_xml\n\ndef to_xml(\n    elm, lvl:int=0, indent:bool=True, do_escape:bool=True\n):\n\nConvert ft element tree into an XML string\n\nsource\n\n\nFT.__html__\n\ndef __html__(\n    \n):\n\n\nto_xml(Div(\"&lt;script&gt;alert('XSS')&lt;/script&gt;\"), do_escape=True)\n\n\"&lt;div&gt;&lt;script&gt;alert('XSS')&lt;/script&gt;&lt;/div&gt;\\n\"\n\n\n\nh = to_xml(samp, do_escape=False)\nprint(h)\n\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;Some page&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div class=\"myclass another\" style=\"padding:1; margin:2\"&gt;\nSome text\nanother line      &lt;input name=\"jph's\"&gt;\n&lt;img src=\"filename\" data=\"1\"&gt;    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\nc = I('hello')\nprint(c)\n\n&lt;i&gt;hello&lt;/i&gt;\n\n\n\nc\n\nhello\n\n\n\nclass PageTitle:\n    def __ft__(self): return H1(\"Hello\")\n\nclass HomePage:\n    def __ft__(self): return Div(PageTitle(), Div('hello'))\n\nh = to_xml(Div(HomePage()))\nexpected_output = \"\"\"&lt;div&gt;\n  &lt;div&gt;\n    &lt;h1&gt;Hello&lt;/h1&gt;\n    &lt;div&gt;hello&lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\"\"\"\nassert h == expected_output\n\n\nprint(h)\n\n&lt;div&gt;\n  &lt;div&gt;\n    &lt;h1&gt;Hello&lt;/h1&gt;\n    &lt;div&gt;hello&lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n\n\n\n\nh = to_xml(samp, indent=False)\nprint(h)\n\n&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Some page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"myclass another\" style=\"padding:1; margin:2\"&gt;Some text\nanother line&lt;input name=\"jph's\"&gt;&lt;img src=\"filename\" data=\"1\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\nInteroperability both directions with Django and Jinja using the html() protocol:\n\ndef _esc(s): return s.__html__() if hasattr(s, '__html__') else Safe(escape(s))\n\nr = Safe('&lt;b&gt;Hello from Django&lt;/b&gt;')\nprint(to_xml(Div(r)))\nprint(_esc(Div(P('Hello from fastcore &lt;3'))))\n\n&lt;div&gt;&lt;b&gt;Hello from Django&lt;/b&gt;&lt;/div&gt;\n\n&lt;div&gt;&lt;p&gt;Hello from fastcore &lt;3&lt;/p&gt;&lt;/div&gt;\n\n\nFT attributes are rendered with to_xml:\n\nprint(to_xml(P('hi', value=Div('ho'))))\n\n&lt;p value=\"&lt;div&gt;ho&lt;/div&gt;\"&gt;hi&lt;/p&gt;\n\n\n\nFT components also stringify with to_xml:\n\nprint(Div('ho'))\n\n&lt;div&gt;ho&lt;/div&gt;\n\n\n\nsource\n\n\nFT.__hash__\n\ndef __hash__(\n    \n):\n\nReturn hash(self).\n\nsource\n\n\nFT.__eq__\n\ndef __eq__(\n    other\n):\n\nReturn self==value.\nFT object equality and hashing is based on tag, attrs, and children.\n\ntest_eq(Div('hello', id='x'), Div('hello', id='x'))\ntest_ne(Div('hello'), Div('goodbye'))\ntest_ne(Div('hello', id='a'), Div('hello', id='b'))\ntest_ne(P('hello'), Div('hello'))\n\ntest_eq(hash(Div('hello', id='x')), hash(Div('hello', id='x')))\nassert hash(Div('hello')), hash(Div('goodbye'))",
    "crumbs": [
      "XML"
    ]
  },
  {
    "objectID": "xml.html#display",
    "href": "xml.html#display",
    "title": "XML",
    "section": "Display",
    "text": "Display\n\nsource\n\nhighlight\n\ndef highlight(\n    s, lang:str='html'\n):\n\nMarkdown to syntax-highlight s in language lang\n\nsource\n\n\nshowtags\n\ndef showtags(\n    s\n):\n\nYou can also reorder the children to come after the attrs, if you use this alternative syntax for FT where the children are in a second pair of () (behind the scenes this is because FT implements __call__ to add children).\n\nhl_md(\nBody(klass='myclass')(\n    Div(style='padding:3px')(\n        'Some text 1&lt;2',\n        I(spurious=True)('in italics'),\n        Input(name='me'),\n        Img(src=\"filename\", data=1)\n    )\n))\n\n&lt;body class=\"myclass\"&gt;\n  &lt;div style=\"padding:3px\"&gt;\nSome text 1&lt;2&lt;i spurious&gt;in italics&lt;/i&gt;    &lt;input name=\"me\"&gt;\n&lt;img src=\"filename\" data=\"1\"&gt;  &lt;/div&gt;\n&lt;/body&gt;\n\n\n\nsource\n\n\ngetattr\n\ndef __getattr__(\n    tag\n):",
    "crumbs": [
      "XML"
    ]
  },
  {
    "objectID": "net.html",
    "href": "net.html",
    "title": "Network functionality",
    "section": "",
    "text": "from fastcore.test import *\nfrom nbdev.showdoc import *\nfrom fastcore.nb_imports import *",
    "crumbs": [
      "Network functionality"
    ]
  },
  {
    "objectID": "net.html#urls",
    "href": "net.html#urls",
    "title": "Network functionality",
    "section": "URLs",
    "text": "URLs\n\nsource\n\nurlquote\n\ndef urlquote(\n    url\n):\n\nUpdate url’s path with urllib.parse.quote\n\nurlquote(\"https://github.com/fastai/fastai/compare/master@{1.day.ago}…master\")\n\n'https://github.com/fastai/fastai/compare/master@%7B1.day.ago%7D%E2%80%A6master'\n\n\n\nurlquote(\"https://www.google.com/search?q=你好\")\n\n'https://www.google.com/search?q=%E4%BD%A0%E5%A5%BD'\n\n\n\nsource\n\n\nurlwrap\n\ndef urlwrap(\n    url, data:NoneType=None, headers:NoneType=None\n):\n\nWrap url in a urllib Request with urlquote\n\nsource\n\nHTTP4xxClientError\n\ndef HTTP4xxClientError(\n    url, code, msg, hdrs, fp\n):\n\nBase class for client exceptions (code 4xx) from url* functions\n\nsource\n\n\nHTTP5xxServerError\n\ndef HTTP5xxServerError(\n    url, code, msg, hdrs, fp\n):\n\nBase class for server exceptions (code 5xx) from url* functions\n\nsource\n\n\n\nurlopener\n\ndef urlopener(\n    \n):\n\n\nsource\n\n\nurlopen\n\ndef urlopen(\n    url, data:NoneType=None, headers:NoneType=None, timeout:NoneType=None, kwargs:VAR_KEYWORD\n):\n\nLike urllib.request.urlopen, but first urlwrap the url, and encode data\nWith urlopen, the body of the response will also be returned in addition to the message if there is an error:\n\ntry: urlopen('https://api.github.com/v3')\nexcept HTTPError as e: \n    print(e.code, e.msg)\n    assert 'documentation_url' in e.msg\n\n404 Not Found\n====Error Body====\n{\n  \"message\": \"Not Found\",\n  \"documentation_url\": \"https://docs.github.com/rest\",\n  \"status\": \"404\"\n}\n\n\n\nsource\n\n\nurlread\n\ndef urlread(\n    url, data:NoneType=None, headers:NoneType=None, decode:bool=True, return_json:bool=False,\n    return_headers:bool=False, timeout:NoneType=None, kwargs:VAR_KEYWORD\n):\n\nRetrieve url, using data dict or kwargs to POST if present\n\nsource\n\n\nurljson\n\ndef urljson(\n    url, data:NoneType=None, headers:NoneType=None, timeout:NoneType=None\n):\n\nRetrieve url and decode json\n\ntest_eq(urljson('https://httpbin.org/get')['headers']['User-Agent'], url_default_headers['User-Agent'])\n\n\nsource\n\n\nurlcheck\n\ndef urlcheck(\n    url, headers:NoneType=None, timeout:int=10\n):\n\n\nsource\n\n\nurlclean\n\ndef urlclean(\n    url\n):\n\nRemove fragment, params, and querystring from url if present\n\ntest_eq(urlclean('http://a.com/b?c=1#d'), 'http://a.com/b')\n\n\nsource\n\n\nurlretrieve\n\ndef urlretrieve(\n    url, filename:NoneType=None, reporthook:NoneType=None, data:NoneType=None, headers:NoneType=None,\n    timeout:NoneType=None\n):\n\nSame as urllib.request.urlretrieve but also works with Request objects\n\nsource\n\n\nurldest\n\ndef urldest(\n    url, dest:NoneType=None\n):\n\n\nsource\n\n\nurlsave\n\ndef urlsave(\n    url, dest:NoneType=None, reporthook:NoneType=None, headers:NoneType=None, timeout:NoneType=None\n):\n\nRetrieve url and save based on its name\n\n#skip\nwith tempfile.TemporaryDirectory() as d: urlsave('http://www.google.com/index.html', d)\n\n\nsource\n\n\nurlvalid\n\ndef urlvalid(\n    x\n):\n\nTest if x is a valid URL\n\nassert urlvalid('http://www.google.com/')\nassert not urlvalid('www.google.com/')\nassert not urlvalid(1)\n\n\nsource\n\n\nurlrequest\n\ndef urlrequest(\n    url, verb, headers:NoneType=None, route:NoneType=None, query:NoneType=None, data:NoneType=None,\n    json_data:bool=True\n):\n\nRequest for url with optional route params replaced by route, plus query string, and post data\n\nhdr = {'Hdr1':'1', 'Hdr2':'2'}\nreq = urlrequest('http://example.com/{foo}/1', 'POST',\n                 headers=hdr, route={'foo':'3'}, query={'q':'4'}, data={'d':'5'})\n\ntest_eq(req.headers, hdr)\ntest_eq(req.full_url, 'http://example.com/3/1?q=4')\ntest_eq(req.method, 'POST')\ntest_eq(req.data, b'{\"d\": \"5\"}')\n\n\nreq = urlrequest('http://example.com/{foo}/1', 'POST', data={'d':'5','e':'6'}, headers=hdr, json_data=False)\ntest_eq(req.data, b'd=5&e=6')\n\n\nsource\n\n\nRequest.summary\n\ndef summary(\n    skip:NoneType=None\n)-&gt;dict:\n\nSummary containing full_url, headers, method, and data, removing skip from headers\n\nreq.summary(skip='Hdr1')\n\n{'full_url': 'http://example.com/{foo}/1',\n 'method': 'POST',\n 'data': b'd=5&e=6',\n 'headers': {'Hdr2': '2'}}\n\n\n\nsource\n\n\nurlsend\n\ndef urlsend(\n    url, verb, headers:NoneType=None, decode:bool=True, route:NoneType=None, query:NoneType=None, data:NoneType=None,\n    json_data:bool=True, return_json:bool=True, return_headers:bool=False, debug:NoneType=None,\n    timeout:NoneType=None\n):\n\nSend request with urlrequest, converting result to json if return_json\n\nsource\n\n\ndo_request\n\ndef do_request(\n    url, post:bool=False, headers:NoneType=None, data:VAR_KEYWORD\n):\n\nCall GET or json-encoded POST on url, depending on post",
    "crumbs": [
      "Network functionality"
    ]
  },
  {
    "objectID": "net.html#basic-clientserver",
    "href": "net.html#basic-clientserver",
    "title": "Network functionality",
    "section": "Basic client/server",
    "text": "Basic client/server\n\nsource\n\nstart_server\n\ndef start_server(\n    port, host:NoneType=None, dgram:bool=False, reuse_addr:bool=True, n_queue:NoneType=None\n):\n\nCreate a socket server on port, with optional host, of type dgram\nYou can create a TCP client and server pass an int as port and optional host. host defaults to your main network interface if not provided. You can create a Unix socket client and server by passing a string to port. A SOCK_STREAM socket is created by default, unless you pass dgram=True, in which case a SOCK_DGRAM socket is created. n_queue sets the listening queue size.\n\nsource\n\n\nstart_client\n\ndef start_client(\n    port, host:NoneType=None, dgram:bool=False\n):\n\nCreate a socket client on port, with optional host, of type dgram\n\nsource\n\n\ntobytes\n\ndef tobytes(\n    s:str\n)-&gt;bytes:\n\nConvert s into HTTP-ready bytes format\n\ntest_eq(tobytes('foo\\nbar'), b'foo\\r\\nbar')\n\n\nsource\n\n\nhttp_response\n\ndef http_response(\n    body:NoneType=None, status:int=200, hdrs:NoneType=None, kwargs:VAR_KEYWORD\n):\n\nCreate an HTTP-ready response, adding kwargs to hdrs\n\nexp = b'HTTP/1.1 200 OK\\r\\nUser-Agent: me\\r\\nContent-Length: 4\\r\\n\\r\\nbody'\ntest_eq(http_response('body', 200, User_Agent='me'), exp)\n\n\nsource\n\n\nrecv_once\n\ndef recv_once(\n    host:str='localhost', port:int=8000\n):\n\nSpawn a thread to receive a single HTTP request and store in d['r']",
    "crumbs": [
      "Network functionality"
    ]
  }
]